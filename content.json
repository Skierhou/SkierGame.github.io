{"meta":{"title":"Skier","subtitle":"游戏开发","description":"游戏开发","author":"Skier","url":"https://SkierHou.github.io","root":"/blog/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2021-03-10T02:11:56.918Z","updated":"2021-03-10T02:11:56.918Z","comments":false,"path":"/404.html","permalink":"https://skierhou.github.io/404.html","excerpt":"","text":""},{"title":"标签","date":"2021-03-01T10:53:57.000Z","updated":"2021-03-10T05:44:23.017Z","comments":true,"path":"categories/index.html","permalink":"https://skierhou.github.io/categories/index.html","excerpt":"","text":""},{"title":"GameFramework学习","date":"2021-03-01T10:53:57.000Z","updated":"2021-03-10T02:11:56.963Z","comments":true,"path":"categories/index3.html","permalink":"https://skierhou.github.io/categories/index3.html","excerpt":"","text":""},{"title":"关于","date":"2021-03-10T05:45:15.760Z","updated":"2021-03-10T05:45:15.760Z","comments":false,"path":"about/index.html","permalink":"https://skierhou.github.io/about/index.html","excerpt":"","text":"不想当策划，美术，制作者的程序不是一个好程序"},{"title":"书单","date":"2021-03-10T02:11:56.941Z","updated":"2021-03-10T02:11:56.941Z","comments":false,"path":"books/index.html","permalink":"https://skierhou.github.io/books/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2021-03-10T02:11:56.994Z","updated":"2021-03-10T02:11:56.994Z","comments":false,"path":"repository/index.html","permalink":"https://skierhou.github.io/repository/index.html","excerpt":"","text":""},{"title":"link","date":"2021-03-01T11:11:07.000Z","updated":"2021-03-10T02:11:56.974Z","comments":true,"path":"link/index.html","permalink":"https://skierhou.github.io/link/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2021-03-10T02:11:56.985Z","updated":"2021-03-10T02:11:56.985Z","comments":true,"path":"links/index.html","permalink":"https://skierhou.github.io/links/index.html","excerpt":"","text":""},{"title":"标签1","date":"2021-03-01T11:09:41.000Z","updated":"2021-03-10T02:11:57.006Z","comments":true,"path":"tags/index.html","permalink":"https://skierhou.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Unity 开发一些记录","slug":"Unity/一些记录","date":"2021-12-20T06:30:01.000Z","updated":"2021-12-21T12:19:32.482Z","comments":true,"path":"2021/12/20/Unity/一些记录/","link":"","permalink":"https://skierhou.github.io/2021/12/20/Unity/%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95/","excerpt":"","text":"XLua开发的一些问题记录 C#枚举在lua中转Int：CS.System.Convert.ChangeType() 泛型函数使用：xlua.get_generic_method(instance, “func_name”); //成员函数传实例，静态函数传类型 RawImage使用扩展前言使用通用管理器UIModelManager，方便RawImage,RT加载卸载，以及RawImage与模型交互 基础思路 对应每一张RawImage，由于显示不同都需要不同的Camera以及RT，将Camera.targetTexture设置成RT 模型加载卸载走项目通用方式 交互问题：在UI上我们只能点击这个RawImage，如果RawImage中只显示一个模型，那我们可以直接在UI上监听拖拽修改这个模型的旋转或者其他操作但是这样做非常不友好，并不能精确的知道是否点中了这张RT上的模型，扩展一下改成世界坐标射线检测，这样不管RT上有多少模型都可以做交互 整理一下交互中射线检测计算思路：(1) 拿到点击位置计算其在RawImage中的偏移值(2) 将偏移值运算在相机的实际渲染高宽上(3) 怎么获得相机实际渲染高宽：正交相机：height=orthographicSize * 2， width = 宽高比height透视相机：height=tan(fov / 2) * near * 2， width = 宽高比height具体推算过程仔细看下这个公式就能知道，关于正交相机高度=size*2这个是Unity中的固定值 交互按需求自行添加，在UIRenderToTexture中监听IDragHandler, IBeginDragHandler, IEndDragHandler, IPointerClickHandler等即可 12345678910111213141516171819202122232425262728293031323334353637383940private void SetClickTarget(Vector2 clickPos)&#123; &#x2F;&#x2F; 通过射线检测当前点击的模型 &#x2F;&#x2F; 拿到点击位置与UI位置的偏移百分比 Camera uiCamera &#x3D; Hooks.CameraManager.UICamera; float width &#x3D; m_RawImage.rectTransform.rect.width; float height &#x3D; m_RawImage.rectTransform.rect.height; Vector2 screenPos &#x3D; RectTransformUtility.WorldToScreenPoint(uiCamera, transform.position); screenPos +&#x3D; new Vector2(width * (0.5f - m_RawImage.rectTransform.pivot.x), height * (0.5f - m_RawImage.rectTransform.pivot.y)); Vector2 offset &#x3D; clickPos - screenPos; offset &#x3D; new Vector2(offset.x &#x2F; width, offset.y &#x2F; height); if (m_Camera.orthographic) &#123; &#x2F;&#x2F; 正交相机的渲染大小height&#x3D;size*2， width &#x3D; 宽高比*height float screenHeight &#x3D; m_Camera.orthographicSize * 2; float screenWidth &#x3D; m_Camera.pixelWidth * 1.0f &#x2F; m_Camera.pixelHeight * screenHeight; Vector3 startPoint &#x3D; m_Camera.transform.position + m_Camera.transform.right * offset.x * screenWidth + m_Camera.transform.up * offset.y * screenHeight; Debug.DrawLine(startPoint, startPoint + m_Camera.transform.forward * 100, Color.red, 5f); if (Physics.Raycast(startPoint, m_Camera.transform.forward, out RaycastHit hit, 100, 1 &lt;&lt; Constant.Layer.UIRenderToTarget)) &#123; m_DragTarget &#x3D; hit.transform; &#125; &#125; else &#123; &#x2F;&#x2F; 透视相机通过FOV和near可以求height， width同正交相机 float screenHeight &#x3D; Mathf.Tan(m_Camera.fieldOfView * 0.5f * Mathf.Deg2Rad) * m_Camera.nearClipPlane * 2; float screenWidth &#x3D; m_Camera.pixelWidth * 1.0f &#x2F; m_Camera.pixelHeight * screenHeight; Vector3 endPoint &#x3D; m_Camera.transform.position + m_Camera.transform.forward * m_Camera.nearClipPlane + m_Camera.transform.right * offset.x * screenWidth + m_Camera.transform.up * offset.y * screenHeight; Vector3 dir &#x3D; (endPoint - m_Camera.transform.position).normalized; Debug.DrawLine(m_Camera.transform.position, endPoint, Color.red, 5f); if (Physics.Raycast(m_Camera.transform.position, dir, out RaycastHit hit, m_Camera.farClipPlane, 1 &lt;&lt; Constant.Layer.UIRenderToTarget)) &#123; m_DragTarget &#x3D; hit.transform; &#125; &#125;&#125; 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373using System;using System.Collections.Generic;using UnityEngine;using UnityEngine.EventSystems;using UnityEngine.UI;namespace Gameplay&#123; public class UIModelManager : ManagerBase &#123; private Stack&lt;Camera&gt; m_CameraPool &#x3D; new Stack&lt;Camera&gt;(); private Stack&lt;int&gt; m_IndexPool &#x3D; new Stack&lt;int&gt;(); private int m_PoolCount &#x3D; 0; private Transform m_UIModelRoot; private Light m_UIModelLight; public override void OnInitilize() &#123; base.OnInitilize(); m_UIModelRoot &#x3D; new GameObject(&quot;UIModelRoot&quot;).transform; m_UIModelRoot.SetParentEx(null); GameObject.DontDestroyOnLoad(m_UIModelRoot); m_UIModelLight &#x3D; new GameObject(&quot;UIModelLight&quot;).GetOrAddComponent&lt;Light&gt;(); m_UIModelLight.transform.SetParentEx(m_UIModelRoot); m_UIModelLight.transform.localEulerAngles &#x3D; new Vector3(36, 30, 0); m_UIModelLight.cookieSize &#x3D; 10; m_UIModelLight.type &#x3D; LightType.Directional; m_UIModelLight.cullingMask &#x3D; 1 &lt;&lt; Constant.Layer.UI | 1 &lt;&lt; Constant.Layer.UIRenderToTarget; m_UIModelLight.shadows &#x3D; LightShadows.None; m_UIModelLight.gameObject.SetActive(false); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 加载一个模型到一张RawImage上 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; public void LoadModelToRawImage(string path, RawImage rawImage, bool canDrag &#x3D; true, Vector3 offset &#x3D; default, Quaternion rot &#x3D; default, Vector3 scale &#x3D; default, Action&lt;UIRenderToTexture, GameObject&gt; callback &#x3D; null) &#123; if (rawImage &#x3D;&#x3D; null) &#123; Debug.LogError(&quot;RawImage Is Null!&quot;); return; &#125; Hooks.GameObjectManager.SpawnAsync(path, (go) &#x3D;&gt; &#123; if (go !&#x3D; null) &#123; UIRenderToTexture renderToTexture &#x3D; rawImage.GetComponent&lt;UIRenderToTexture&gt;(); Vector3 pos; if (renderToTexture &#x3D;&#x3D; null) &#123; int index &#x3D; m_IndexPool.Count &gt; 0 ? m_IndexPool.Pop() : m_PoolCount++; pos &#x3D; new Vector3(10 * index, -10000, 0); renderToTexture &#x3D; rawImage.GetOrAddComponent&lt;UIRenderToTexture&gt;(); renderToTexture.Init(pos, true, index); UpdateLight(); &#125; else &#123; pos &#x3D; new Vector3(10 * renderToTexture.Index, -10000, 0); &#125; go.SetLayerRecursively(Constant.Layer.UIRenderToTarget); go.transform.SetParent(m_UIModelRoot); go.transform.localPosition &#x3D; pos + offset; go.transform.localScale &#x3D; scale &#x3D;&#x3D; default ? Vector3.one : scale; go.transform.rotation &#x3D; rot; renderToTexture.AddTarget(go, canDrag); callback?.Invoke(renderToTexture, go); &#125; &#125;); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 卸载单个 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; public void UnLoadModelByRawImage(RawImage rawImage, GameObject go) &#123; if (rawImage !&#x3D; null &amp;&amp; go !&#x3D; null) &#123; UIRenderToTexture renderToTexture &#x3D; rawImage.GetComponent&lt;UIRenderToTexture&gt;(); int id &#x3D; go.GetInstanceID(); if (renderToTexture !&#x3D; null &amp;&amp; renderToTexture.Targets !&#x3D; null &amp;&amp; renderToTexture.Targets.ContainsKey(id)) &#123; renderToTexture.Targets.Remove(id); Hooks.GameObjectManager.Recycle(go); if (renderToTexture.Targets.Count &#x3D;&#x3D; 0) &#123; renderToTexture.ResetTarget(); m_IndexPool.Push(renderToTexture.Index); &#125; &#125; UpdateLight(); &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 卸载所有 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; public void UnLoadModelByRawImage(RawImage rawImage) &#123; if (rawImage !&#x3D; null) &#123; UIRenderToTexture renderToTexture &#x3D; rawImage.GetComponent&lt;UIRenderToTexture&gt;(); if (renderToTexture !&#x3D; null &amp;&amp; renderToTexture.Targets !&#x3D; null) &#123; foreach (var target in renderToTexture.Targets.Values) &#123; Hooks.GameObjectManager.Recycle(target.gameObject); &#125; renderToTexture.ResetTarget(); m_IndexPool.Push(renderToTexture.Index); &#125; UpdateLight(); &#125; &#125; private void UpdateLight() &#123; m_UIModelLight.gameObject.SetActive(m_CameraPool.Count &lt; m_PoolCount); &#125; public Camera SpawnCamera() &#123; if (m_CameraPool.Count &gt; 0) &#123; Camera camera &#x3D; m_CameraPool.Pop(); camera.gameObject.SetActive(true); return camera; &#125; else &#123; GameObject go &#x3D; new GameObject(&quot;CameraRTT&quot;); go.transform.SetParentEx(m_UIModelRoot); Camera camera &#x3D; go.GetOrAddComponent&lt;Camera&gt;(); camera.fieldOfView &#x3D; 30; camera.allowHDR &#x3D; false; camera.backgroundColor &#x3D; Color.clear; camera.useOcclusionCulling &#x3D; false; camera.clearFlags &#x3D; CameraClearFlags.SolidColor; camera.cullingMask &#x3D; 1 &lt;&lt; Constant.Layer.UIRenderToTarget; camera.farClipPlane &#x3D; 30; camera.orthographicSize &#x3D; 1; return camera; &#125; &#125; public void RecyleCamera(Camera camera) &#123; if (camera !&#x3D; null) &#123; camera.targetTexture &#x3D; null; camera.gameObject.SetActive(false); m_CameraPool.Push(camera); &#125; &#125; &#125; public class UIRenderToTexture : MonoBehaviour, IDragHandler, IBeginDragHandler, IEndDragHandler, IPointerClickHandler &#123; public struct Target &#123; public GameObject gameObject; public bool canDrag; &#125; private Camera m_Camera; private RawImage m_RawImage; private RenderTexture m_RenderTexture; private Dictionary&lt;int, Target&gt; m_Targets; private int m_Index; private Transform m_DragTarget; public Dictionary&lt;int, Target&gt; Targets &#x3D;&gt; m_Targets; public int Index &#x3D;&gt; m_Index; void OnEnable() &#123; InitCamera(); if (m_RawImage &#x3D;&#x3D; null) m_RawImage &#x3D; GetComponent&lt;RawImage&gt;(); if (m_Targets !&#x3D; null) &#123; foreach (var target in m_Targets.Values) &#123; if(target.gameObject !&#x3D; null) target.gameObject.SetActive(true); &#125; &#125; if (m_RenderTexture &#x3D;&#x3D; null) &#123; m_RenderTexture &#x3D; RenderTexture.GetTemporary((int)m_RawImage.rectTransform.rect.width, (int)m_RawImage.rectTransform.rect.height, 1); m_RenderTexture.name &#x3D; &quot;UIRenderToTexture&quot;; &#125; m_Camera.targetTexture &#x3D; m_RenderTexture; m_RawImage.texture &#x3D; m_RenderTexture; &#125; void OnDisable() &#123; if (m_Targets !&#x3D; null) &#123; foreach (var target in m_Targets.Values) &#123; if(target.gameObject !&#x3D; null) target.gameObject.SetActive(true); &#125; &#125; if (m_Camera !&#x3D; null) Hooks.UIModelManager.RecyleCamera(m_Camera); ReleaseRenderTexture(); &#125; void OnDestroy() &#123; if (m_Camera !&#x3D; null) Hooks.UIModelManager.RecyleCamera(m_Camera); ReleaseRenderTexture(); &#125; private void InitCamera(bool orth &#x3D; true) &#123; if (m_Camera &#x3D;&#x3D; null) &#123; m_Camera &#x3D; Hooks.UIModelManager.SpawnCamera(); &#125; else &#123; m_Camera.gameObject.SetActive(true); &#125; m_Camera.orthographic &#x3D; orth; &#125; private void ReleaseRenderTexture() &#123; if (m_RenderTexture !&#x3D; null) &#123; RenderTexture.ReleaseTemporary(m_RenderTexture); m_RenderTexture &#x3D; null; m_RawImage.texture &#x3D; null; &#125; &#125; public void Init(Vector3 vec, bool orth, int index) &#123; InitCamera(orth); m_Index &#x3D; index; if (m_Camera) &#123; m_Camera.transform.localPosition &#x3D; vec + new Vector3(0, 0, 20); m_Camera.transform.localEulerAngles &#x3D; new Vector3(0, 180, 0); &#125; &#125; public void AddTarget(GameObject target, bool canDrag) &#123; if (target) &#123; if (m_Targets &#x3D;&#x3D; null) m_Targets &#x3D; new Dictionary&lt;int, Target&gt;(); m_Targets.Add(target.GetInstanceID(), new Target &#123; gameObject &#x3D; target, canDrag &#x3D; canDrag &#125;); &#125; &#125; public void ResetTarget() &#123; m_Targets.Clear(); m_Targets &#x3D; null; if (m_Camera !&#x3D; null) Hooks.UIModelManager.RecyleCamera(m_Camera); ReleaseRenderTexture(); &#125; private void Update() &#123; if (m_Targets !&#x3D; null) &#123; foreach (var target in m_Targets.Values) &#123; if(m_DragTarget &#x3D;&#x3D; null || m_DragTarget.gameObject !&#x3D; target.gameObject) target.gameObject.transform.rotation &#x3D; Quaternion.Lerp(target.gameObject.transform.rotation, Quaternion.identity, Time.deltaTime * 5); &#125; &#125; &#125; private void SetClickTarget(Vector2 clickPos) &#123; &#x2F;&#x2F; 通过射线检测当前点击的模型 &#x2F;&#x2F; 拿到点击位置与UI位置的偏移百分比 Camera uiCamera &#x3D; Hooks.CameraManager.UICamera; float width &#x3D; m_RawImage.rectTransform.rect.width; float height &#x3D; m_RawImage.rectTransform.rect.height; Vector2 screenPos &#x3D; RectTransformUtility.WorldToScreenPoint(uiCamera, transform.position); screenPos +&#x3D; new Vector2(width * (0.5f - m_RawImage.rectTransform.pivot.x), height * (0.5f - m_RawImage.rectTransform.pivot.y)); Vector2 offset &#x3D; clickPos - screenPos; offset &#x3D; new Vector2(offset.x &#x2F; width, offset.y &#x2F; height); if (m_Camera.orthographic) &#123; &#x2F;&#x2F; 正交相机的渲染大小height&#x3D;size*2， width &#x3D; 宽高比*height float screenHeight &#x3D; m_Camera.orthographicSize * 2; float screenWidth &#x3D; m_Camera.pixelWidth * 1.0f &#x2F; m_Camera.pixelHeight * screenHeight; Vector3 startPoint &#x3D; m_Camera.transform.position + m_Camera.transform.right * offset.x * screenWidth + m_Camera.transform.up * offset.y * screenHeight; Debug.DrawLine(startPoint, startPoint + m_Camera.transform.forward * 100, Color.red, 5f); if (Physics.Raycast(startPoint, m_Camera.transform.forward, out RaycastHit hit, 100, 1 &lt;&lt; Constant.Layer.UIRenderToTarget)) &#123; m_DragTarget &#x3D; hit.transform; &#125; &#125; else &#123; &#x2F;&#x2F; 透视相机通过FOV和near可以求height， width同正交相机 float screenHeight &#x3D; Mathf.Tan(m_Camera.fieldOfView * 0.5f * Mathf.Deg2Rad) * m_Camera.nearClipPlane * 2; float screenWidth &#x3D; m_Camera.pixelWidth * 1.0f &#x2F; m_Camera.pixelHeight * screenHeight; Vector3 endPoint &#x3D; m_Camera.transform.position + m_Camera.transform.forward * m_Camera.nearClipPlane + m_Camera.transform.right * offset.x * screenWidth + m_Camera.transform.up * offset.y * screenHeight; Vector3 dir &#x3D; (endPoint - m_Camera.transform.position).normalized; Debug.DrawLine(m_Camera.transform.position, endPoint, Color.red, 5f); if (Physics.Raycast(m_Camera.transform.position, dir, out RaycastHit hit, m_Camera.farClipPlane, 1 &lt;&lt; Constant.Layer.UIRenderToTarget)) &#123; m_DragTarget &#x3D; hit.transform; &#125; &#125; &#125; public void OnBeginDrag(PointerEventData eventData) &#123; m_DragTarget &#x3D; null; SetClickTarget(eventData.position); &#x2F;&#x2F; 不能拖拽时置空 if (m_DragTarget !&#x3D; null &amp;&amp; m_Targets.TryGetValue(m_DragTarget.GetInstanceID(), out Target target) &amp;&amp; !target.canDrag) &#123; m_DragTarget &#x3D; null; &#125; &#125; public void OnDrag(PointerEventData eventData) &#123; if (m_DragTarget !&#x3D; null) m_DragTarget.localEulerAngles -&#x3D; new Vector3(0, eventData.delta.x, 0); &#125; public void OnEndDrag(PointerEventData eventData) &#123; m_DragTarget &#x3D; null; &#125; public void OnPointerClick(PointerEventData eventData) &#123; m_DragTarget &#x3D; null; SetClickTarget(eventData.position); if (m_DragTarget !&#x3D; null) &#123; &#x2F;&#x2F; 点中模型，发送事件或者其他操作 &#125; &#125; &#125;&#125; ScrollView扩展","categories":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/categories/Unity/"}],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/tags/Unity/"}]},{"title":"C# Task用法记录","slug":"CSharp/Task","date":"2021-12-01T06:30:01.000Z","updated":"2021-12-21T12:17:27.531Z","comments":true,"path":"2021/12/01/CSharp/Task/","link":"","permalink":"https://skierhou.github.io/2021/12/01/CSharp/Task/","excerpt":"","text":"链接超详细： https://www.cnblogs.com/zhaoshujie/p/11082753.html官方： https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.task?view=netcore-3.1 基础ThreadPool相比Thread来说具备了很多优势，但是ThreadPool却又存在一些使用上的不方便。比如： ThreadPool不支持线程的取消、完成、失败通知等交互性操作； ThreadPool不支持线程执行的先后次序； 使用方式： 函数标记async，则执行这个函数会启用一个线程12345678910111213public static async Task Test()&#123; await Task.Run(() &#x3D;&gt; &#123; &#x2F;&#x2F; Just loop. int ctr &#x3D; 0; for (ctr &#x3D; 0; ctr &lt;&#x3D; 1000000; ctr++) &#123; &#125; Console.WriteLine(&quot;Finished &#123;0&#125; loop iterations&quot;, ctr); &#125;); Console.WriteLine(&quot;Finish111&quot;);&#125; Task t = Task.Factory.StartNew(action); Task t = new Task(action); t.Start(); //new Task() 默认不会启动 需要主动启动 父任务包含子任务：关键是父任务中，创建子任务且设置TaskCreationOptions.AttachedToParent123456789Task&lt;string[]&gt; parent &#x3D; new Task&lt;string[]&gt;(state &#x3D;&gt;&#123; &#x2F;&#x2F;创建并启动子任务 string[] result &#x3D; new string[2]; new Task(() &#x3D;&gt; &#123; Thread.Sleep(2000); result[0] &#x3D; &quot;我是子任务1。&quot;; &#125;, TaskCreationOptions.AttachedToParent).Start(); return result;&#125;parent.Start();&#x2F;&#x2F;等待子任务执行完，parent才算执行完成 挂起函数 等待任务完成 注：’t’ 代表Task实例 等待1个，t.wait(); 等待多个Task，Task.WaitAll(Task[]); 等待多个Task到其中第一个完成为止，Task.WaitAny(Task[]) Task完成后执行，t.ContinueWith(Action) Task 接口分析 取消Task设置Task的CancellationTokenvar cts = new CancellationTokenSource();cts.Cancel(); 异常处理单个任务：Try{}catch (Exception ex){}多个任务：Try{}Catch(AggregateException ex){} IProgress异步编程的进程通知通过Report传入自定义T值，Progress执行委托 123456789101112131415161718192021222324static void DoProcessing(IProgress&lt;int&gt; progress)&#123; for (int i &#x3D; 0; i &lt;&#x3D; 100; ++i) &#123; Thread.Sleep(100); if (progress !&#x3D; null) &#123; progress.Report(i); &#125; &#125;&#125;static async Task Display()&#123; &#x2F;&#x2F;当前线程 var progress &#x3D; new Progress&lt;int&gt;(percent &#x3D;&gt; &#123; Console.Clear(); Console.Write(&quot;&#123;0&#125;%&quot;, percent); &#125;); &#x2F;&#x2F;线程池线程 await Task.Run(() &#x3D;&gt; DoProcessing(progress)); Console.WriteLine(&quot;&quot;); Console.WriteLine(&quot;结束&quot;);&#125;","categories":[{"name":"Task","slug":"Task","permalink":"https://skierhou.github.io/categories/Task/"}],"tags":[{"name":"C#","slug":"C","permalink":"https://skierhou.github.io/tags/C/"},{"name":"Task","slug":"Task","permalink":"https://skierhou.github.io/tags/Task/"}]},{"title":"C# Thread记录","slug":"CSharp/Thread","date":"2021-12-01T06:30:01.000Z","updated":"2021-12-21T12:17:24.108Z","comments":true,"path":"2021/12/01/CSharp/Thread/","link":"","permalink":"https://skierhou.github.io/2021/12/01/CSharp/Thread/","excerpt":"","text":"链接精简详细： https://www.cnblogs.com/luxiaoxun/p/3280146.html官网： https://docs.microsoft.com/en-us/dotnet/api/system.threading.thread?redirectedfrom=MSDN&amp;view=net-5.0Event用法： https://www.cnblogs.com/chenwolong/p/AutoResetEvent.htmlSemaphore用法： https://www.cnblogs.com/yifengjianbai/p/5468449.htmlMutex用法： https://www.cnblogs.com/nele/p/5534580.html 基础 进程与线程：进程作为操作系统执行程序的基本单位，拥有应用程序的资源，进程包含线程，进程的资源被线程共享，线程不拥有资源。 前台线程和后台线程：通过Thread类新建线程默认为前台线程。当所有前台线程关闭时，所有的后台线程也会被直接终止，不会抛出异常。 普通ThreadThread t1 = new Thread(new ThreadStart(TestMethod)); //不带参数Thread t2 = new Thread(new ParameterizedThreadStart(TestMethod)); //带一个object参数 函数 注释 Start(); 启动线程 Suspend(); 挂起线程 Resume(); 挂起线程 Abort(); 打断线程 Join(); 其他线程挂起，等待线程完成后执行之后的逻辑 与Task的Wait()类似 ThreadPool作用：为了减少Thread创建销毁的开销ThreadPool.QueueUserWorkItem(TestMethod, “Hello”); //创建并开启线程，可传入一个object参数 AutoResetEvent和ManualResetEvent的使用：即信号量的使用Event用法： https://www.cnblogs.com/chenwolong/p/AutoResetEvent.html构造函数：参数：true:非阻塞(不阻塞线程)，false：阻塞。区别：AutoResetEvent在每次WaitOne()后自动Reset()信号，而ManualResetEvent不会自动Reset()信号，需要手动Reset() Semaphore信号量：为了协调多个线程合理分配资源Semaphore用法： https://www.cnblogs.com/yifengjianbai/p/5468449.html Mutex互斥锁：同一时间只能有一个线程获取它Mutex用法： https://www.cnblogs.com/nele/p/5534580.html构造：new Mutex();申请：WaitOne();释放：ReleaseMutex(); Monitor排他锁：通过Monitor.Enter() 和 Monitor.Exit()实现排它锁的获取和释放，获取之后独占资源，不允许其他线程访问lock()语法是简化版本理解为Monitor.Enter() 和 Monitor.Exit()的语法糖 WaitHandle：以上线程同步操作的公共基类提供静态函数：WaitAll，WaitAnyWaitAll：等待一组WaitHandle全部完成，WaitAny：等待一组WaitHandle中的一个完成，只要判断有完成的即结束等待，返回值：数组的索引，如没有执行完成的则返回-1","categories":[{"name":"Thread","slug":"Thread","permalink":"https://skierhou.github.io/categories/Thread/"}],"tags":[{"name":"C#","slug":"C","permalink":"https://skierhou.github.io/tags/C/"},{"name":"Thread","slug":"Thread","permalink":"https://skierhou.github.io/tags/Thread/"}]},{"title":"URP效果实现,从基础慢慢深入","slug":"Graphics/URP/URP效果实现","date":"2021-11-30T06:30:01.000Z","updated":"2021-12-21T12:18:20.166Z","comments":true,"path":"2021/11/30/Graphics/URP/URP效果实现/","link":"","permalink":"https://skierhou.github.io/2021/11/30/Graphics/URP/URP%E6%95%88%E6%9E%9C%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"介绍之前学习过入门精要，之后就很少接触了，现在接触URP，再学习一遍入门精要也顺便学习下HLSL，主要是对着链接中的URP HLSL入门学习进行学习，会有一定自己的扩展 基础光照模型基础公式 Lambert： max(0,dot(L,N)) HalfLambert： max(0,dot(L,N)) * 0.5 + 0.5 Phong： pow(max(0,dot(reflect(-L,N), V)), Gloss) BlinnPhong： pow(max(0,dot(normalize(L+V), N)), Gloss) 代码 Lambert / HalfLambert / HalfLambert12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970Shader &quot;Unlit&#x2F;Lambert&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; _BaseColor (&quot;BaseColor&quot;, Color) &#x3D; (1,1,1,1) &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _BaseColor; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float4 normalOS:NORMAL; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; float3 normalWS:TEXCOORD1; &#125;; Varyings Vert(Attributes i) &#123; Varyings o; o.positionHS &#x3D; TransformObjectToHClip(i.positionOS.xyz); o.uv &#x3D; TRANSFORM_TEX(i.uv, _MainTex); o.normalWS &#x3D; TransformObjectToWorldNormal(i.normalOS.xyz, true); return o; &#125; float4 Frag(Varyings i) :SV_Target&#123; Light mylight &#x3D; GetMainLight(); real4 LightColor &#x3D; real4(mylight.color, 1); float3 lightDir &#x3D; normalize(mylight.direction); float lambert &#x3D; dot(normalize(i.normalWS), lightDir); float halfLambert &#x3D; lambert * 0.5f + 0.5f; float4 color &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv); return color * _BaseColor * halfLambert * LightColor; &#125; ENDHLSL Pass &#123; Tags&#123; &quot;LightMode&quot; &#x3D; &quot;UniversalForward&quot; &#125; HLSLPROGRAM #pragma vertex Vert #pragma fragment Frag ENDHLSL &#125; &#125;&#125; Phong / BlinnPhong / BlinnPhong123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778Shader &quot;Unlit&#x2F;Phong&quot;&#123; Properties &#123; _MainTex(&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; _GlossColor(&quot;BaseColor&quot;, Color) &#x3D; (1,1,1,1) _Gloss(&quot;Gloss&quot;, Range(1, 256)) &#x3D; 1 &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _GlossColor; float _Gloss; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float4 normalOS:NORMAL; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; float3 normalWS:TEXCOORD1; float3 viewDirWS:TEXCOORD2; &#125;; Varyings Vert(Attributes i) &#123; Varyings o; o.positionHS &#x3D; TransformObjectToHClip(i.positionOS.xyz); o.uv &#x3D; TRANSFORM_TEX(i.uv, _MainTex); o.viewDirWS &#x3D; normalize(_WorldSpaceCameraPos.xyz - TransformObjectToWorld(i.positionOS.xyz));&#x2F;&#x2F;得到世界空间的视图方向 o.normalWS &#x3D; TransformObjectToWorldNormal(i.normalOS.xyz, true); return o; &#125; float4 Frag(Varyings i) :SV_Target&#123; Light mylight &#x3D; GetMainLight(); real4 LightColor &#x3D; real4(mylight.color, 1); float3 lightDir &#x3D; normalize(mylight.direction); float3 viewDir &#x3D; normalize(i.viewDirWS); float3 worldNormal &#x3D; normalize(i.normalWS); float phong &#x3D; pow(max(dot(reflect(-lightDir, worldNormal), viewDir), 0), _Gloss); float blinnPhong &#x3D; pow(max(dot(normalize(lightDir + viewDir), worldNormal), 0), _Gloss); float4 col &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv); float4 diffuse &#x3D; LightColor * col * max(dot(lightDir, worldNormal), 0); float4 specular &#x3D; _GlossColor * blinnPhong * LightColor; return float4(specular.rgb + diffuse.rgb, col.a); &#125; ENDHLSL Pass &#123; Tags&#123; &quot;LightMode&quot; &#x3D; &quot;UniversalForward&quot; &#125; HLSLPROGRAM #pragma vertex Vert #pragma fragment Frag ENDHLSL &#125; &#125;&#125; 总结 TransformObjectToHClip TransformObjectToWorld TransformObjectToWorldNormal _WorldSpaceCameraPos 光照信息： #include “Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl” SubShader{HLSLINCLUDE … ENDHLSL} Pass{HLSLPROGRAM … ENDHLSL} (第一次写Pass中写成HLSLEINCLUDE了，没报错效果又一直是错的，注意了！！！) 法线贴图基础简介 我们采用在世界坐标系下，在片元着色器中进行计算。定义顶点着色器拿到数据的结构体，我们需要顶点位置，uv，顶点法线，顶点切线 获得世界坐标系下的：顶点位置，法线，切线，副切线计算副切线时，叉乘法线，切线，并在乘切线的w值判断正负，在乘负奇数缩放影响因子。 1o.BtangentWS&#x3D; cross(o.normal.xyz,o.tangent.xyz) * i.tangent.w; 片元处理中采样法线贴图，得切线空间法线，在将其转换到世界空间 12345float3x3 T2W &#x3D; &#123;i.tangentWS.xyz,i.BtangentWS.xyz,i.normalWS.xyz&#125;; float4 norTex &#x3D; SAMPLE_TEXTURE2D(_NormalTex, sampler_NormalTex, i.uv);float3 nomralTS &#x3D; UnpackNormalScale(norTex, _NormalScale);normalTS.z&#x3D;pow((1-pow(normalTS.x,2)-pow(normalTS.y,2)),0.5); &#x2F;&#x2F;规范化法线 不影响x,y情况下规范化z轴float3 normalWS &#x3D; normalize(mul(normalTS,T2W)); 使用带入法线贴图计算后的法线用于后续计算即可。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102Shader &quot;Unlit&#x2F;Normal&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; [Normal]_NormalTex(&quot;NormalTex&quot;, 2D) &#x3D; &quot;bump&quot;&#123;&#125; _NormalScale(&quot;NormalScale&quot;, float) &#x3D; 1 [HDR]_SpecularColor(&quot;SpecularColor&quot;, Color) &#x3D; (1,1,1,1) _Gloss(&quot;Gloss&quot;,Range(1,256)) &#x3D; 1 &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); TEXTURE2D(_NormalTex); SAMPLER(sampler_NormalTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _NormalTex_ST; float _NormalScale; float4 _SpecularColor; float _Gloss; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float4 normalOS:NORMAL; float4 tangentOS:TANGENT; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float4 uv : TEXCOORD0; float4 normalWS:TEXCOORD1; float4 tangentWS:TEXCOORD2; float4 BtangentWS:TEXCOORD3; &#125;; Varyings vert(Attributes i) &#123; Varyings o; o.positionHS &#x3D; TransformObjectToHClip(i.positionOS); o.normalWS.xyz &#x3D; normalize(TransformObjectToWorldNormal(i.normalOS)); o.tangentWS.xyz &#x3D; normalize(TransformObjectToWorld(i.tangentOS)); o.BtangentWS.xyz &#x3D; cross(o.normalWS.xyz, o.tangentWS.xyz) * i.tangentOS.w * unity_WorldTransformParams.w; &#x2F;&#x2F; 存一下世界空间坐标 float3 positionWS &#x3D; TransformObjectToWorld(i.positionOS); o.tangentWS.w &#x3D; positionWS.x; o.BtangentWS.w &#x3D; positionWS.y; o.normalWS.w &#x3D; positionWS.z; o.uv.xy &#x3D; TRANSFORM_TEX(i.uv, _MainTex); o.uv.zw &#x3D; TRANSFORM_TEX(i.uv, _NormalTex); return o; &#125; float4 frag(Varyings i) : SV_Target &#123; float4 norTex &#x3D; SAMPLE_TEXTURE2D(_NormalTex, sampler_NormalTex, i.uv.zw); float3 positionWS &#x3D; float3(i.tangentWS.w, i.BtangentWS.w, i.normalWS.w); float3x3 T2W &#x3D; &#123;i.tangentWS.xyz, i.BtangentWS.xyz, i.normalWS.xyz&#125;; float3 normalTS &#x3D; UnpackNormalScale(norTex, _NormalScale); normalTS.z &#x3D; pow(1 - pow(normalTS.x, 2) - pow(normalTS.y, 2), 0.5f); &#x2F;&#x2F;规范化 float3 normalWS &#x3D; mul(normalTS, T2W); float3 viewDirWS &#x3D; normalize(_WorldSpaceCameraPos.xyz - positionWS); Light myLight &#x3D; GetMainLight(); float3 lightDir &#x3D; normalize(myLight.direction); float4 col &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv.xy); float halfLambert &#x3D; dot(normalWS, lightDir) * 0.5f + 0.5f; float3 diffuse &#x3D; myLight.color * col.xyz * halfLambert; float3 specular &#x3D; myLight.color * _SpecularColor.rgb * pow(dot(normalize(viewDirWS + lightDir), normalWS), _Gloss); return float4(diffuse + specular, col.a); &#125; ENDHLSL Pass &#123; Tags&#123; &quot;LightMode&quot; &#x3D; &quot;UniversalForward&quot; &#125; HLSLPROGRAM #pragma vertex vert #pragma fragment frag ENDHLSL &#125; &#125;&#125; 总结 规范化向量一般用normalize，在不想影响xy轴情况下可以使用勾股定理自己计算另一个轴的值 UnpackNormal，UnpackNormalScale mul(), 矩阵相乘 为了节省空间，可以将一些值藏在部分多余参数中，比如这次代码中，将世界空间坐标xyz分别写在切线，副切线，法线的w值上 渐变纹理基础思路不适用常规的模型uv，而是使用lambert/halflambert的值作为x轴或y轴，对渐变纹理图进行采样 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273Shader &quot;Unlit&#x2F;Ramp&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; _RampTex(&quot;RampTex&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); TEXTURE2D(_RampTex); SAMPLER(sampler_RampTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _RampTex_ST; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float4 normalOS:NORMAL; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; float3 normalWS :TEXCOORD1; &#125;; Varyings vert(Attributes i) &#123; Varyings o; o.positionHS &#x3D; TransformObjectToHClip(i.positionOS); o.uv &#x3D; TRANSFORM_TEX(i.uv, _MainTex); o.normalWS &#x3D; normalize(TransformObjectToWorldNormal(i.normalOS)); return o; &#125; float4 frag(Varyings i) : SV_Target &#123; float4 col &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv); Light light &#x3D; GetMainLight(); float3 lightDir &#x3D; normalize(light.direction); float3 normalWS &#x3D; normalize(i.normalWS); float halfLambert &#x3D; dot(lightDir, normalWS) * 0.5f + 0.5f; float4 ramp &#x3D; SAMPLE_TEXTURE2D(_RampTex, sampler_RampTex, float2(halfLambert, 0.5f)); return ramp * col * float4(light.color, 1); &#125; ENDHLSL Pass &#123; HLSLPROGRAM #pragma vertex vert #pragma fragment frag ENDHLSL &#125; &#125;&#125; AlphaTest基础简介使用clip，在片元着色器对裁剪一些像素 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970Shader &quot;Unlit&#x2F;AlphaTest&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; _BaseColor(&quot;BaseColor&quot;,Color) &#x3D; (1,1,1,1) [HDR]_BurnColor(&quot;BurnColor&quot;,Color) &#x3D; (1,1,1,1) _Cutoff (&quot;Cutoff&quot;, Range(0,1)) &#x3D; 0.5 &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;TransparentCutout&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot; &quot;Queue&quot; &#x3D; &quot;AlphaTest&quot; &#125; HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); TEXTURE2D(_RampTex); SAMPLER(sampler_RampTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _BaseColor; float4 _BurnColor; float _Cutoff; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; &#125;; Varyings vert(Attributes i) &#123; Varyings o; o.positionHS &#x3D; TransformObjectToHClip(i.positionOS); o.uv &#x3D; TRANSFORM_TEX(i.uv, _MainTex); return o; &#125; float4 frag(Varyings i) : SV_Target &#123; float4 col &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv) * _BaseColor; &#x2F;&#x2F; step(_Cutoff, col.r) &#x3D; (_Cutoff &lt;&#x3D; col.r ? 1 : 0) clip(step(_Cutoff, col.r) - 0.01); col &#x3D; lerp(col, _BurnColor, step(col.r, saturate(_Cutoff + 0.1))) ; return col; &#125; ENDHLSL Pass &#123; HLSLPROGRAM #pragma vertex vert #pragma fragment frag ENDHLSL &#125; &#125;&#125; 总结 clip()， 参数小于0则裁剪 step(a,b) 等价于 a &lt;= b ? 1 : 0， 用于优化shader代码中的if，else AlphaBlend基础简介 关闭深度写入 渲染队列，渲染类型设置成Transparent 透明的 设置Blend 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778Shader &quot;Unlit&#x2F;AlphaBlend&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; _AlphaTex(&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot;&#123;&#125; _BaseColor(&quot;BaseColor&quot;,Color) &#x3D; (1,1,1,1) &#125; SubShader &#123; Tags&#123; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalRenderPipeline&quot; &quot;IgnoreProjector&quot; &#x3D; &quot;True&quot; &quot;RenderType&quot; &#x3D; &quot;Transparent&quot; &quot;Queue&quot; &#x3D; &quot;Transparent&quot; &#125; ZWrite Off Blend SrcAlpha OneMinusSrcAlpha HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); TEXTURE2D(_AlphaTex); SAMPLER(sampler_AlphaTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _AlphaTex_ST; float4 _BaseColor; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float4 uv : TEXCOORD0; &#125;; Varyings vert(Attributes i) &#123; Varyings o; o.positionHS &#x3D; TransformObjectToHClip(i.positionOS); o.uv.xy &#x3D; TRANSFORM_TEX(i.uv, _MainTex); o.uv.zw &#x3D; TRANSFORM_TEX(i.uv, _AlphaTex); return o; &#125; float4 frag(Varyings i) : SV_Target &#123; float4 col &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv.xy) * _BaseColor; float alpha &#x3D; SAMPLE_TEXTURE2D(_AlphaTex, sampler_AlphaTex, i.uv.zw).a; return float4(col.rgb, alpha); &#125; ENDHLSL Pass &#123; HLSLPROGRAM #pragma vertex vert #pragma fragment frag ENDHLSL &#125; &#125;&#125; 总结 “IgnoreProjector” = “True”， 忽视 多光源基础 首先需要获取多光源，通过GetAdditionalLightsCount()，GetAdditionalLight(index, positionWS)两个函数处理多光源 将主光源计算后的颜色，叠加所有叠加光源颜色输出 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687Shader &quot;Unlit&#x2F;MulLight&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; _BaseColor (&quot;BaseColor&quot;, Color) &#x3D; (1,1,1,1) [KeywordEnum(ON,OFF)]_ADD_LIGHT(&quot;AddLight&quot;,float) &#x3D; 1 &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _BaseColor; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float4 normalOS:NORMAL; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; float3 normalWS:TEXCOORD1; float3 positionWS:TEXCOORD2; &#125;; Varyings Vert(Attributes i) &#123; Varyings o; o.positionHS &#x3D; TransformObjectToHClip(i.positionOS.xyz); o.uv &#x3D; TRANSFORM_TEX(i.uv, _MainTex); o.normalWS &#x3D; TransformObjectToWorldNormal(i.normalOS.xyz, true); o.positionWS &#x3D; TransformObjectToWorld(i.positionOS.xyz); return o; &#125; float4 Frag(Varyings i) :SV_Target&#123; Light mylight &#x3D; GetMainLight(); real4 LightColor &#x3D; real4(mylight.color, 1); float3 lightDir &#x3D; normalize(mylight.direction); float3 normalWS &#x3D; normalize(i.normalWS); float halfLambert &#x3D; dot(normalWS, lightDir) * 0.5f + 0.5f; float4 color &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv) * _BaseColor * halfLambert * LightColor; &#x2F;&#x2F; AddLight float4 addLightColor &#x3D; float4(0,0,0,1); #if _ADD_LIGHT_ON int lightCount &#x3D; GetAdditionalLightsCount(); for (int index &#x3D; 0; index &lt; lightCount; index++) &#123; Light light &#x3D; GetAdditionalLight(index, i.positionWS); addLightColor +&#x3D; (dot(normalWS, normalize(light.direction)) * 0.5f + 0.5f) * real4(light.color, 1) * light.distanceAttenuation * light.shadowAttenuation; &#125; #endif return color + addLightColor; &#125; ENDHLSL Pass &#123; Tags&#123; &quot;LightMode&quot; &#x3D; &quot;UniversalForward&quot; &#125; HLSLPROGRAM #pragma vertex Vert #pragma fragment Frag #pragma shader_feature _ADD_LIGHT_ON _ADD_LIGHT_OFF ENDHLSL &#125; &#125;&#125; 总结 shader枚举开关：[KeywordEnum(ON,OFF)]_ADD_LIGHT(“AddLight”,float) = 1 //定义shader中的枚举 只有ON,OFF两个选项#pragma shader_feature _ADD_LIGHT_ON _ADD_LIGHT_OFF //定义shader_feature 规则：参数名_枚举名 （需要把所有定义的选项都放进去）#if _ADD_LIGHT_ON … #endif 使用 阴影投射和接收基础 投射使用官方写好的阴影投射Pass UsePass “Universal Render Pipeline/Lit/ShadowCaster”使用官方写好的 不支持SRP Batcher， 因此自己写阴影投射Pass参考”Packages/com.unity.render-pipelines.universal/Shaders/ShadowCasterPass.hlsl” 接收TransformWorldToShadowCoord(i.positionWS) //获得shadowcoordGetMainLight(shadowcoord).shadowAttenuation //获得阴影值#pragma multi_compile _ _MAIN_LIGHT_SHADOWS //开启阴影#pragma multi_compile _ _MAIN_LIGHT_SHADOWS_CASCADE //级联阴影#pragma multi_compile _ _SHADOWS_SOFT //柔化阴影，得到软阴影 额外光源阴影接收 代码 主光源阴影接收Shader 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081Shader &quot;Unlit&#x2F;Shadow&quot;&#123; Properties &#123; _MainTex(&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; _GlossColor(&quot;BaseColor&quot;, Color) &#x3D; (1,1,1,1) _Gloss(&quot;Gloss&quot;, Range(1, 256)) &#x3D; 1 &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _GlossColor; float _Gloss; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float4 normalOS:NORMAL; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; float3 normalWS:TEXCOORD1; float3 positionWS:TEXCOORD2; &#125;; Varyings Vert(Attributes i) &#123; Varyings o; o.positionHS &#x3D; TransformObjectToHClip(i.positionOS.xyz); o.uv &#x3D; TRANSFORM_TEX(i.uv, _MainTex); o.positionWS &#x3D; TransformObjectToWorld(i.positionOS.xyz); o.normalWS &#x3D; TransformObjectToWorldNormal(i.normalOS.xyz, true); return o; &#125; float4 Frag(Varyings i) :SV_Target&#123; Light mylight &#x3D; GetMainLight(TransformWorldToShadowCoord(i.positionWS)); real4 LightColor &#x3D; real4(mylight.color, 1); float3 lightDir &#x3D; normalize(mylight.direction); float3 viewDir &#x3D; normalize(_WorldSpaceCameraPos.xyz - i.positionWS); float3 worldNormal &#x3D; normalize(i.normalWS); float phong &#x3D; pow(max(dot(reflect(-lightDir, worldNormal), viewDir), 0), _Gloss); float blinnPhong &#x3D; pow(max(dot(normalize(lightDir + viewDir), worldNormal), 0), _Gloss); float4 col &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv); float4 diffuse &#x3D; LightColor * col * max(dot(lightDir, worldNormal), 0) * mylight.shadowAttenuation; float4 specular &#x3D; _GlossColor * blinnPhong * LightColor * mylight.shadowAttenuation; return float4(specular.rgb + diffuse.rgb, col.a); &#125; ENDHLSL Pass &#123; Tags&#123; &quot;LightMode&quot; &#x3D; &quot;UniversalForward&quot; &#125; HLSLPROGRAM #pragma vertex Vert #pragma fragment Frag #pragma multi_compile _ _MAIN_LIGHT_SHADOWS &#x2F;&#x2F;开启阴影 #pragma multi_compile _ _MAIN_LIGHT_SHADOWS_CASCADE &#x2F;&#x2F;级联阴影 #pragma multi_compile _ _SHADOWS_SOFT &#x2F;&#x2F;柔化阴影，得到软阴影 ENDHLSL &#125; UsePass &quot;Universal Render Pipeline&#x2F;Lit&#x2F;ShadowCaster&quot; &#125;&#125; 额外光源阴影接收Shader 1234567891011121314151617181920&#x2F;&#x2F; AddLightfloat4 addLightColor &#x3D; float4(0, 0, 0, 1);#if _ADD_LIGHT_ON #if defined(SHADOWS_SHADOWMASK) &amp;&amp; defined(LIGHTMAP_ON) half4 shadowMask &#x3D; inputData.shadowMask; #elif !defined (LIGHTMAP_ON) half4 shadowMask &#x3D; unity_ProbesOcclusion; #else half4 shadowMask &#x3D; half4(1, 1, 1, 1); #endif int lightCount &#x3D; GetAdditionalLightsCount(); for (int index &#x3D; 0; index &lt; lightCount; index++) &#123; Light light &#x3D; GetAdditionalLight(index, i.positionWS, shadowMask); addLightColor +&#x3D; (dot(normalWS, normalize(light.direction)) * 0.5f + 0.5f) * real4(light.color, 1) * light.distanceAttenuation * light.shadowAttenuation; &#125;#endif 主光源投射阴影 12345678910111213141516171819202122232425262728293031323334353637&#x2F;&#x2F;参考 &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;Shaders&#x2F;ShadowCasterPass.hlsl&quot;Pass&#123; Name &quot;ShadowCaster&quot; Tags&#123;&quot;LightMode&quot; &#x3D; &quot;ShadowCaster&quot;&#125; ZWrite On ZTest LEqual ColorMask 0 HLSLPROGRAM #pragma vertex VertShadowCaster #pragma fragment FragShadowCaster Varyings VertShadowCaster(Attributes i) &#123; Varyings o; o.uv &#x3D; TRANSFORM_TEX(i.uv, _MainTex); float3 positionWS &#x3D; TransformObjectToWorld(i.positionOS.xyz); float3 normalWS &#x3D; TransformObjectToWorldNormal(i.normalOS.xyz, true); Light light &#x3D; GetMainLight(); o.positionHS &#x3D; TransformWorldToHClip(ApplyShadowBias(positionWS, normalWS, light.direction.xyz)); #if UNITY_REVERSED_Z o.positionHS.z &#x3D; min(o.positionHS.z, o.positionHS.w * UNITY_NEAR_CLIP_VALUE); #else o.positionHS.z &#x3D; max(o.positionHS.z, o.positionHS.w * UNITY_NEAR_CLIP_VALUE); #endif return o; &#125; half4 FragShadowCaster(Varyings i) :SV_Target &#123; return 0; &#125; ENDHLSL&#125; 总结 查看源码思路，最终需要得到阴影值，从Light中看到shadowAttenuation是我们需要的通过 GetMainLight(shadowcoord) 或者 GetMainLight(float4 shadowCoord, float3 positionWS, half4 shadowMask) 获得的阴影会被赋值调用了Shadow.hlsl中的 MainLightRealtimeShadow 以及 MainLightShadow查看其中判断的宏可以发现需要 MAIN_LIGHT_CALCULATE_SHADOWS， 全局搜索发现开启 _MAIN_LIGHT_SHADOWS 后会定义MAIN_LIGHT_CALCULATE_SHADOWS函数网里面跟进可以看到_MAIN_LIGHT_SHADOWS_CASCADE _SHADOWS_SOFT 还有其他一些宏，看使用情况开启即可 GetMainLight需要参数 shadowcoord， 在Shadow.hlsl 查找shadowcoord 可以找到几个函数，再看参数和调用地方，可以确认TransformWorldToShadowCoord函数我们可以直接使用 初次看URP源码，先记录下在初次使用时寻找关键函数的思路 序列帧基础 将一张序列帧图片分块，按块采样显示，间隔一定时间切换下一块 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465Shader &quot;Unlit&#x2F;SequenceFrame&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; _FrameRate(&quot;FrameRate&quot;,float) &#x3D; 10 _Sheet(&quot;Sheet&quot;,Vector) &#x3D; (1,1,1,1) &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float _FrameRate; float4 _Sheet; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; &#125;; Varyings Vert(Attributes i) &#123; Varyings o; o.positionHS &#x3D; TransformObjectToHClip(i.positionOS.xyz); o.uv &#x3D; TRANSFORM_TEX(i.uv, _MainTex); return o; &#125; float4 Frag(Varyings i) :SV_Target&#123; float2 uv &#x3D; 0; uv.x &#x3D; i.uv.x &#x2F; _Sheet.x + frac(floor(_Time.y * _FrameRate) &#x2F; _Sheet.x); uv.y &#x3D; i.uv.y &#x2F; _Sheet.y + 1 - frac(floor(_Time.y * _FrameRate &#x2F; _Sheet.x) &#x2F; _Sheet.y); return SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, uv); &#125; ENDHLSL Pass &#123; Tags&#123; &quot;LightMode&quot; &#x3D; &quot;UniversalForward&quot; &#125; HLSLPROGRAM #pragma vertex Vert #pragma fragment Frag ENDHLSL &#125; &#125;&#125; 总结 frac函数：取小数，frac(x) = x - (int)x; _Time获取变化时间 图片左下角为(0,0)点，因此y轴需要反转一下 广告牌基础实现效果：正方向始终朝向相机思路：顶点着色器变换顶点坐标，使得渲染出来的模型朝向相机 将所有操作都放在模型空间，使用模型空间坐标作为锚点，则锚点为(0,0,0) 根据顶点坐标的(x,y,z)重新计算顶点坐标 pos = center + right * x + up * y + z * fwd; 需要得出right, up, fwd，fwd为朝向相机的方向，通过相机朝向可以推出，需要求right和up，假设我们的广告牌正方向都朝上则up = (0, 1, 0)， right = cross(up, fwd)再重新计算up = cross(fwd, right) 得到up,right,fwd， 将计算结果作为模型空间顶点坐标进行其他计算即可 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283Shader &quot;Unlit&#x2F;ADS&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; _BaseColor (&quot;BaseColor&quot;, Color) &#x3D; (1,1,1,1) &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Transparent&quot; &quot;RenderType&quot; &#x3D; &quot;Transparent&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; ZWrite Off Blend SrcAlpha OneMinusSrcAlpha Cull Off HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _BaseColor; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float4 normalOS:NORMAL; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; float3 normalWS:TEXCOORD1; &#125;; Varyings Vert(Attributes i) &#123; Varyings o; &#x2F;&#x2F;重新计算顶点坐标 float3 cameraPosOS &#x3D; TransformWorldToObject(_WorldSpaceCameraPos.xyz); float3 fwd &#x3D; normalize(cameraPosOS); float3 up &#x3D; abs(fwd.y) &lt; 0.99f ? float3(0, 1, 0) : float3(0, 0, 1); float3 right &#x3D; normalize(cross(up, fwd)); up &#x3D; normalize(cross(fwd, right)); float3x3 Matrix &#x3D; &#123; right, up, fwd &#125;; float3 posOS &#x3D; mul(i.positionOS.xyz, Matrix); &#x2F;&#x2F; &#x3D; i.positionOS.x * right + i.positionOS.y * up + i.positionOS.z * fwd o.positionHS &#x3D; TransformObjectToHClip(posOS); o.uv &#x3D; TRANSFORM_TEX(i.uv, _MainTex); o.normalWS &#x3D; TransformObjectToWorldNormal(i.normalOS.xyz, true); return o; &#125; float4 Frag(Varyings i) :SV_Target&#123; Light mylight &#x3D; GetMainLight(); real4 LightColor &#x3D; real4(mylight.color, 1); float3 lightDir &#x3D; normalize(mylight.direction); float lambert &#x3D; dot(normalize(i.normalWS), lightDir); float halfLambert &#x3D; lambert * 0.5f + 0.5f; float4 color &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv); return color * _BaseColor * halfLambert * LightColor; &#125; ENDHLSL Pass &#123; Tags&#123; &quot;LightMode&quot; &#x3D; &quot;UniversalForward&quot; &#125; HLSLPROGRAM #pragma vertex Vert #pragma fragment Frag ENDHLSL &#125; &#125;&#125; 总结 广告牌核心思想就是做顶点变换 使用cross叉乘得垂直向量，unity中的叉乘使用左手法则 玻璃效果基础 首先需要抓屏，Build-in中通过grab pass或者传入RT，URP中_CameraColorTexture得到当前屏幕同等分辨率的图像，它在opaque模型和skybox渲染完成之后抓取通过:TEXTURE2D(_CameraColorTexture);SAMPLER(sampler_CameraColorTexture);获取使用_CameraColorTexture必须设置中打开Opaque Texture选项 采样屏幕图像需要屏幕坐标：ComputeScreenPos(positionCS);i.screenPos.xy / i.screenPos.w; //获取屏幕UV，需要做齐次除法 应用法线，对采样点进行偏移，可以使用世界空间法线或者切线空间法线世界空间的法线由世界空间确定，会随着模型的旋转而变化；切线空间的法线不随着模型的旋转而变换； 由于_CameraColorTextrue在Opaque之后，但在Transparent之前，因此透明物体无法显示因此可以利用RenderFeature，Render Objects设置一个”LightMode”=”Grab”，在透明物体之后执行的透明队列 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103Shader &quot;Unlit&#x2F;Glass&quot;&#123; Properties &#123; _NormalTex(&quot;Normal&quot;,2D) &#x3D; &quot;bump&quot;&#123;&#125; _NormalScale(&quot;NormalScale&quot;,Range(0,1)) &#x3D; 1 _BaseColor(&quot;BaseColor&quot;,Color) &#x3D; (1,1,1,1) _Amount(&quot;amount&quot;,float) &#x3D; 100 [KeywordEnum(WS_N,TS_N)]_NORMAL_STAGE(&quot;NormalStage&quot;,float) &#x3D; 1 &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Transparent&quot; &quot;RenderType&quot; &#x3D; &quot;Transparent&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot; &#125; HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_NormalTex); SAMPLER(sampler_NormalTex); SAMPLER(_CameraColorTexture); float4 _CameraColorTexture_TexelSize;&#x2F;&#x2F;该向量是非本shader独有，不能放在常量缓冲区 CBUFFER_START(UnityPerMaterial) float4 _NormalTex_ST; float _NormalScale; float _Amount; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float4 normalOS:NORMAL; float4 tangentOS:TANGENT; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; float4 normalWS:TEXCOORD1; float4 tangentWS:TEXCOORD2; float4 BtangentWS:TEXCOORD3; float4 screenPos:TEXCOORD4; &#125;; Varyings vert(Attributes i) &#123; Varyings o; &#x2F;&#x2F; 使用以下函数 快速获取坐标，法线变换结果 ShaderVariablesFunctions.hlsl 引用 Core.hlsl即可 VertexPositionInputs input &#x3D; GetVertexPositionInputs(i.positionOS.xyz); o.positionHS &#x3D; input.positionCS; VertexNormalInputs normalInput &#x3D; GetVertexNormalInputs(i.normalOS, i.tangentOS); o.normalWS.xyz &#x3D; normalInput.normalWS; o.tangentWS.xyz &#x3D; normalInput.tangentWS; o.BtangentWS.xyz &#x3D; normalInput.bitangentWS; &#x2F;&#x2F; 存一下世界空间坐标 o.tangentWS.w &#x3D; input.positionWS.x; o.BtangentWS.w &#x3D; input.positionWS.y; o.normalWS.w &#x3D; input.positionWS.z; o.screenPos &#x3D; ComputeScreenPos(input.positionCS); o.uv &#x3D; TRANSFORM_TEX(i.uv, _NormalTex); return o; &#125; float4 frag(Varyings i) : SV_Target &#123; float4 norTex &#x3D; SAMPLE_TEXTURE2D(_NormalTex, sampler_NormalTex, i.uv); float3 normalTS &#x3D; UnpackNormalScale(norTex, _NormalScale); normalTS.z &#x3D; pow(1 - pow(normalTS.x, 2) - pow(normalTS.y, 2), 0.5f); &#x2F;&#x2F;规范化#if _NORMAL_STAGE_WS_N float3 positionWS &#x3D; float3(i.tangentWS.w, i.BtangentWS.w, i.normalWS.w); float3x3 T2W &#x3D; &#123; i.tangentWS.xyz, i.BtangentWS.xyz, i.normalWS.xyz &#125;; float3 normalWS &#x3D; mul(normalTS, T2W); float2 SS_bias &#x3D; normalWS.xy * _Amount * _CameraColorTexture_TexelSize.xy;&#x2F;&#x2F;世界空间的法线由世界空间确定，会随着模型的旋转而变化#else float2 SS_bias &#x3D; normalTS.xy * _Amount * _CameraColorTexture_TexelSize.xy;&#x2F;&#x2F;切线空间的法线不随着模型的旋转而变换#endif float2 SS_texcoord &#x3D; i.screenPos.xy &#x2F; i.screenPos.w;&#x2F;&#x2F;获取屏幕UV float4 glassColor &#x3D; tex2D(_CameraColorTexture, SS_texcoord + SS_bias);&#x2F;&#x2F;把最终的颜色输出到屏幕即可 return glassColor; &#125; ENDHLSL Pass &#123; Tags&#123; &quot;LightMode&quot; &#x3D; &quot;Grab&quot; &#125; HLSLPROGRAM #pragma vertex vert #pragma fragment frag #pragma shader_feature_local _NORMAL_STAGE_WS_N ENDHLSL &#125; &#125;&#125; 总结 使用ShaderVariablesFunctions.hlsl中的通用函数：GetVertexPositionInputs(positionOS)，GetVertexNormalInputs(normalOS, tangentOS)快速计算法线坐标变换以及法线 _CameraColorTexture只在运行时生效 _TextureName_TexelSize：图片的宽高，这个声明在CBuffer外x = 1.0/widthy = 1.0/heightz = widthw = height _TextureName_ST：图片的Tilling 和 Offsetx,y 对应 Tilling的 x,yz,w 对应 Offset的 x,y 利用RenderFeature设置特殊的渲染方式 屏幕深度，护盾特效基础 获取屏幕深度图 _CameraDepthTexture;TEXUTRE2D(_CameraDepthTexture); SAMPLER(sampler_CameraDepthTexture);通过屏幕坐标采样：ComputeScreenPos(positionCS); 别忘了使用时齐次除法，这步操作通常再原片着色器 Linear01Depth(depth, _ZBufferParams) 获取0-1线性深度 URPSetting中需要打开深度图 护盾特效：需实现菲尼尔效果，扫光效果菲尼尔效果 基础公式：F0 + (1 - F0) * pow(1.0 - dot(viewDirWS, normalWS), 5.0);F0为材质的菲尼尔系数通用沿y轴扫光效果：float flow=saturate(pow(1-abs(frac(i.positionWS.y0.3-_Time.y0.2)-0.5),10)0.3);float4 flowcolor=flow_emissioncolor; 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495Shader &quot;Unlit&#x2F;DepthShield&quot;&#123; Properties &#123; _MainTex(&quot;MainTex&quot;,2D) &#x3D; &quot;white&quot;&#123;&#125; _BaseColor(&quot;BaseColor&quot;,Color) &#x3D; (1,1,1,1) _F0 (&quot;F0&quot;, float) &#x3D; 0.01 _EmissionColor (&quot;EmissionColor&quot;, Color) &#x3D; (1,1,1,1) _Speed(&quot;Speed&quot;, float) &#x3D; 1 &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Transparent&quot; &quot;RenderType&quot; &#x3D; &quot;Transparent&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot; &#125; Blend SrcAlpha OneMinusSrcAlpha HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); TEXTURE2D(_CameraDepthTexture); SAMPLER(sampler_CameraDepthTexture); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _BaseColor; float4 _EmissionColor; float _F0; float _Speed; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float4 normalOS:NORMAL; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; float4 screenPos:TEXCOORD1; float3 positionWS:TEXCOORD2; float3 normalWS:TEXCOORD3; &#125;; Varyings vert(Attributes i) &#123; Varyings o; &#x2F;&#x2F; 使用以下函数 快速获取坐标，法线变换结果 ShaderVariablesFunctions.hlsl 引用 Core.hlsl即可 VertexPositionInputs input &#x3D; GetVertexPositionInputs(i.positionOS.xyz); o.positionHS &#x3D; input.positionCS; o.positionWS &#x3D; input.positionWS; o.screenPos &#x3D; ComputeScreenPos(input.positionCS); o.uv &#x3D; TRANSFORM_TEX(i.uv, _MainTex); o.normalWS &#x3D; normalize(TransformObjectToWorldNormal(i.normalOS.xyz)); return o; &#125; float4 frag(Varyings i) : SV_Target &#123; float4 col &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv) * _BaseColor; float2 uvSS &#x3D; i.screenPos.xy &#x2F; i.screenPos.w;&#x2F;&#x2F;获取屏幕UV float4 depthColor &#x3D; SAMPLE_TEXTURE2D(_CameraDepthTexture, sampler_CameraDepthTexture, uvSS); float screenDepth &#x3D; Linear01Depth(depthColor.a, _ZBufferParams); float depth &#x3D; i.positionHS.z; depth &#x3D; Linear01Depth(depth, _ZBufferParams);&#x2F;&#x2F;得到模型的线性深度 float edge &#x3D; saturate(depth - screenDepth + 0.005) * 100;&#x2F;&#x2F;计算接触光 float3 viewDirWS &#x3D; normalize(_WorldSpaceCameraPos.xyz - i.positionWS); float fresnel &#x3D; _F0 + (1 - _F0) * pow(1 - dot(viewDirWS, i.normalWS), 5); float flow &#x3D; saturate(pow(1 - abs(frac(i.positionWS.y * 0.3 - _Time.y * _Speed) - 0.5), 10) * 0.3); float flow1 &#x3D; saturate(pow(1 - abs(frac(i.positionWS.y * 0.5 - _Time.y * _Speed) - 0.5), 10) * 0.5); float flow2 &#x3D; saturate(pow(1 - abs(frac(i.positionWS.y * 0.7 - _Time.y * _Speed) - 0.5), 10) * 0.7); float4 flowcolor &#x3D; (flow + flow1 + flow2) * _EmissionColor; return float4(col.rgb, fresnel + edge) + flowcolor; &#125; ENDHLSL Pass &#123; Tags&#123; &quot;LightMode&quot; &#x3D; &quot;UniversalForward&quot; &#125; HLSLPROGRAM #pragma vertex vert #pragma fragment frag ENDHLSL &#125; &#125;&#125; 总结 _ZBufferParams: UnityInput.hlsl 官方链接// x = 1-far/near// y = far/near// z = x/far// w = y/far#if UNITY_REVERSED_Z// x = -1+far/near// y = 1// z = x/far// w = 1/far 特定物体描边效果链接urp管线的自学hlsl之路 第二十五篇 Render Feature制作特定模型外描边 基础整理一下描边过程： 获得基础纯色图：按层级/渲染队列，过滤出需要渲染的物体，返回纯色 对纯色图进行模糊操作 纯色模糊图 - 纯色图：得到外描边图 实际上模糊图 - 纯色图，内部边缘也会有一段负数渐变区，将其显示出来相当于内描边，取绝对值abs，可以得到内外描边效果图 将描边图与原图叠加输出 代码 基础纯色图：绘制之前需要设置一下输出目标：ConfigureTarget(temp);最终是要将物体绘制出来：context.DrawRenderers(renderingData.cullResults, ref draw, ref filter);设置FilteringSettings filter = new FilteringSettings(queue, layer);设置DrawingSettings draw = CreateDrawingSettings(shaderTag, ref renderingData, renderingData.cameraData.defaultOpaqueSortFlags); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&#x2F;&#x2F;第一个pass 绘制纯色的图像 class DrawSoildColorPass : ScriptableRenderPass &#123; Setting mysetting &#x3D; null; OutlineRenderFeather SelectOutline &#x3D; null; ShaderTagId shaderTag &#x3D; new ShaderTagId(&quot;DepthOnly&quot;);&#x2F;&#x2F;只有在这个标签LightMode对应的shader才会被绘制 FilteringSettings filter; public DrawSoildColorPass(Setting setting, OutlineRenderFeather render) &#123; mysetting &#x3D; setting; SelectOutline &#x3D; render; renderPassEvent &#x3D; setting.passEvent; &#x2F;&#x2F;过滤设定 RenderQueueRange queue &#x3D; new RenderQueueRange(); queue.lowerBound &#x3D; Mathf.Min(setting.QueueMax, setting.QueueMin); queue.upperBound &#x3D; Mathf.Max(setting.QueueMax, setting.QueueMin); filter &#x3D; new FilteringSettings(queue, setting.layer); &#125; public override void Configure(CommandBuffer cmd, RenderTextureDescriptor cameraTextureDescriptor) &#123; int temp &#x3D; Shader.PropertyToID(&quot;_MyTempColor1&quot;); RenderTextureDescriptor desc &#x3D; cameraTextureDescriptor; cmd.GetTemporaryRT(temp, desc); SelectOutline.solidcolorID &#x3D; temp; ConfigureTarget(temp); &#x2F;&#x2F;设置它的输出RT ConfigureClear(ClearFlag.All, Color.black); &#125; public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) &#123; mysetting.mat.SetColor(&quot;_SoildColor&quot;, mysetting.color); CommandBuffer cmd &#x3D; CommandBufferPool.Get(&quot;提取固有色pass&quot;); &#x2F;&#x2F;绘制设定 var draw &#x3D; CreateDrawingSettings(shaderTag, ref renderingData, renderingData.cameraData.defaultOpaqueSortFlags); draw.overrideMaterial &#x3D; mysetting.mat; draw.overrideMaterialPassIndex &#x3D; 0; &#x2F;&#x2F;开始绘制（准备好了绘制设定和过滤设定） context.DrawRenderers(renderingData.cullResults, ref draw, ref filter); context.ExecuteCommandBuffer(cmd); CommandBufferPool.Release(cmd); &#125; &#125; 获取原图renderer.cameraColorTarget; 12345678910public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData)&#123; if(setting.mat !&#x3D; null) &#123; RenderTargetIdentifier sour &#x3D; renderer.cameraColorTarget; &#x2F;&#x2F;原图 renderer.EnqueuePass(_DrawSoildColorPass); _DrawBlurPass.Setup(sour); renderer.EnqueuePass(_DrawBlurPass); &#125;&#125; 模糊图拿到基础纯色图，进行模糊即可，模糊操作可以参考高品质后处理：十种图像模糊算法的总结与实现后处理效果汇总 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class DrawBlurPass : ScriptableRenderPass &#123; Setting setting &#x3D; null; OutlineRenderFeather SelectOutline &#x3D; null; RenderTargetIdentifier sour; BlurBlitter _blurBlitter &#x3D; new BlurBlitter(); public DrawBlurPass(Setting setting, OutlineRenderFeather render) &#123; this.setting &#x3D; setting; SelectOutline &#x3D; render; renderPassEvent &#x3D; setting.passEvent; &#125; public void Setup(RenderTargetIdentifier sour) &#123; this.sour &#x3D; sour; if (this.setting.ColorType &#x3D;&#x3D; Setting.EColorType.INcolorON) &#123; this.setting.mat.EnableKeyword(&quot;_INCOLORON&quot;); this.setting.mat.DisableKeyword(&quot;_INCOLOROFF&quot;); &#125; else &#123; this.setting.mat.EnableKeyword(&quot;_INCOLOROFF&quot;); this.setting.mat.DisableKeyword(&quot;_INCOLORON&quot;); &#125; &#125; public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) &#123; CommandBuffer cmd &#x3D; CommandBufferPool.Get(&quot;颜色计算&quot;); RenderTextureDescriptor renderTextureDescriptor &#x3D; renderingData.cameraData.cameraTargetDescriptor; int SourID &#x3D; Shader.PropertyToID(&quot;_SourTex&quot;); cmd.GetTemporaryRT(SourID, renderTextureDescriptor); cmd.CopyTexture(sour, SourID); &#x2F;&#x2F;模糊处理 int BlurID &#x3D; Shader.PropertyToID(&quot;_BlurTex&quot;); cmd.GetTemporaryRT(BlurID, renderTextureDescriptor); _blurBlitter.SetSource(BlurID, renderTextureDescriptor); _blurBlitter.downSample &#x3D; 1; _blurBlitter.blurScale &#x3D; setting.blur; _blurBlitter.iteratorCount &#x3D; setting.passloop; _blurBlitter.blurType &#x3D; BlurType.Box; _blurBlitter.Render(cmd); cmd.Blit(SelectOutline.solidcolorID, sour, setting.mat, 1);&#x2F;&#x2F;在第1个pass里合并所有图像 cmd.ReleaseTemporaryRT(SelectOutline.solidcolorID); cmd.ReleaseTemporaryRT(SourID); cmd.ReleaseTemporaryRT(BlurID); context.ExecuteCommandBuffer(cmd); &#125; &#125; 合并图像两个Pass都比较简单，不多说明了1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798Shader &quot;Unlit&#x2F;Outline&quot;&#123; Properties &#123; _MainTex(&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; _SoildColor(&quot;SoildColor&quot;,Color) &#x3D; (1,1,1,1) &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); TEXTURE2D(_SourTex); SAMPLER(sampler_SourTex); TEXTURE2D(_BlurTex); SAMPLER(sampler_BlurTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _SoildColor; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; &#125;; ENDHLSL &#x2F;&#x2F; Pass 0 纯色 Pass &#123; Tags&#123; &quot;LightMode&quot; &#x3D; &quot;UniversalForward&quot; &#125; HLSLPROGRAM #pragma vertex Vert #pragma fragment Frag Varyings Vert(Attributes i) &#123; Varyings o; o.positionHS &#x3D; TransformObjectToHClip(i.positionOS.xyz); o.uv &#x3D; TRANSFORM_TEX(i.uv, _MainTex); return o; &#125; float4 Frag(Varyings i) :SV_Target&#123; return _SoildColor; &#125; ENDHLSL &#125; &#x2F;&#x2F; Pass 1 合并图像 Pass &#123; Tags&#123; &quot;LightMode&quot; &#x3D; &quot;UniversalForward&quot; &#125; HLSLPROGRAM #pragma vertex Vert1 #pragma fragment Frag1 #pragma multi_compile_local _INCOLORON _INCOLOROFF Varyings Vert1(Attributes i) &#123; Varyings o; o.positionHS &#x3D; TransformObjectToHClip(i.positionOS.xyz); o.uv &#x3D; TRANSFORM_TEX(i.uv, _MainTex); return o; &#125; float4 Frag1(Varyings i) :SV_Target&#123; float4 blur &#x3D; SAMPLE_TEXTURE2D(_BlurTex, sampler_BlurTex, i.uv); float4 sour &#x3D; SAMPLE_TEXTURE2D(_SourTex, sampler_SourTex, i.uv); float4 soild &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv); real4 color;#if _INCOLORON color &#x3D; abs(blur - soild) + sour;#elif _INCOLOROFF color &#x3D; saturate(blur - soild) + sour;#endif return color; &#125; ENDHLSL &#125; &#125;&#125; 总结 获取基础纯色图的过程，是一个基础过滤物体到渲染的过程，可以参考URP源码RenderObjectsPass.cs 边缘检测描边基础参考Unity Shader入门精要，12.3，13.4章节 基础边缘检测 卷积：通常为22,33的方形区域，每个格子对应一个权重值，采样一个像素点时，对其周围方形空间采样按权重值叠加后再除以个数得到当前像素值 常见的边缘检测算子：Roberts，Prewitt，Sobel等 得到两个方向的梯度值，Gx，GyG = sqrt(GxGx,GyGy); 通常优化开方： G = abs(Gx) + abs(Gy)G 值表示梯度值，梯度值越大表示越在边缘 检测结果分析这种方式检测，会产生很多我们不希望的边缘线，如光照影响的，法线影响的，阴影影响的等 通过深度和深度法线上进行边缘检测 需要获取深度图，以及深度法线图，通过_CameraDepthTexture可以获得深度图，但是URP不支持深度法线图因此需要获得深度法线图：自定义RenderFeather，在不透明物体渲染之前使用”Hidden/Internal-DepthNormalsTexture”渲染一次，将图片存为”_CameraDepthNormalsTexture” _CameraDepthNormalsTexture.xyz存法线信息，_CameraDepthNormalsTexture.w存深度信息，UnityCG.cginc中定义： DecodeFloatRG 解码深度：线性深度 = z + w/255 _CameraDepthNormalsTexutre.xyz法线信息并非真实法线，需要对其进行解码操作获得观察空间法线UnityCG.cginc中定义：DecodeViewNormalStereo 镜像对比方式：如像素(x,y+1)与(x,y-1),(x+1,y)与(x-1,y)比较法线以及深度是否相同，相同返回1，不同返回0，代码里对应CheckSame函数，小于一定范围则视为相同 检测结果分析可以明显看到这种方式比第一种方式减少了很多不必要的边缘线 代码 基础边缘检测 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104Shader &quot;Unlit&#x2F;OutlinePPS&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; _EdgeColor (&quot;EdgeColor&quot;, Color) &#x3D; (1,1,1,1) _EdgeOnly (&quot;EdgeOnly&quot;,Range(0,1)) &#x3D; 1 _BackgroundColor (&quot;BackgroundColor&quot;, Color) &#x3D; (1,1,1,1) &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; Cull Off ZWrite Off ZTest Always HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _MainTex_TexelSize; float4 _EdgeColor; float4 _BackgroundColor; float _EdgeOnly; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv[9] : TEXCOORD0; &#125;; Varyings Vert(Attributes i) &#123; Varyings o; o.positionHS &#x3D; TransformObjectToHClip(i.positionOS.xyz); &#x2F;&#x2F; 3*3区域uv o.uv[0] &#x3D; i.uv + _MainTex_TexelSize.xy * (-1, -1); o.uv[1] &#x3D; i.uv + _MainTex_TexelSize.xy * (0, -1); o.uv[2] &#x3D; i.uv + _MainTex_TexelSize.xy * (1, -1); o.uv[3] &#x3D; i.uv + _MainTex_TexelSize.xy * (-1, 0); o.uv[4] &#x3D; i.uv + _MainTex_TexelSize.xy * (0, 0); o.uv[5] &#x3D; i.uv + _MainTex_TexelSize.xy * (1, 0); o.uv[6] &#x3D; i.uv + _MainTex_TexelSize.xy * (-1, 1); o.uv[7] &#x3D; i.uv + _MainTex_TexelSize.xy * (0, 1); o.uv[8] &#x3D; i.uv + _MainTex_TexelSize.xy * (1, 1); return o; &#125; float luminance(float3 color) &#123; return 0.2125*color.r + 0.7154*color.g + 0.0721*color.b; &#125; &#x2F;&#x2F; 主要用于描边检测 float sobel(Varyings i)&#x2F;&#x2F;定义索伯检测函数 &#123; const float Gx[9] &#x3D; &#123; -1,-2,-1,0,0,0,1,2,1 &#125;; const float Gy[9] &#x3D; &#123; -1,0,1,-2,0,2,-1,0,1 &#125;; float texColor &#x3D; 0; float edgeX &#x3D; 0; float edgeY &#x3D; 0; for (int it &#x3D; 0; it &lt; 9; it++) &#123; texColor &#x3D; luminance(SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv[it])); edgeX +&#x3D; texColor * Gx[it]; edgeY +&#x3D; texColor * Gy[it]; &#125; return 1 - abs(edgeX) - abs(edgeY); &#125; float4 Frag(Varyings i) :SV_Target&#123; float edge &#x3D; sobel(i); float4 color &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv[4]); float4 color1 &#x3D; lerp(_EdgeColor, color, edge); float4 color2 &#x3D; lerp(_EdgeColor, _BackgroundColor, edge); return lerp(color1, color2, _EdgeOnly); &#125; ENDHLSL Pass &#123; HLSLPROGRAM #pragma vertex Vert #pragma fragment Frag ENDHLSL &#125; &#125;&#125; 通过深度和深度法线边缘检测 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139Shader &quot;Unlit&#x2F;OutlinePPSDepth&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; _EdgeColor (&quot;EdgeColor&quot;, Color) &#x3D; (1,1,1,1) _EdgeOnly (&quot;EdgeOnly&quot;,Range(0,1)) &#x3D; 1 _BackgroundColor (&quot;BackgroundColor&quot;, Color) &#x3D; (1,1,1,1) _SampleDistance(&quot;SampleDistance&quot;,Range(0,1)) &#x3D; 1 _SensitivityDepth (&quot;SensitivityDepth&quot;,Range(0,3)) &#x3D; 1 _SensitivityNormals (&quot;SensitivityNormals&quot;,Range(0,3)) &#x3D; 1 &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; Cull Off ZWrite Off ZTest Always HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); TEXTURE2D(_CameraDepthNormalsTexture); SAMPLER(sampler_CameraDepthNormalsTexture); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _MainTex_TexelSize; float4 _EdgeColor; float4 _BackgroundColor; float _EdgeOnly; float _SampleDistance; float _SensitivityDepth; float _SensitivityNormals; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; &#125;; Varyings Vert(Attributes i) &#123; Varyings o; o.positionHS &#x3D; TransformObjectToHClip(i.positionOS.xyz); o.uv &#x3D; i.uv; return o; &#125; float CheckSame(float2 centerNormal, float centerDepth, float2 sampleNormal, float sampleDepth) &#123; float2 diffNormal &#x3D; abs(centerNormal - sampleNormal) * _SensitivityNormals; float diffDepth &#x3D; abs(centerDepth - sampleDepth) * _SensitivityDepth; int isSameNormal &#x3D; (diffNormal.x + diffNormal.y) &lt; 0.1f; int isSameDepth &#x3D; diffDepth &lt; 0.1 * centerNormal; return isSameNormal * isSameDepth ? 1.0 : 0.0; &#125; float DecodeFloatRG(float2 enc) &#123; float2 kDecodeDot &#x3D; float2(1.0, 1 &#x2F; 255.0); return dot(enc, kDecodeDot); &#125; float3 DecodeViewNormalStereo(float4 enc4) &#123; float kScale &#x3D; 1.7777; float3 nn &#x3D; enc4.xyz * float3(2 * kScale, 2 * kScale, 0) + float3(-kScale, -kScale, 1); float g &#x3D; 2.0 &#x2F; dot(nn.xyz, nn.xyz); float3 n; n.xy &#x3D; g * nn.xy; n.z &#x3D; g - 1; return n; &#125; float sobel(Varyings i) &#123; float2 uv[9]; float2 normal[9]; float depth[9]; uv[0] &#x3D; i.uv + _SampleDistance * _MainTex_TexelSize.xy * (-1, -1); uv[1] &#x3D; i.uv + _SampleDistance * _MainTex_TexelSize.xy * (0, -1); uv[2] &#x3D; i.uv + _SampleDistance * _MainTex_TexelSize.xy * (1, -1); uv[3] &#x3D; i.uv + _SampleDistance * _MainTex_TexelSize.xy * (-1, 0); uv[4] &#x3D; i.uv + _SampleDistance * _MainTex_TexelSize.xy * (0, 0); uv[5] &#x3D; i.uv + _SampleDistance * _MainTex_TexelSize.xy * (1, 0); uv[6] &#x3D; i.uv + _SampleDistance * _MainTex_TexelSize.xy * (-1, 1); uv[7] &#x3D; i.uv + _SampleDistance * _MainTex_TexelSize.xy * (0, 1); uv[8] &#x3D; i.uv + _SampleDistance * _MainTex_TexelSize.xy * (1, 1); for (int it &#x3D; 0; it &lt; 9; it++) &#123; real4 depthnormalTex &#x3D; SAMPLE_TEXTURE2D(_CameraDepthNormalsTexture, sampler_CameraDepthNormalsTexture, uv[it]); normal[it] &#x3D; depthnormalTex.xy; &#x2F;&#x2F;临时法线 没使用DecodeViewNormalStereo，使用后有问题... depth[it] &#x3D; DecodeFloatRG(depthnormalTex.zw); &#x2F;&#x2F; depthnormalTex.z * 1.0 + depthnormalTex.w &#x2F; 255.0; &#x2F;&#x2F;得到线性深度 &#125; float edge &#x3D; 1; edge *&#x3D; CheckSame(normal[0], depth[0], normal[8], depth[8]); edge *&#x3D; CheckSame(normal[1], depth[1], normal[7], depth[7]); edge *&#x3D; CheckSame(normal[2], depth[2], normal[6], depth[6]); edge *&#x3D; CheckSame(normal[3], depth[3], normal[5], depth[5]); return edge; &#125; float4 Frag(Varyings i) :SV_Target&#123; float edge &#x3D; sobel(i); float4 color &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv); float4 mainColor &#x3D; lerp(_EdgeColor, color, edge); float4 noMainColor &#x3D; lerp(_EdgeColor, _BackgroundColor, edge); return lerp(mainColor, noMainColor, _EdgeOnly); &#125; ENDHLSL Pass &#123; HLSLPROGRAM #pragma vertex Vert #pragma fragment Frag ENDHLSL &#125; &#125;&#125; 深度法线RenderFeather 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105using UnityEngine;using UnityEngine.Rendering;using UnityEngine.Rendering.Universal;&#x2F;&#x2F;&#x2F; &lt;summary&gt;&#x2F;&#x2F;&#x2F; 获取深度法线&#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt;public class DepthNormalsRenderFeather : ScriptableRendererFeature&#123; class DepthNormalsRenderPass : ScriptableRenderPass &#123; private RenderTargetHandle destination &#123; get; set; &#125; private Material depthNormalsMaterial &#x3D; null; private FilteringSettings m_FilteringSettings; ShaderTagId m_ShaderTagId &#x3D; new ShaderTagId(&quot;DepthOnly&quot;); public DepthNormalsRenderPass(RenderQueueRange renderQueueRange, LayerMask layerMask, Material material) &#123; m_FilteringSettings &#x3D; new FilteringSettings(renderQueueRange, layerMask); this.depthNormalsMaterial &#x3D; material; &#125; public void Setup(RenderTargetHandle destination) &#123; this.destination &#x3D; destination; &#125; public override void Configure(CommandBuffer cmd, RenderTextureDescriptor cameraTextureDescriptor) &#123; RenderTextureDescriptor descriptor &#x3D; cameraTextureDescriptor; descriptor.depthBufferBits &#x3D; 32; descriptor.colorFormat &#x3D; RenderTextureFormat.ARGB32; cmd.GetTemporaryRT(destination.id, descriptor, FilterMode.Point); ConfigureTarget(destination.Identifier()); ConfigureClear(ClearFlag.All, Color.black); &#125; &#x2F;&#x2F; Here you can implement the rendering logic. &#x2F;&#x2F; Use &lt;c&gt;ScriptableRenderContext&lt;&#x2F;c&gt; to issue drawing commands or execute command buffers &#x2F;&#x2F; https:&#x2F;&#x2F;docs.unity3d.com&#x2F;ScriptReference&#x2F;Rendering.ScriptableRenderContext.html &#x2F;&#x2F; You don&#39;t have to call ScriptableRenderContext.submit, the render pipeline will call it at specific points in the pipeline. public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) &#123; CommandBuffer cmd &#x3D; CommandBufferPool.Get(&quot;深度法线获取pass&quot;); using (new ProfilingSample(cmd, &quot;DepthNormals Prepass&quot;)) &#123; context.ExecuteCommandBuffer(cmd); cmd.Clear(); var sortFlags &#x3D; renderingData.cameraData.defaultOpaqueSortFlags; var drawSettings &#x3D; CreateDrawingSettings(m_ShaderTagId, ref renderingData, sortFlags); drawSettings.perObjectData &#x3D; PerObjectData.None; ref CameraData cameraData &#x3D; ref renderingData.cameraData; Camera camera &#x3D; cameraData.camera; if (cameraData.isStereoEnabled) context.StartMultiEye(camera); drawSettings.overrideMaterial &#x3D; depthNormalsMaterial; context.DrawRenderers(renderingData.cullResults, ref drawSettings, ref m_FilteringSettings); cmd.SetGlobalTexture(&quot;_CameraDepthNormalsTexture&quot;, destination.id); &#125; context.ExecuteCommandBuffer(cmd); CommandBufferPool.Release(cmd); &#125; &#x2F;&#x2F; Cleanup any allocated resources that were created during the execution of this render pass. public override void OnCameraCleanup(CommandBuffer cmd) &#123; if (destination !&#x3D; RenderTargetHandle.CameraTarget) &#123; cmd.ReleaseTemporaryRT(destination.id); destination &#x3D; RenderTargetHandle.CameraTarget; &#125; &#125; &#125; DepthNormalsRenderPass m_ScriptablePass; RenderTargetHandle depthNormalsTexture; Material depthNormalsMaterial; &#x2F;&#x2F;&#x2F; &lt;inheritdoc&#x2F;&gt; public override void Create() &#123; depthNormalsMaterial &#x3D; CoreUtils.CreateEngineMaterial(&quot;Hidden&#x2F;Internal-DepthNormalsTexture&quot;); m_ScriptablePass &#x3D; new DepthNormalsRenderPass(RenderQueueRange.opaque, -1, depthNormalsMaterial); &#x2F;&#x2F; Configures where the render pass should be injected. m_ScriptablePass.renderPassEvent &#x3D; RenderPassEvent.AfterRenderingPrePasses; depthNormalsTexture.Init(&quot;_CameraDepthNormalsTexture&quot;); &#125; &#x2F;&#x2F; Here you can inject one or multiple render passes in the renderer. &#x2F;&#x2F; This method is called when setting up the renderer once per-camera. public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) &#123; m_ScriptablePass.Setup(depthNormalsTexture); renderer.EnqueuePass(m_ScriptablePass); &#125;&#125; 总结 URP并不支持深度法线图，通过RenderFeather自己生成一张并设置为全局变量 代码中并没有使用DecodeViewNormalStereo函数，在测试过程中使用DecodeViewNormalStereo解码，实际效果不知道为什么出现问题(待解决)但是可以直接使用为解码的法线xy，因为计算过程xy与解码后成正比，不影响实际结果 科幻扫描效果链接urp管线的自学hlsl之路 第二十三篇 科幻扫描效果前篇urp管线的自学hlsl之路 第二十四篇 科幻扫描效果后篇 基础 首先要知道这是一个后处理，我们要做的是在屏幕上画线，再附加扫描再屏幕上画线条需要区分可画区域与不可画区域，通过深度图来区分，只有有深度的地方才需要画线画线需要与世界坐标系的x，y，z轴对应，目前我们不知道屏幕图像上的一点在世界坐标系的位置，因此第一步需要计算屏幕像素点在世界坐标的实际位置，即重建世界坐标系。 世界坐标通过深度值，相机世界坐标以及一个朝向确定： positionWS = _WorldSpaceCameraPos + depth * Direction; 求：Direction这个过程相当于NDC反运算，通过near，far，fov计算 相机到近平面四个顶点的向量计算过程：height = near * tan(fov / 2);width = height * camera.aspect; //aspect为屏幕高宽比fwd = camera.fwd * near;right = camera.right * width;up = camera.up * height;四个向量为：BottomLeft = fwd - right - up;BottomRight = fwd + right - up;UpLeft = fwd - right + up;UpRight = fwd + right + up;将结果线性变换：float size = BottomLeft.magnitude / near;BottomLeft = BottomLeft.normalize * size;BottomRight = BottomRight.normalize * size;UpLeft = UpLeft.normalize * size;UpRight = UpRight.normalize * size;将结果通过RenderFeature传入材质中。 基于x,y,z轴画线： uv从左下角(0,0)到右上角(1,1)，将屏幕划分为四个区域，分别取上面以及计算好的向量这时候将渲染屏幕大小的片，其对应有四个顶点，按照uv划分设置朝向，在片元着色器中，每个像素得到的朝向是经过四个顶点朝向插值完的结果，因此得到相机到像素世界坐标的朝向以及长度12345678910int t &#x3D; 0;if (i.uv.x &lt; 0.5 &amp;&amp; i.uv.y &lt; 0.5) &#x2F;&#x2F; 左下 t &#x3D; 0;else if (i.uv.x &gt; 0.5 &amp;&amp; i.uv.y &lt; 0.5) &#x2F;&#x2F; 右下 t &#x3D; 1;else if (i.uv.x &gt; 0.5 &amp;&amp; i.uv.y &gt; 0.5) &#x2F;&#x2F; 左上 t &#x3D; 2; else &#x2F;&#x2F; 右上 t &#x3D; 3;o.Direction &#x3D; _Matrix[t].xyz; 通过上面的分析得到向量后，能直接得到positionWS = _WorldSpaceCameraPos + depth * Direction + float3(0.01,0.01,0.01); //增加一点偏移是画出线显示在实际物体上面输出positionWS查看效果：重新构建的世界坐标系将屏幕划分成四块将positionWS取frac，0-1：变成条状了使用step裁剪掉大部分0.98：最后就变成了线，可以看到3种类型线，分别对应x，y，z轴赋予颜色：线条变得更加明显了，这些线就代表世界坐标重构之后的x，y，z轴，其对应间隔为112float3 Line &#x3D; step(0.98, frac(positionWS));float3 LineColor &#x3D; Line.x * _ColorX + Line.y * _ColorY + Line.z * _ColorZ; 描边：通过上面学习的基于屏幕深度，深度法线做描边检测即可 扫描效果：类似上面做过的护盾扫描效果float flow=saturate(pow(1-abs(frac(i.positionWS.y0.3-_Time.y0.2)-0.5),10)0.3);对其魔改一下，原来的效果为，0-1-0的渐变，扫描时我们通常使用1-0渐变，因此舍弃一部分渐变：float mask=saturate(pow(abs(frac(positionWS.x + _Time.y0.2)-0.75),10)*0.3); 代码 RenderFeature 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158using UnityEngine;using UnityEngine.Rendering;using UnityEngine.Rendering.Universal;&#x2F;&#x2F;&#x2F; &lt;summary&gt;&#x2F;&#x2F;&#x2F; 科幻扫描效果&#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt;public class ScanRenderFeather : ScriptableRendererFeature&#123; class ScanRenderPass : ScriptableRenderPass &#123; private Setting setting; private RenderTargetIdentifier source; private Material mat; public void Setup(Setting setting) &#123; this.setting &#x3D; setting; mat &#x3D; new Material(setting.shader); renderPassEvent &#x3D; setting.Event; &#125; public void Set(RenderTargetIdentifier source) &#123; this.source &#x3D; source; mat.SetColor(&quot;_ColorX&quot;, setting.ColorX); mat.SetColor(&quot;_ColorY&quot;, setting.ColorY); mat.SetColor(&quot;_ColorZ&quot;, setting.ColorZ); mat.SetColor(&quot;_ColorEdge&quot;, setting.ColorEdge); mat.SetColor(&quot;_OutlineColor&quot;, setting.ColorOutline); mat.SetFloat(&quot;_Width&quot;, setting.Width); mat.SetFloat(&quot;_Spacing&quot;, setting.Spacing); mat.SetFloat(&quot;_Speed&quot;, setting.Speed); mat.SetFloat(&quot;_EdgeSample&quot;, setting.EdgeSample); mat.SetFloat(&quot;_NormalSensitivity&quot;, setting.NormalSensitivity); mat.SetFloat(&quot;_DepthSensitivity&quot;, setting.DepthSensitivity); if (setting.AXIS &#x3D;&#x3D; AxisType.X) &#123; mat.DisableKeyword(&quot;_AXIS_Y&quot;); mat.DisableKeyword(&quot;_AXIS_Z&quot;); mat.EnableKeyword(&quot;_AXIS_X&quot;); &#125; else if (setting.AXIS &#x3D;&#x3D; AxisType.Y) &#123; mat.DisableKeyword(&quot;_AXIS_Z&quot;); mat.DisableKeyword(&quot;_AXIS_X&quot;); mat.EnableKeyword(&quot;_AXIS_Y&quot;); &#125; else &#123; mat.DisableKeyword(&quot;_AXIS_X&quot;); mat.DisableKeyword(&quot;_AXIS_Y&quot;); mat.EnableKeyword(&quot;_AXIS_Z&quot;); &#125; &#125; &#x2F;&#x2F; This method is called before executing the render pass. &#x2F;&#x2F; It can be used to configure render targets and their clear state. Also to create temporary render target textures. &#x2F;&#x2F; When empty this render pass will render to the active camera render target. &#x2F;&#x2F; You should never call CommandBuffer.SetRenderTarget. Instead call &lt;c&gt;ConfigureTarget&lt;&#x2F;c&gt; and &lt;c&gt;ConfigureClear&lt;&#x2F;c&gt;. &#x2F;&#x2F; The render pipeline will ensure target setup and clearing happens in a performant manner. public override void OnCameraSetup(CommandBuffer cmd, ref RenderingData renderingData) &#123; &#125; &#x2F;&#x2F; Here you can implement the rendering logic. &#x2F;&#x2F; Use &lt;c&gt;ScriptableRenderContext&lt;&#x2F;c&gt; to issue drawing commands or execute command buffers &#x2F;&#x2F; https:&#x2F;&#x2F;docs.unity3d.com&#x2F;ScriptReference&#x2F;Rendering.ScriptableRenderContext.html &#x2F;&#x2F; You don&#39;t have to call ScriptableRenderContext.submit, the render pipeline will call it at specific points in the pipeline. public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) &#123; int temp &#x3D; Shader.PropertyToID(&quot;temp&quot;); CommandBuffer cmd &#x3D; CommandBufferPool.Get(&quot;扫描特效&quot;); RenderTextureDescriptor desc &#x3D; renderingData.cameraData.cameraTargetDescriptor; Camera cam &#x3D; renderingData.cameraData.camera; float height &#x3D; cam.nearClipPlane * Mathf.Tan(Mathf.Deg2Rad * cam.fieldOfView * 0.5f); Vector3 up &#x3D; cam.transform.up * height; Vector3 right &#x3D; cam.transform.right * height * cam.aspect; Vector3 forward &#x3D; cam.transform.forward * cam.nearClipPlane; Vector3 ButtomLeft &#x3D; forward - right - up; Vector3 ButtomRight &#x3D; forward + right - up; Vector3 TopRight &#x3D; forward + right + up; Vector3 TopLeft &#x3D; forward - right + up; float scale &#x3D; ButtomLeft.magnitude &#x2F; cam.nearClipPlane; ButtomLeft &#x3D; ButtomLeft.normalized * scale; ButtomRight &#x3D; ButtomRight.normalized * scale; TopRight &#x3D; TopRight.normalized * scale; TopLeft &#x3D; TopLeft.normalized * scale; Matrix4x4 MATRIX &#x3D; new Matrix4x4(); MATRIX.SetRow(0, ButtomLeft); MATRIX.SetRow(1, ButtomRight); MATRIX.SetRow(2, TopRight); MATRIX.SetRow(3, TopLeft); mat.SetMatrix(&quot;_Matrix&quot;, MATRIX); cmd.GetTemporaryRT(temp, desc); cmd.Blit(source, temp, mat); cmd.Blit(temp, source); context.ExecuteCommandBuffer(cmd); cmd.ReleaseTemporaryRT(temp); CommandBufferPool.Release(cmd); &#125; &#x2F;&#x2F; Cleanup any allocated resources that were created during the execution of this render pass. public override void OnCameraCleanup(CommandBuffer cmd) &#123; &#125; &#125; ScanRenderPass m_ScriptablePass; public enum AxisType &#123; X, Y, Z &#125; [System.Serializable] public class Setting &#123; public Shader shader &#x3D; null; public RenderPassEvent Event &#x3D; RenderPassEvent.AfterRenderingTransparents; [ColorUsage(true, true)] public Color ColorX &#x3D; Color.white; [ColorUsage(true, true)] public Color ColorY &#x3D; Color.white; [ColorUsage(true, true)] public Color ColorZ &#x3D; Color.white; [ColorUsage(true, true)] public Color ColorEdge &#x3D; Color.white; [ColorUsage(true, true)] public Color ColorOutline &#x3D; Color.white; [Range(0, 0.2f), Tooltip(&quot;线框宽度&quot;)] public float Width &#x3D; 0.1f; [Range(0.1f, 10), Tooltip(&quot;线框间距&quot;)] public float Spacing &#x3D; 1; [Range(0, 10), Tooltip(&quot;滚动速度&quot;)] public float Speed &#x3D; 1; [Range(0, 3), Tooltip(&quot;边缘采样半径&quot;)] public float EdgeSample &#x3D; 1; [Range(0, 3), Tooltip(&quot;法线灵敏度&quot;)] public float NormalSensitivity &#x3D; 1; [Range(0, 3), Tooltip(&quot;深度灵敏度&quot;)] public float DepthSensitivity &#x3D; 1; [Tooltip(&quot;特效方向&quot;)] public AxisType AXIS; &#125; [SerializeField] public Setting setting; public override void Create() &#123; m_ScriptablePass &#x3D; new ScanRenderPass(); m_ScriptablePass.Setup(setting); &#125; public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) &#123; m_ScriptablePass.Set(renderer.cameraColorTarget); renderer.EnqueuePass(m_ScriptablePass); &#125;&#125; Shader 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153Shader &quot;Unlit&#x2F;Scan&quot;&#123; Properties &#123; [HideInInspector] _MainTex(&quot;MainTex&quot;,2D) &#x3D; &quot;white&quot;&#123;&#125; [HDR]_ColorX(&quot;ColorX&quot;,Color) &#x3D; (1,1,1,1) [HDR]_ColorY(&quot;ColorY&quot;,Color) &#x3D; (1,1,1,1) [HDR]_ColorZ(&quot;ColorZ&quot;,Color) &#x3D; (1,1,1,1) [HDR]_ColorEdge(&quot;ColorEdge&quot;,Color) &#x3D; (1,1,1,1) _Width(&quot;Width&quot;,float) &#x3D; 0.02 _Spacing(&quot;Spacing&quot;,float) &#x3D; 1 _Speed(&quot;Speed&quot;,float) &#x3D; 1 _EdgeSample(&quot;EdgeSample&quot;,Range(0,1)) &#x3D; 1 _NormalSensitivity(&quot;NormalSensitivity&quot;,float) &#x3D; 1 _DepthSensitivity(&quot;DepthSensitivity&quot;,float) &#x3D; 1 [HDR]_OutlineColor(&quot;OutlineColr&quot;,Color) &#x3D; (1,1,1,1) &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; Cull Off ZWrite Off ZTest Always HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); &#x2F;&#x2F; 使用_CameraDepthNormalsTexture取代深度图 &#x2F;&#x2F; _CameraDepthNormalsTexture.xy法线信息，zw存深度信息，线性深度&#x3D;z+w&#x2F;255 TEXTURE2D(_CameraDepthTexture); SAMPLER(sampler_CameraDepthTexture); TEXTURE2D(_CameraDepthNormalsTexture); SAMPLER(sampler_CameraDepthNormalsTexture); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _MainTex_TexelSize; real4 _ColorX; real4 _ColorY; real4 _ColorZ; real4 _ColorEdge; real4 _OutlineColor; float _Width; float _Spacing; float _Speed; float _EdgeSample; float _NormalSensitivity; float _DepthSensitivity; CBUFFER_END float4x4 _Matrix; struct Attributes &#123; float4 positionOS:POSITION; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; float3 Direction:TEXCOORD1; &#125;; Varyings Vert(Attributes i) &#123; Varyings o; o.positionHS &#x3D; TransformObjectToHClip(i.positionOS.xyz); o.uv &#x3D; i.uv; int t &#x3D; 0; if (i.uv.x &lt; 0.5 &amp;&amp; i.uv.y &lt; 0.5) t &#x3D; 0; else if (i.uv.x &gt; 0.5 &amp;&amp; i.uv.y &lt; 0.5) t &#x3D; 1; else if (i.uv.x &gt; 0.5 &amp;&amp; i.uv.y &gt; 0.5) t &#x3D; 2; else t &#x3D; 3; o.Direction &#x3D; _Matrix[t].xyz; return o; &#125; &#x2F;&#x2F; 主要用于描边检测 int sobel(Varyings i)&#x2F;&#x2F;定义索伯检测函数 &#123; real depth[4]; real2 normal[4]; float2 uv[4];&#x2F;&#x2F;计算采样需要的uv uv[0] &#x3D; i.uv + float2(-1, -1) * _EdgeSample * _MainTex_TexelSize.xy; uv[1] &#x3D; i.uv + float2(1, -1) * _EdgeSample * _MainTex_TexelSize.xy; uv[2] &#x3D; i.uv + float2(-1, 1) * _EdgeSample * _MainTex_TexelSize.xy; uv[3] &#x3D; i.uv + float2(1, 1) * _EdgeSample * _MainTex_TexelSize.xy; for (int t &#x3D; 0; t &lt; 4; t++) &#123; real4 depthnormalTex &#x3D; SAMPLE_TEXTURE2D(_CameraDepthNormalsTexture, sampler_CameraDepthNormalsTexture, uv[t]); normal[t] &#x3D; depthnormalTex.xy;&#x2F;&#x2F;得到临时法线 depth[t] &#x3D; depthnormalTex.z * 1.0 + depthnormalTex.w &#x2F; 255.0;&#x2F;&#x2F;得到线性深度 &#125; &#x2F;&#x2F;depth检测 int Dep &#x3D; abs(depth[0] - depth[3]) * abs(depth[1] - depth[2]) * _DepthSensitivity &gt; 0.01 ? 1 : 0; &#x2F;&#x2F;normal检测 float2 nor &#x3D; abs(normal[0] - normal[3]) * abs(normal[1] - normal[2]) * _NormalSensitivity; int Nor &#x3D; (nor.x + nor.y) &gt; 0.01 ? 1 : 0; return saturate(Dep + Nor); &#125; float4 Frag(Varyings i) :SV_Target&#123; int outline &#x3D; sobel(i); real4 tex &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv); real4 depthnormal &#x3D; SAMPLE_TEXTURE2D(_CameraDepthNormalsTexture, sampler_CameraDepthNormalsTexture, i.uv); float depth01 &#x3D; depthnormal.z * 1.0 + depthnormal.w &#x2F; 255.0; depth01 *&#x3D; _ProjectionParams.z; &#x2F;&#x2F;float depth01 &#x3D; LinearEyeDepth(SAMPLE_TEXTURE2D(_CameraDepthTexture, sampler_CameraDepthTexture, i.uv).x, _ZBufferParams).x; float3 positionWS &#x3D; _WorldSpaceCameraPos + depth01 * i.Direction + float3(0.01, 0.01, 0.01); &#x2F;&#x2F;增加一点偏移是画出线显示在实际物体上面 float3 positionWS01 &#x3D; positionWS * _ZBufferParams.w; float3 Line &#x3D; step(1 - _Width, frac(positionWS &#x2F; _Spacing)); float4 LineColor &#x3D; Line.x * _ColorX + Line.y * _ColorY + Line.z * _ColorZ + outline * _OutlineColor;#ifdef _AXIS_X float mask &#x3D; saturate(pow(abs(frac(positionWS01.x * 10 + _Time.y * 0.1 * _Speed) - 0.53), 10) * 200); float mask2 &#x3D; saturate(pow(abs(frac(positionWS01.x * 10 - _Time.y * 0.1 * _Speed) - 0.47), 10) * 200); float mask3 &#x3D; saturate(pow(abs(frac(positionWS01.z * 10 + _Time.y * 0.1 * _Speed) - 0.53), 10) * 200); float mask4 &#x3D; saturate(pow(abs(frac(positionWS01.z * 10 - _Time.y * 0.1 * _Speed) - 0.47), 10) * 200); mask +&#x3D; mask2 + mask3 + mask4; mask +&#x3D; step(0.95, mask);#elif _AXIS_Y float mask &#x3D; saturate(pow(abs(frac(positionWS01.y * 10 + _Time.y * 0.1 * _Speed) - 0.75), 10) * 10); mask +&#x3D; step(0.95, mask);#elif _AXIS_Z float mask &#x3D; saturate(pow(abs(frac(positionWS01.z * 10 + _Time.y * 0.1 * _Speed) - 0.75), 10) * 10); mask +&#x3D; step(0.95, mask);#endif return tex * saturate(1 - mask) + (LineColor + _ColorEdge) * mask; &#x2F;&#x2F; 扫描加入一个覆盖颜色更真实 &#125; ENDHLSL Pass &#123; HLSLPROGRAM #pragma vertex Vert #pragma fragment Frag #pragma multi_compile_local _AXIS_X _AXIS_Y _AXIS_Z ENDHLSL &#125; &#125;&#125; 总结 通过屏幕像素点获得对应的世界坐标，在后处理中特别实用，如全局雾效，SSAO等 扫描效果与之前护盾扫描类似，扫描公式大概都以这样的为准，在此基础上进行魔改 屏幕炫光，更好的广告牌算法基础 使用模型空间(0,0,0,1)点做MV变换后得相机空间坐标，加上原先顶点的模型偏移，乘P矩阵得最终顶点坐标基础广告牌已经完成，变得简单多了123float4 pivotWS &#x3D; mul(UNITY_MATRIX_M, float4(0, 0, 0, 1));float4 pivotVS &#x3D; mul(UNITY_MATRIX_V, pivotWS);o.positionHS &#x3D; mul(UNITY_MATRIX_P, pivotVS + float4(i.positionOS.xy, 0, 1)); 加入旋转以及缩放控制，目前对顶点进行变换并不会允许缩放以及旋转的控制思路：在模型空间对其x，y坐标做缩放，旋转后(广告牌不需要z值)，再放入顶点变换计算中 二维旋转矩阵：{ cos(a),-sin(a), sin(a),cos(a)} 获得GameObject的世界坐标缩放float ScaleX = length(float3(UNITY_MATRIX_M[0].x, UNITY_MATRIX_M[1].x, UNITY_MATRIX_M[2].x));float ScaleY = length(float3(UNITY_MATRIX_M[0].y, UNITY_MATRIX_M[1].y, UNITY_MATRIX_M[2].y));float ScaleZ = length(float3(UNITY_MATRIX_M[0].z, UNITY_MATRIX_M[1].z, UNITY_MATRIX_M[2].z)); 需要与unity顺序一致：先缩放，后旋转 制作炫光，加入一个渐隐渐现效果 制作渐隐渐现只需要一个值来控制(alpha)，怎么求得alpha 物体中心点周围一个范围， 采样屏幕深度纹理，判断深度值，被遮挡不通过 透明值 = 没被遮挡数 / 采样总数 // alpha = passCount / totalSampleCount; 裁剪空间坐标，透除：pos.xy / pos.w 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109Shader &quot;Unlit&#x2F;ADS Pro&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; [HDR]_BaseColor(&quot;BaseColor&quot;, Color) &#x3D; (1,1,1,1) _Rotate(&quot;Rotate&quot;,Range(0,3.14)) &#x3D; 0 &#125; SubShader &#123; Tags &#123; &quot;Queue&quot; &#x3D; &quot;Overlay&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; Blend One One ZWrite Off ZTest Always HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); TEXTURE2D(_CameraDepthTexture); SAMPLER(sampler_CameraDepthTexture); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _BaseColor; float _Rotate; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; float4 color : COLOR; &#125;; Varyings Vert(Attributes i) &#123; Varyings o; o.uv &#x3D; TRANSFORM_TEX(i.uv, _MainTex); float4 pivotWS &#x3D; mul(UNITY_MATRIX_M, float4(0, 0, 0, 1)); float4 pivotVS &#x3D; mul(UNITY_MATRIX_V, pivotWS); float ScaleX &#x3D; length(float3(UNITY_MATRIX_M[0].x, UNITY_MATRIX_M[1].x, UNITY_MATRIX_M[2].x)); float ScaleY &#x3D; length(float3(UNITY_MATRIX_M[0].y, UNITY_MATRIX_M[1].y, UNITY_MATRIX_M[2].y)); &#x2F;&#x2F;float ScaleZ &#x3D; length(float3(UNITY_MATRIX_M[0].z, UNITY_MATRIX_M[1].z, UNITY_MATRIX_M[2].z)); float2x2 rotateMatrix &#x3D; &#123;cos(_Rotate),-sin(_Rotate),sin(_Rotate),cos(_Rotate)&#125;; float2 pos &#x3D; i.positionOS.xy * float2(ScaleX, ScaleY); pos &#x3D; mul(rotateMatrix, pos); float4 positionVS &#x3D; pivotVS + float4(pos, 0, 1); o.positionHS &#x3D; mul(UNITY_MATRIX_P, positionVS); int sampleCount &#x3D; 3; int axisCount &#x3D; sampleCount * 2 + 1; float totalCount &#x3D; axisCount * axisCount; float sampleRate &#x3D; 0.2;&#x2F;&#x2F;中心区域大小比例 float pivotDepth &#x3D; -pivotVS.z;&#x2F;&#x2F;取相机空间轴心的线性深度 float4 pivotCS &#x3D; mul(UNITY_MATRIX_P, pivotVS); int passCount &#x3D; 0; for (int x &#x3D; -sampleCount; x &lt;&#x3D; sampleCount; ++x) &#123; for (int y &#x3D; -sampleCount; y &lt;&#x3D; sampleCount; ++y) &#123; float2 samplePos &#x3D; pivotCS.xy + o.positionHS.xy * sampleRate * float2(x, y) &#x2F; axisCount; &#x2F;&#x2F;裁剪空间采样坐标 float2 SSuv &#x3D; samplePos &#x2F; o.positionHS.w * 0.5 + 0.5;&#x2F;&#x2F;把裁剪空间手动透除，变换到NDC空间下，并根据当前平台判断是否翻转y轴 #ifdef UNITY_UV_STARTS_AT_TOP SSuv.y &#x3D; 1 - SSuv.y; #endif if (SSuv.x &lt; 0 || SSuv.x&gt;1 || SSuv.y &lt; 0 || SSuv.y&gt;1) continue;&#x2F;&#x2F;如果满足跳出本次循环进入下次循环 float depth &#x3D; SAMPLE_TEXTURE2D_LOD(_CameraDepthTexture, sampler_CameraDepthTexture, SSuv, 0).x; depth &#x3D; LinearEyeDepth(depth, _ZBufferParams); passCount +&#x3D; step(pivotDepth, depth); &#125; &#125; o.color &#x3D; _BaseColor * _BaseColor.a * passCount &#x2F; totalCount; o.color *&#x3D; smoothstep(0.1, 2, pivotDepth); return o; &#125; float4 Frag(Varyings i) :SV_Target&#123; float4 color &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv); return i.color * color; &#125; ENDHLSL Pass &#123; Tags&#123; &quot;LightMode&quot; &#x3D; &quot;UniversalForward&quot; &quot;RenderType&quot; &#x3D; &quot;Overlay&quot; &#125; HLSLPROGRAM #pragma vertex Vert #pragma fragment Frag ENDHLSL &#125; &#125;&#125; 总结 取线性深度可以通过相机空间的-z值获取 判断平台差异，倒转y，UNITY_UV_STARTS_AT_TOP 屏幕空间贴花基础 Unity官方从2021.2版本开始才提供了 Unity URP官方文档2021.2版本 贴花组件 Decal Projector Component Shader使用：Shader Graphs/Decal 使用时打开RenderFeather： Decal VisualEffectGraph粒子系统里提供了内置的ForwardDecal 自己实现一个屏幕空间贴画 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495Shader &quot;Unlit&#x2F;Decal&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; _BaseColor (&quot;BaseColor&quot;, Color) &#x3D; (1,1,1,1) _EdgeStretchPrevent (&quot;EdgeStretchPrevent&quot;, Range(-1,1)) &#x3D; 0 &#125; SubShader &#123; Tags &#123; &quot;Queue&quot; &#x3D; &quot;Transparent-499&quot; &quot;RenderType&quot; &#x3D; &quot;Overlay&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot; &quot;DisableBatch&quot; &#x3D; &quot;True&quot;&#125; Blend SrcAlpha OneMinusSrcAlpha HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); TEXTURE2D(_CameraDepthTexture); SAMPLER(sampler_CameraDepthTexture); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _BaseColor; float _EdgeStretchPrevent; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float4 screenPos : TEXCOORD0; float3 cameraPosOS:TEXCOORD1; float4 cameraVertexDirOS:TEXCOORD2; &#125;; Varyings Vert(Attributes i) &#123; Varyings o; o.positionHS &#x3D; TransformObjectToHClip(i.positionOS.xyz); &#x2F;&#x2F; 与ComputeScreenPos()函数效果相同 &#x2F;*o.screenPos &#x3D; o.positionHS * 0.5f; o.screenPos.xy &#x3D; float2(o.screenPos.x, o.screenPos.y * _ProjectionParams.x) + o.screenPos.w; o.screenPos.zw &#x3D; o.positionHS.zw;*&#x2F; o.screenPos &#x3D; ComputeScreenPos(o.positionHS); float4 posVS &#x3D; mul(UNITY_MATRIX_V, mul(UNITY_MATRIX_M, i.positionOS)); o.cameraVertexDirOS.w &#x3D; -posVS.z; &#x2F;&#x2F;w存线性深度 o.cameraVertexDirOS.xyz &#x3D; mul(UNITY_MATRIX_I_M, mul(UNITY_MATRIX_I_V, float4(posVS.xyz, 0))).xyz; &#x2F;&#x2F;变换回模型空间坐标，但忽略了平移矩阵 o.cameraPosOS &#x3D; mul(UNITY_MATRIX_I_M, mul(UNITY_MATRIX_I_V, float4(0, 0, 0, 1))).xyz;&#x2F;&#x2F;计算模型空间下的相机坐标 return o; &#125; float4 Frag(Varyings i) :SV_Target&#123; float2 uv &#x3D; i.screenPos.xy &#x2F; i.screenPos.w; float depth &#x3D; LinearEyeDepth(SAMPLE_TEXTURE2D(_CameraDepthTexture, sampler_CameraDepthTexture, uv).x, _ZBufferParams); i.cameraVertexDirOS.xyz &#x2F;&#x3D; i.cameraVertexDirOS.w; float3 decalPos &#x3D; i.cameraPosOS + i.cameraVertexDirOS.xyz * depth;&#x2F;&#x2F;模型空间下的计算：相机坐标+相机朝着顶点的射线（已透除）*相机空间的线性深度 float mask &#x3D; (abs(decalPos.x) &lt; 0.5 ? 1 : 0) * (abs(decalPos.y) &lt; 0.5 ? 1 : 0) * (abs(decalPos.z) &lt; 0.5 ? 1 : 0); float3 decalNormal &#x3D; normalize(cross(ddy(decalPos), ddx(decalPos))); mask *&#x3D; decalNormal.y &gt; 0.2 * _EdgeStretchPrevent ? 1 : 0;&#x2F;&#x2F;边缘拉伸的防止阈值 float2 YdecalUV &#x3D; decalPos.xz + 0.5; &#x2F;&#x2F; 模型空间下坐标偏移 -0.5 到 0.5， 因此+0.5使其 0 - 1范围 float4 tex &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, YdecalUV) * mask; return tex; &#125; ENDHLSL Pass &#123; Tags&#123; &quot;LightMode&quot; &#x3D; &quot;UniversalForward&quot; &#125; HLSLPROGRAM #pragma vertex Vert #pragma fragment Frag #pragma target 3.0 ENDHLSL &#125; &#125;&#125; 总结 ddx，ddy函数解释：对屏幕坐标x和y方向的偏导数ddx(v) = 该像素点右边的v值 - 该像素点的v值ddy(v) = 该像素点下面的v值 - 该像素点的v值ddx(float3(1,2,3)) = float3(0,0,0) //因为使用该shader的所有像素 输出的记录值都是 float3(1,2,3)那么差值就为float3(0,0,0)即理解为：ddx(v)，在屏幕上水平方向横跨一个像素的v值变化量，ddy，则在垂直方向上b的变化量 解释：代码中使用 float3 decalNormal = normalize(cross(ddy(decalPos), ddx(decalPos)));拿到模型空间decalPos后，ddy(decalPos)求得其往下的向量，ddx(decalPos)求得往右的向量，相当于得到decalPos在其相对坐标上的的x，y向量，叉乘得到z向量(垂直与两个向量)可以近似理解为：ddx(decalPos) = (u+1,v)求出来的decalPos - (u,v)求出来的decalPos，在使用中相当于pos2-pos1，得到pos1到pos2的向量 防止以后绕晕了再记录一下，以下M，V代表变换矩阵，I_M，I_V代表转置positionVS = mul(v * mul(M, positionOS))； positionOS = mul(I_M, mul(I_V, positionVS);将变换过程理解为： positionOS -&gt; M -&gt; V = positionVS； 那么回去需要原路返回：positionVS -&gt; I_V -&gt; I_M = positionOS; SSAO屏幕空间环境光遮蔽基础理论参考 &#x63;&#111;&#x6d;&#46;&#x75;&#110;&#x69;&#x74;&#x79;&#x2e;&#114;&#101;&#110;&#100;&#x65;&#x72;&#x2d;&#x70;&#x69;&#x70;&#x65;&#x6c;&#x69;&#x6e;&#x65;&#115;&#x2e;&#117;&#110;&#105;&#x76;&#101;&#114;&#x73;&#97;&#108;&#x40;&#49;&#x32;&#46;&#49;&#46;&#49;\\ShaderLibrary\\SSAO.hlsl环境遮罩之SSAO原理URP屏幕空间环境光遮蔽后处理(SSAO)【光线追踪系列十六】基于着色点的正向半球随机方向生成 首先需要明确一点将所有坐标都转换至相机空间操作。 通过屏幕uv获取像素深度值，在裁剪空间中深度值就为其z轴的值，根据uv以及depth重建像素在相机空间的坐标屏幕uv从0到1，裁剪空间uv从-1到1，将uv*2-1，范围变换至-1到1就为裁剪空间xy坐标。通过renderingData.cameraData.GetGPUProjectionMatrix()获得当前相机P矩阵，以及P逆矩阵通过逆矩阵求得VS坐标，进行齐次除法 1234567&#x2F;&#x2F;根据UV和depth，重建像素在viewspace中的坐标float3 ReconstructPositionVS(float2 uv, float depth) &#123; float4 positionInHS &#x3D; float4(uv * 2 - 1, depth, 1); float4 positionVS &#x3D; mul(CustomInvProjMatrix, positionInHS); positionVS &#x2F;&#x3D; positionVS.w; return positionVS.xyz;&#125; 得到当前像素的VS坐标后，需要在沿其法线方向的半球中随机采样点，然后计算对当前像素的ao影响规定半球半径_SampleRadius，采样点数量_SampleCount，随机半球可以参照【光线追踪系列十六】基于着色点的正向半球随机方向生成 123456789101112131415161718float Random(float2 st) &#123; return frac(sin(dot(st, float2(12.9898, 78.233))) * 43758.5453123);&#125;float Random(float x) &#123; return frac(sin(x) * 43758.5453123);&#125;&#x2F;&#x2F; 随机球float3 RandomSphere(float3 positionVS, float index)&#123; float r1 &#x3D; Random(positionVS.xy); float r2 &#x3D; Random(index); float z &#x3D; sqrt(1 - r2); float th &#x3D; 2 * PI * r1; float x &#x3D; cos(th) * sqrt(r2); float y &#x3D; sin(th) * sqrt(r2); return float3(x, y, z);&#125; 先随机一个半球的单位向量，再将其转换至视觉空间，将偏移加载像素VS坐标上，通过偏移后的VS再获得当前屏幕uv，采样该uv随机点的深度值，再重新构建VS坐标 1234567891011float2 ReProjectToUV(float3 positionVS) &#123; float4 positionHS &#x3D; mul(CustomProjMatrix, float4(positionVS, 1)); return (positionHS.xy &#x2F; positionHS.w + 1) * 0.5;&#125;float3 offset &#x3D; RandomSphere(positionVS, it);offset &#x3D; normalize(mul(TBN, offset));float3 samplePositionVS &#x3D; positionVS + offset * _SampleRadius;float2 sampleUV &#x3D; ReProjectToUV(samplePositionVS); float sampleDepth &#x3D; SampleDepth(sampleUV);float3 hitPositionVS &#x3D; ReconstructPositionVS(sampleUV, sampleDepth); 获取到随机采样点后，计算该点对当前像素的ao影响值 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232Shader &quot;Unlit&#x2F;SSAO&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; &#125; SubShader &#123; ZTest Always ZWrite Off Cull Off Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; HLSLINCLUDE #pragma shader_feature __AO_DEBUG__ #pragma shader_feature _Blur #include &quot;Packages&#x2F;com.unity.render-pipelines.core&#x2F;ShaderLibrary&#x2F;Common.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.core&#x2F;ShaderLibrary&#x2F;Filtering.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Input.hlsl&quot; struct Attributes &#123; float4 positionOS : POSITION; float2 uv : TEXCOORD0; UNITY_VERTEX_INPUT_INSTANCE_ID &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; UNITY_VERTEX_OUTPUT_STEREO &#125;; Varyings Vert(Attributes input) &#123; Varyings output; UNITY_SETUP_INSTANCE_ID(input); UNITY_INITIALIZE_VERTEX_OUTPUT_STEREO(output); output.positionHS &#x3D; TransformObjectToHClip(input.positionOS); output.uv &#x3D; input.uv; return output; &#125; ENDHLSL Pass &#123; HLSLPROGRAM #pragma vertex Vert #pragma fragment Frag TEXTURE2D_X_FLOAT(_CameraDepthTexture); TEXTURE2D_X(_MainTex); SAMPLER(sampler_MainTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_TexelSize; float4x4 CustomProjMatrix; float4x4 CustomInvProjMatrix; float _Atten; float _Contrast; float _SampleRadius; int _SampleCount; CBUFFER_END float Random(float2 st) &#123; return frac(sin(dot(st, float2(12.9898, 78.233))) * 43758.5453123); &#125; float Random(float x) &#123; return frac(sin(x) * 43758.5453123); &#125; float3 RandomSampleOffset(float2 uv, float index) &#123; float2 alphaBeta &#x3D; float2(Random(uv) * PI * 2, Random(index) * PI); float2 sin2; float2 cos2; sincos(alphaBeta, sin2, cos2); return float3(cos2.y * cos2.x, sin2.y, cos2.y * sin2.x); &#125; &#x2F;&#x2F;根据UV和depth，重建像素在viewspace中的坐标 float3 ReconstructPositionVS(float2 uv, float depth) &#123; float4 positionInHS &#x3D; float4(uv * 2 - 1, depth, 1); float4 positionVS &#x3D; mul(CustomInvProjMatrix, positionInHS); positionVS &#x2F;&#x3D; positionVS.w; return positionVS.xyz; &#125; float2 ReProjectToUV(float3 positionVS) &#123; float4 positionHS &#x3D; mul(CustomProjMatrix, float4(positionVS, 1)); return (positionHS.xy &#x2F; positionHS.w + 1) * 0.5; &#125; float SampleDepth(float2 uv) &#123; return LOAD_TEXTURE2D_X(_CameraDepthTexture, _MainTex_TexelSize.zw * uv).x; &#125; float4 Frag(Varyings i) :SV_Target&#123; float4 color &#x3D; SAMPLE_TEXTURE2D_X(_MainTex, sampler_MainTex, i.uv); float depth &#x3D; SampleDepth(i.uv); float3 positionVS &#x3D; ReconstructPositionVS(i.uv, depth); float3 tangentVS &#x3D; normalize(ddx(positionVS)); &#x2F;&#x2F;重建法线 float3 normalVS &#x3D; normalize(cross(ddy(positionVS), ddx(positionVS))); &#x2F;&#x2F; 面法线 float3 binormalVS &#x3D; cross(normalVS, tangentVS); float3x3 TBN &#x3D; &#123;tangentVS, binormalVS, normalVS&#125;; float ao &#x3D; 0; float rcpSampleCount &#x3D; rcp(_SampleCount); for (int it &#x3D; 0; it &lt; (int)_SampleCount; ++it) &#123; &#x2F;&#x2F; 随机偏移值 float3 offset &#x3D; RandomSampleOffset(i.uv, it); offset &#x3D; mul(TBN, offset); float3 samplePositionVS &#x3D; positionVS + offset * _SampleRadius * (1 + it) * rcpSampleCount; &#x2F;&#x2F;float4 samplePositionHS &#x3D; mul(CustomProjMatrix, float4(samplePositionVS, 1)); &#x2F;&#x2F;float4 sampleScreenPos &#x3D; ComputeScreenPos(samplePositionHS); &#x2F;&#x2F;ComputeScreenPos需要在顶点着色器使用，在片元计算结果不对劲 &#x2F;&#x2F;float2 sampleUV &#x3D; sampleScreenPos.xy &#x2F; sampleScreenPos.w; float2 sampleUV &#x3D; ReProjectToUV(samplePositionVS); float sampleDepth &#x3D; SampleDepth(sampleUV); float3 hitPositionVS &#x3D; ReconstructPositionVS(sampleUV, sampleDepth); float3 hitOffset &#x3D; hitPositionVS - positionVS; float a &#x3D; max(0, dot(hitOffset, normalVS) - 0.001); &#x2F;&#x2F;0~radius float b &#x3D; dot(hitOffset, hitOffset) + 0.001; &#x2F;&#x2F;0~ radius^2 ao +&#x3D; a * rcp(b); &#x2F;&#x2F; 0 ~ 1&#x2F;radius &#125; ao *&#x3D; _SampleRadius * rcpSampleCount; ao &#x3D; PositivePow(ao * _Atten, _Contrast); ao &#x3D; 1 - saturate(ao); return ao; #if __AO_DEBUG__ || _Blur return float4(ao, ao, ao, 1); #else return ao * color; #endif &#125; ENDHLSL &#125; Pass &#123; HLSLPROGRAM #pragma vertex Vert #pragma fragment FragBlurH #include &quot;..&#x2F;Blur&#x2F;Blur.hlsl&quot; TEXTURE2D_X(_MainTex); SAMPLER(sampler_MainTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_TexelSize; CBUFFER_END float4 FragBlurH(Varyings i) : SV_Target &#123; return BoxBlur(_MainTex,i.uv * _MainTex_TexelSize.zw,2,float2(1,0)); &#125; ENDHLSL &#125; Pass &#123; HLSLPROGRAM #pragma vertex Vert #pragma fragment FragBlurV #include &quot;..&#x2F;Blur&#x2F;Blur.hlsl&quot; TEXTURE2D_X(_MainTex); SAMPLER(sampler_MainTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_TexelSize; CBUFFER_END float4 FragBlurV(Varyings i) : SV_Target &#123; return BoxBlur(_MainTex,i.uv * _MainTex_TexelSize.zw,2,float2(0,1)); &#125; ENDHLSL &#125; Pass &#123; HLSLPROGRAM #pragma vertex Vert #pragma fragment FragComb TEXTURE2D_X(_MainTex); SAMPLER(sampler_MainTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_TexelSize; CBUFFER_END TEXTURE2D_X(_AOTex); SAMPLER(sampler_AOTex); float4 FragComb(Varyings i) : SV_Target &#123; float4 color &#x3D; SAMPLE_TEXTURE2D_X(_MainTex, sampler_MainTex, i.uv); float ao &#x3D; SAMPLE_TEXTURE2D_X(_AOTex, sampler_AOTex, i.uv); #if __AO_DEBUG__ return ao; #else return ao * color; #endif &#125; ENDHLSL &#125; &#125;&#125; 总结屏幕空间操作指南： 通过uv，depth，重构世界坐标，需要InvVP，vp逆矩阵，(相机空间坐标同理) 都先得到裁剪空间坐标再进行对应的变换：positionCS = P * V * M * positionOS 123456float3 ReconstructPositionWS(float2 uv, float depth) &#123; float3 positionCS &#x3D; float3(uv * 2 - 1, depth); float4 positionWS &#x3D; mul(_MatrixInvVP, float4(positionCS, 1)); positionWS &#x2F;&#x3D; positionWS.w; return positionWS.xyz;&#125; 同样可以从世界坐标转换至裁剪坐标CS，裁剪坐标的xy范围(0-1)的uv值，z值为深度值 123456float3 Reproject(float3 positionWS) &#123; float4 positionCS &#x3D; mul(_MatrixVP, float4(positionWS, 1)); positionCS &#x2F;&#x3D; positionCS.w; positionCS.xy &#x3D; (positionCS.xy + 1) * 0.5; return positionCS.xyz;&#125; 裁剪空间得到屏幕uv 1float2 pixelCoord &#x3D; positionCS.xy * _MainTex_TexelSize.zw; SSPR屏幕空间平面反射基础 记录需要平面反射的平面，世界坐标以及法线，针对所有平面都有以下操作(一个坐标一个法线确定一个平面) 通过屏幕uv以及depth，重构世界坐标系 在ComputeShader中做反转变换：将世界坐标沿平面反转，得到新的反转点后再转换至屏幕空间得到uv2 uv2的颜色就是反射uv1的颜色 将ComputShader反转后的图像，用于平面的渲染，渲染是需要判断当前深度》屏幕深度，则渲染图像上的颜色 代码 shader：需要反射的平面，对其反射处理使用的shader 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182Shader &quot;URPLearn&#x2F;PlanarReflection&quot;&#123; Properties &#123; &#125; SubShader &#123; ZTest Always ZWrite Off Cull Off Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; Blend One One HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.core&#x2F;ShaderLibrary&#x2F;Common.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.core&#x2F;ShaderLibrary&#x2F;Filtering.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Input.hlsl&quot; struct Attributes &#123; float4 positionOS : POSITION; float2 uv : TEXCOORD0; UNITY_VERTEX_INPUT_INSTANCE_ID &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; float4 screenPos : TEXCOORD1; UNITY_VERTEX_OUTPUT_STEREO &#125;; Varyings Vert(Attributes input) &#123; Varyings output; UNITY_SETUP_INSTANCE_ID(input); UNITY_INITIALIZE_VERTEX_OUTPUT_STEREO(output); output.positionHS &#x3D; TransformObjectToHClip(input.positionOS); output.uv &#x3D; input.uv; output.screenPos &#x3D; ComputeScreenPos(output.positionHS); return output; &#125; TEXTURE2D(_ReflectionTex); TEXTURE2D(_CameraDepthTexture); SAMPLER(sampler_ReflectionTex); SAMPLER(sampler_CameraDepthTexture); CBUFFER_START(UnityPerMaterial) CBUFFER_END float4 Frag(Varyings i) : SV_Target &#123; float2 screenUV &#x3D; i.screenPos.xy &#x2F; i.screenPos.w; float depth &#x3D; SAMPLE_TEXTURE2D(_CameraDepthTexture, sampler_CameraDepthTexture, screenUV); if (i.positionHS.z &gt;&#x3D; depth) &#123; float4 color &#x3D; SAMPLE_TEXTURE2D_X(_ReflectionTex, sampler_ReflectionTex, screenUV); return color; &#125; else &#123; discard; return float4(0,0,0,0); &#125; &#125; ENDHLSL Pass &#123; HLSLPROGRAM #pragma vertex Vert #pragma fragment Frag ENDHLSL &#125; &#125;&#125; RenderFeather：对标记的平面做反射以及再次渲染 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241using System;using UnityEngine;using UnityEngine.Rendering;using UnityEngine.Rendering.Universal;namespace URPLearn&#123; public class SSPRRenderFeather : ScriptableRendererFeature &#123; class SSPRPlanarRenderPass : ScriptableRenderPass &#123; private Material _material; private SSPRTexGenerator _ssprTexGenerator &#x3D; new SSPRTexGenerator(); private PlanarRendererGroups _planarRendererGroups &#x3D; new PlanarRendererGroups(); public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) &#123; CommandBuffer cmd &#x3D; CommandBufferPool.Get(&quot;SSPR-ReflectionTex&quot;); ReflectPlane.GetVisiblePlanarGroups(_planarRendererGroups); foreach (var group in _planarRendererGroups.PlanarRenderers) &#123; cmd.Clear(); var planarDescriptor &#x3D; group.descriptor; var renderers &#x3D; group.renderers; _ssprTexGenerator.Render(cmd, this.colorAttachment, ref renderingData, ref group.descriptor); cmd.SetRenderTarget(this.colorAttachment, this.depthAttachment); foreach (var rd in renderers) &#123; cmd.DrawRenderer(rd, _material); &#125; _ssprTexGenerator.ReleaseTemporary(cmd); context.ExecuteCommandBuffer(cmd); &#125; cmd.Release(); &#125; public void Setup(Material material, ComputeShader computeShader, bool blur, bool excludeBackground) &#123; _material &#x3D; material; _ssprTexGenerator.BindCS(computeShader); _ssprTexGenerator.enableBlur &#x3D; blur; _ssprTexGenerator.excludeBackground &#x3D; excludeBackground; &#125; &#125; [SerializeField] private Material _material; [SerializeField] private ComputeShader _computeShader; [SerializeField] private bool _blur; [SerializeField] private bool _excludeBackground; SSPRPlanarRenderPass m_ScriptablePass; &#x2F;&#x2F;&#x2F; &lt;inheritdoc&#x2F;&gt; public override void Create() &#123; m_ScriptablePass &#x3D; new SSPRPlanarRenderPass(); m_ScriptablePass.renderPassEvent &#x3D; RenderPassEvent.BeforeRenderingPostProcessing; &#125; &#x2F;&#x2F; Here you can inject one or multiple render passes in the renderer. &#x2F;&#x2F; This method is called when setting up the renderer once per-camera. public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) &#123; if (renderingData.cameraData.renderType !&#x3D; CameraRenderType.Base) &#123; return; &#125; if (_material &#x3D;&#x3D; null || _computeShader &#x3D;&#x3D; null) &#123; return; &#125; m_ScriptablePass.Setup(_material, _computeShader, _blur, _excludeBackground); m_ScriptablePass.ConfigureTarget(renderer.cameraColorTarget, renderer.cameraDepthTarget); renderer.EnqueuePass(m_ScriptablePass); &#125; &#125; public class SSPRTexGenerator &#123; private static class ShaderProperties &#123; public static readonly int Result &#x3D; Shader.PropertyToID(&quot;_Result&quot;); public static readonly int CameraColorTexture &#x3D; Shader.PropertyToID(&quot;_CameraColorTexture&quot;); public static readonly int PlanarPosition &#x3D; Shader.PropertyToID(&quot;_PlanarPosition&quot;); public static readonly int PlanarNormal &#x3D; Shader.PropertyToID(&quot;_PlanarNormal&quot;); public static readonly int MatrixVP &#x3D; Shader.PropertyToID(&quot;_MatrixVP&quot;); public static readonly int MatrixInvVP &#x3D; Shader.PropertyToID(&quot;_MatrixInvVP&quot;); public static readonly int MainTexelSize &#x3D; Shader.PropertyToID(&quot;_MainTex_TexelSize&quot;); &#125; private ComputeShader _computeShader; private int _reflectionTexID; private int _kernelClear; private int _kernalPass1; private int _kernalPass2; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 在生成反射贴图的时候，是否剔除掉无穷远的像素(例如天空盒) &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private bool _excludeBackground; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 模糊 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private bool _enableBlur; private BlurBlitter _blurBlitter &#x3D; new BlurBlitter(); public SSPRTexGenerator(string reflectTexName &#x3D; &quot;_ReflectionTex&quot;) &#123; _reflectionTexID &#x3D; Shader.PropertyToID(reflectTexName); &#125; public void BindCS(ComputeShader cp) &#123; _computeShader &#x3D; cp; this.UpdateKernelIndex(); &#125; private void UpdateKernelIndex() &#123; _kernelClear &#x3D; _computeShader.FindKernel(&quot;Clear&quot;); _kernalPass1 &#x3D; _computeShader.FindKernel(&quot;DrawReflectionTex1&quot;); _kernalPass2 &#x3D; _computeShader.FindKernel(&quot;DrawReflectionTex2&quot;); if (_excludeBackground) &#123; _kernalPass1 +&#x3D; 2; _kernalPass2 +&#x3D; 2; &#125; &#125; public bool excludeBackground &#123; get &#123; return _excludeBackground; &#125; set &#123; _excludeBackground &#x3D; value; if (_computeShader) &#123; this.UpdateKernelIndex(); &#125; &#125; &#125; public bool enableBlur &#123; get &#123; return _enableBlur; &#125; set &#123; _enableBlur &#x3D; value; &#125; &#125; public void Render(CommandBuffer cmd, RenderTargetIdentifier id, ref RenderingData renderingData, ref PlanarDescriptor planarDescriptor) &#123; if (_computeShader &#x3D;&#x3D; null) &#123; Debug.LogError(&quot;请设置CS&quot;); return; &#125; var reflectionTexDes &#x3D; renderingData.cameraData.cameraTargetDescriptor; reflectionTexDes.enableRandomWrite &#x3D; true; reflectionTexDes.msaaSamples &#x3D; 1; cmd.GetTemporaryRT(_reflectionTexID, reflectionTexDes); var rtWidth &#x3D; reflectionTexDes.width; var rtHeight &#x3D; reflectionTexDes.height; &#x2F;&#x2F; V矩阵 Matrix4x4 v &#x3D; renderingData.cameraData.camera.worldToCameraMatrix; &#x2F;&#x2F; 还不清楚：为什么不直接使用renderingData.cameraData.GetProjectionMatrix() Matrix4x4 p &#x3D; GL.GetGPUProjectionMatrix(renderingData.cameraData.GetProjectionMatrix(), false); &#x2F;&#x2F; MVP矩阵变换过程都是 右乘向量，所以VP &#x3D; p * v; var matrixVP &#x3D; p * v; var invMatrixVP &#x3D; matrixVP.inverse; &#x2F;&#x2F; computeShader 中thread组设置为(8,8,1) int threadGroupX &#x3D; reflectionTexDes.width &#x2F; 8; int threadGroupY &#x3D; reflectionTexDes.height &#x2F; 8; RenderTargetIdentifier cameraColorTex &#x3D; id; &#x2F;&#x2F; computeshader参数设置 cmd.SetComputeVectorParam(_computeShader, ShaderProperties.MainTexelSize, new Vector4(1.0f &#x2F; rtWidth, 1.0f &#x2F; rtHeight, rtWidth, rtHeight)); cmd.SetComputeVectorParam(_computeShader, ShaderProperties.PlanarPosition, planarDescriptor.position); cmd.SetComputeVectorParam(_computeShader, ShaderProperties.PlanarNormal, planarDescriptor.normal); cmd.SetComputeMatrixParam(_computeShader, ShaderProperties.MatrixVP, matrixVP); cmd.SetComputeMatrixParam(_computeShader, ShaderProperties.MatrixInvVP, invMatrixVP); &#x2F;&#x2F; Texture相关参数都只能对应kernel设置 cmd.SetComputeTextureParam(_computeShader, _kernelClear, ShaderProperties.Result, _reflectionTexID); cmd.DispatchCompute(_computeShader, _kernelClear, threadGroupX, threadGroupY, 1); &#x2F;&#x2F; Pass1 对像素做反转 cmd.SetComputeTextureParam(_computeShader, _kernalPass1, ShaderProperties.CameraColorTexture, cameraColorTex); cmd.SetComputeTextureParam(_computeShader, _kernalPass1, ShaderProperties.Result, _reflectionTexID); cmd.DispatchCompute(_computeShader, _kernalPass1, threadGroupX, threadGroupY, 1); &#x2F;&#x2F; Pass2 修理反转后像素的遮挡问题 cmd.SetComputeTextureParam(_computeShader, _kernalPass2, ShaderProperties.CameraColorTexture, cameraColorTex); cmd.SetComputeTextureParam(_computeShader, _kernalPass2, ShaderProperties.Result, _reflectionTexID); cmd.DispatchCompute(_computeShader, _kernalPass2, threadGroupX, threadGroupY, 1); if (_enableBlur) &#123; _blurBlitter.SetSource(_reflectionTexID, reflectionTexDes); _blurBlitter.blurType &#x3D; BlurType.BoxBilinear; _blurBlitter.iteratorCount &#x3D; 1; _blurBlitter.downSample &#x3D; 1; _blurBlitter.Render(cmd); &#125; &#x2F;&#x2F; 将结果图片设置为全局(在当前cmd内都能直接获取) cmd.SetGlobalTexture(_reflectionTexID, _reflectionTexID); &#125; public void ReleaseTemporary(CommandBuffer cmd) &#123; cmd.ReleaseTemporaryRT(_reflectionTexID); &#125; &#125;&#125; ReflectPlane：标记哪些平面需要反射 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166using System;using System.Collections.Generic;using System.Linq;using System.Text;using System.Threading.Tasks;using UnityEngine;namespace URPLearn&#123; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 一个平面，平面由一个点和法线来确定 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; public struct PlanarDescriptor &#123; public Vector3 position; public Vector3 normal; public static bool operator &#x3D;&#x3D;(PlanarDescriptor p1, PlanarDescriptor p2) &#123; return IsNormalEqual(p1.normal, p2.normal) &amp;&amp; IsPositionInPlanar(p1.position, p2); &#125; public static bool operator !&#x3D;(PlanarDescriptor p1, PlanarDescriptor p2) &#123; return !IsNormalEqual(p1.normal, p2.normal) || !IsPositionInPlanar(p1.position, p2); &#125; public override bool Equals(object obj) &#123; if (obj &#x3D;&#x3D; null) &#123; return false; &#125; if (obj is PlanarDescriptor p) &#123; return IsNormalEqual(normal, p.normal) &amp;&amp; IsPositionInPlanar(p.position, this); &#125; else &#123; return false; &#125; &#125; public override int GetHashCode() &#123; int hash &#x3D; 17; hash &#x3D; hash * 23 + position.GetHashCode(); hash &#x3D; hash * 23 + normal.GetHashCode(); return hash; &#125; public override string ToString() &#123; return base.ToString(); &#125; private static bool IsNormalEqual(Vector3 n1, Vector3 n2) &#123; return 1 - Vector3.Dot(n1, n2) &lt; 0.001f; &#125; private static bool IsPositionInPlanar(Vector3 checkPos, PlanarDescriptor planar) &#123; return Vector3.Dot(planar.position - checkPos, planar.normal) &lt; 0.01f; &#125; &#125; public class PlanarRendererGroup &#123; public PlanarDescriptor descriptor; public HashSet&lt;Renderer&gt; renderers &#x3D; new HashSet&lt;Renderer&gt;(); public void Clear() &#123; renderers.Clear(); &#125; &#125; public class PlanarRendererGroups &#123; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 池子 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private Stack&lt;PlanarRendererGroup&gt; _freePool &#x3D; new Stack&lt;PlanarRendererGroup&gt;(); &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 平面反射 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private List&lt;PlanarRendererGroup&gt; _planarRenderers &#x3D; new List&lt;PlanarRendererGroup&gt;(); public List&lt;PlanarRendererGroup&gt; PlanarRenderers &#x3D;&gt; _planarRenderers; public void AddRender(Renderer renderer) &#123; var position &#x3D; renderer.transform.position; var normal &#x3D; renderer.transform.up; var planarDescriptor &#x3D; new PlanarDescriptor() &#123; position &#x3D; position, normal &#x3D; normal &#125;; &#x2F;&#x2F; 如果有同一平面的则放在一起渲染 foreach (var renderers in _planarRenderers) &#123; if (renderers.descriptor &#x3D;&#x3D; planarDescriptor) &#123; renderers.renderers.Add(renderer); return; &#125; &#125; &#x2F;&#x2F; 没有则添加一个平面渲染组 &#123; var group &#x3D; AllocateGroup(); group.descriptor &#x3D; planarDescriptor; group.renderers.Add(renderer); _planarRenderers.Add(group); &#125; &#125; private PlanarRendererGroup AllocateGroup() &#123; if (_freePool.Count &gt; 0) return _freePool.Pop(); else return new PlanarRendererGroup(); &#125; public void Clear() &#123; foreach (var group in _planarRenderers) &#123; group.Clear(); _freePool.Push(group); &#125; _planarRenderers.Clear(); &#125; &#125; [ExecuteInEditMode] public class ReflectPlane : MonoBehaviour &#123; private static List&lt;ReflectPlane&gt; _reflectPlanes &#x3D; new List&lt;ReflectPlane&gt;(); public static List&lt;ReflectPlane&gt; ReflectPlanes &#x3D;&gt; _reflectPlanes; public static void GetVisiblePlanarGroups(PlanarRendererGroups groups) &#123; groups.Clear(); foreach (var p in ReflectPlanes) &#123; var renderer &#x3D; p.GetComponent&lt;Renderer&gt;(); if (renderer.isVisible) &#123; groups.AddRender(renderer); &#125; &#125; &#125; private void OnEnable() &#123; _reflectPlanes.Add(this); &#125; private void OnDisable() &#123; _reflectPlanes.Remove(this); &#125; &#125;&#125; ComputeShader：对图像进行反转操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113#pragma kernel Clear#pragma kernel DrawReflectionTex1#pragma kernel DrawReflectionTex2#pragma kernel DrawReflectionTex1 EXCLUDE_BACKGROUND#pragma kernel DrawReflectionTex2 EXCLUDE_BACKGROUND#include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot;RWTexture2D&lt;float4&gt; _Result;Texture2D&lt;float4&gt; _CameraColorTexture;Texture2D&lt;float&gt; _CameraDepthTexture;float4 _MainTex_TexelSize;float4x4 _MatrixInvVP;float4x4 _MatrixVP;float3 _PlanarPosition;float3 _PlanarNormal;SamplerState PointClampSampler;float3 TransformPositionCSToWS(float3 positionCS) &#123; float4 positionWS &#x3D; mul(_MatrixInvVP, float4(positionCS, 1)); positionWS &#x2F;&#x3D; positionWS.w; return positionWS.xyz;&#125;float3 ReconstructPositionWS(float2 uv, float depth) &#123; float3 positionCS &#x3D; float3(uv * 2 - 1, depth); float3 positionWS &#x3D; TransformPositionCSToWS(positionCS); return positionWS;&#125;float3 Reproject(float3 positionWS) &#123; float4 positionCS &#x3D; mul(_MatrixVP, float4(positionWS, 1)); positionCS &#x2F;&#x3D; positionCS.w; positionCS.xy &#x3D; (positionCS.xy + 1) * 0.5; return positionCS.xyz;&#125;float4 GetMirrorPositionWS(float3 positionWS) &#123; float normalProj &#x3D; dot(positionWS - _PlanarPosition, _PlanarNormal); return float4(positionWS - normalProj * _PlanarNormal * 2, normalProj);&#125;[numthreads(8, 8, 1)]void Clear(uint3 id : SV_DispatchThreadID)&#123; _Result[id.xy] &#x3D; float4(0, 0, 0, 0);&#125;float4 GetMirrorPositionWSFromID(uint3 id) &#123; float2 pixelCoord &#x3D; id.xy; float2 uv &#x3D; id.xy * _MainTex_TexelSize.xy; float depth &#x3D; _CameraDepthTexture.SampleLevel(PointClampSampler, uv, 0);#ifdef EXCLUDE_BACKGROUND#if UNITY_REVERSED_Z if (depth &#x3D;&#x3D; 0)#else if (depth &#x3D;&#x3D; 1)#endif &#123; return float4(0, 0, 0, 0); &#125;#endif float3 positionWS &#x3D; ReconstructPositionWS(uv, depth); float4 mirrorPositionWS &#x3D; GetMirrorPositionWS(positionWS); return mirrorPositionWS;&#125;float3 GetMirrorUVDepthFromID(uint3 id) &#123; float4 mirrorPositionWS &#x3D; GetMirrorPositionWSFromID(id); if (mirrorPositionWS.w &gt; 0.01) &#123; float3 uvAndDepth &#x3D; Reproject(mirrorPositionWS.xyz); return uvAndDepth; &#125; else &#123; return float3(0, 0, 0); &#125;&#125;[numthreads(8, 8, 1)]void DrawReflectionTex1(uint3 id : SV_DispatchThreadID) &#123; float2 uv &#x3D; id.xy; float3 mirrorUVAndDepth &#x3D; GetMirrorUVDepthFromID(id); float2 mirrorPixelCoord &#x3D; mirrorUVAndDepth.xy * _MainTex_TexelSize.zw; _Result[mirrorPixelCoord] &#x3D; float4(_CameraColorTexture[uv].rgb, mirrorUVAndDepth.z);&#125;[numthreads(8, 8, 1)]void DrawReflectionTex2(uint3 id : SV_DispatchThreadID) &#123; float2 uv &#x3D; id.xy; float3 mirrorUVAndDepth &#x3D; GetMirrorUVDepthFromID(id); float2 toPixelCoord &#x3D; mirrorUVAndDepth.xy * _MainTex_TexelSize.zw; float4 originalColor &#x3D; _Result[toPixelCoord];#if UNITY_REVERSED_Z bool overwrite &#x3D; mirrorUVAndDepth.z &gt; originalColor.a;#else bool overwrite &#x3D; mirrorUVAndDepth.z &lt; originalColor.a;#endif if (overwrite) &#123; _Result[toPixelCoord] &#x3D; float4(_CameraColorTexture[uv].rgb, 1); &#125; else &#123; _Result[toPixelCoord] &#x3D; float4(originalColor.rgb, 1); &#125;&#125; 总结 ComputeScreenPos在顶点着色器计算好屏幕空间坐标，再在片元着色器做齐次除法就可以得到屏幕uv 屏幕空间操作指南：参考上面SSAO总结，一般就是涉及世界坐标重建这个事情 URP实现PBR基础 满足以下几点的光照模型，符合PBR模型： 微表面：不同材质的平面，有很多不同朝向不一的微小平面 能量守恒：出射光的总量不超过入射光的总量 反射方程：使用基于物理的BRDF(双向反射分布函数) PBR反射方程：L(o) = f(fr(p,wi,wo) * Li(p,wi) * dot(n,wi) * dwi) BRDF-Cooktorrance方程： fr(p,wi,wo) = k(d)*f(lambert) + K(s)*f(cook-torrance) f(lamber) = c / Π ∫(cook-torrance) = DFG / (4*dot(wo,n)*dot(wi,n)) D：法线分布函数（NDF），估算微平面的整体取向，公式：a^2 / (Π * (NdotH^2) * (a^2-1) + 1)^2 （注：a表示粗糙度） F: 菲尼尔方程，用于描述表面反射光所占比例， 公式： F0 + (1 - F0) * pos(1 - cosTheta, 5) （注：F0表示不同材质的垂直方向的反射率，直接光照中cosTheta：HdotV或HdotL，间接光照中cosTheta：NdotV） G：几何函数，用于计算微表面，自阴影， 公式：cosTheta / (cosTheta(1.0 - k) + k) （注：k由粗糙度a计算，直接光照：k=(a+1)^2 / 8， 间接光照：k=a^2 / 2 ， cosTheta需要分别计算NoV,NoL的和） K(d)：(1-F)*(1-metallic) K(s)：菲尼尔值里包括了表面反射系数，因此K(s)不需要 IBL间接光照 CubeMap IrradianceMap 或者ShadeSH9() ,URP用SampleSH9() 球谐函数计算间接光照的diffuse 预高光积分图，或者高光积分算法计算间接光照的specular12345678float2 IntegrateSpecularBRDF(float NoV, float roughness)&#123; const float4 c0 &#x3D; float4(-1, -0.0275, -0.572, 0.022); const float4 c1 &#x3D; float4(1, 0.0425, 1.04, -0.04); float4 r &#x3D; roughness * c0 + c1; float a004 &#x3D; min(r.x * r.x, exp2(-9.28 * NoV)) * r.x + r.y; return float2(-c1.z, c1.z) * a004 + r.zw;&#125; 准备资源 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223Shader &quot;Unlit&#x2F;PBR&quot;&#123; Properties &#123; _BaseColor(&quot;_BaseColor&quot;, Color) &#x3D; (1, 1, 1, 1) _MainTex(&quot;_MainTex&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; _BumpScale(&quot;_BumpScale&quot;, Range(-1, 1)) &#x3D; 1 [NoScaleOffset] _BumpMap(&quot;_BumpMap&quot;, 2D) &#x3D; &quot;bump&quot; &#123;&#125; [NoScaleOffset] _MetalnessMap(&quot;_MetalnessMap&quot;, 2D) &#x3D; &quot;black&quot; &#123;&#125; [NoScaleOffset] _RoughnessMap(&quot;_RoughnessMap&quot;, 2D) &#x3D; &quot;gray&quot; &#123;&#125; _IndirectIntensity(&quot;_IndirectIntensity&quot;, Range(0, 1)) &#x3D; 1 &#x2F;&#x2F;[NoScaleOffset] _IrradianceCube (&quot;_IrradianceCube&quot;, Cube) &#x3D; &quot;black&quot; &#123;&#125; &#x2F;&#x2F;[NoScaleOffset] _RadianceCube (&quot;_RadianceCube&quot;, Cube) &#x3D; &quot;black&quot; &#123;&#125; [Toggle(USE_BRDF_INTEGRATION_MAP)] _UseBRDFIntegrationMap(&quot;_UseBRDFIntegrationMap&quot;, Float) &#x3D; 0 [NoScaleOffset] _BRDFIntegrationMap(&quot;_BRDFIntegrationMap&quot;, 2D) &#x3D; &quot;black&quot; &#123;&#125; &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; HLSLINCLUDE #define EPSILSON 0.000001 #define BRDF_PI 3.14159265359 #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; TEXTURE2D(_MainTex); SAMPLER(sampler_MainTex); TEXTURE2D(_BumpMap); SAMPLER(sampler_BumpMap); TEXTURE2D(_MetalnessMap); SAMPLER(sampler_MetalnessMap); TEXTURE2D(_RoughnessMap); SAMPLER(sampler_RoughnessMap); TEXTURE2D(_BRDFIntegrationMap); SAMPLER(sampler_BRDFIntegrationMap); CBUFFER_START(UnityPerMaterial) float4 _MainTex_ST; float4 _BaseColor; float _BumpScale; float _IndirectIntensity; CBUFFER_END struct Attributes &#123; float4 positionOS:POSITION; float4 normalOS:NORMAL; float4 tangentOS:TANGENT; float2 uv : TEXCOORD0; &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; float4 tangentWS:TEXCOORD1; float4 BtangentWS:TEXCOORD2; float4 normalWS:TEXCOORD3; &#125;; &#x2F;&#x2F;菲涅尔函数 float3 FresnelSchlick(float NoV, float3 F0) &#123; return F0 + (1.0 - F0) * pow(1.0 - NoV, 5); &#125; &#x2F;&#x2F;几何函数 float GeometrySchlickGGX(float NoV, float k) &#123; return NoV &#x2F; max(NoV * (1.0 - k) + k, EPSILSON); &#125; &#x2F;&#x2F;几何函数 float GeometrySmith(float NoV, float NoL, float k) &#123; return GeometrySchlickGGX(NoV, k) * GeometrySchlickGGX(NoL, k); &#125; &#x2F;&#x2F;分布函数 alpha&#x3D;roughness*roughness float DistributionGGX(float NoH, float alpha) &#123; float a2 &#x3D; alpha * alpha; float denom &#x3D; pow(NoH * NoH * (a2 - 1.0) + 1.0, 2); return a2 &#x2F; max(denom * BRDF_PI, EPSILSON); &#125; &#x2F;&#x2F;计算直接光照 float3 CalcDirectLight(float metalness, float roughness, float3 albedo, float3 F0, float3 normal, float3 viewDir, float NoV, float3 worldPos) &#123; &#x2F;&#x2F;准备参数 Light mylight &#x3D; GetMainLight(); float3 lightDir &#x3D; normalize(mylight.direction); &#x2F;&#x2F;获取光线方向 float3 floatDir &#x3D; normalize(viewDir + lightDir); &#x2F;&#x2F;计算半角方向 float NoL &#x3D; saturate(dot(normal, lightDir)); &#x2F;&#x2F;计算法线光线点积 float NoH &#x3D; saturate(dot(normal, floatDir)); &#x2F;&#x2F;计算法线半角点积 float HoL &#x3D; saturate(dot(floatDir, lightDir)); &#x2F;&#x2F;计算半角光线点积，同半角视线点积 &#x2F;&#x2F;计算方程参数 float3 F &#x3D; FresnelSchlick(HoL, F0); &#x2F;&#x2F;计算菲涅尔 float G &#x3D; GeometrySmith(NoV, NoL, pow(roughness + 1.0, 2) &#x2F; 8.0); &#x2F;&#x2F;计算遮挡 float D &#x3D; DistributionGGX(NoH, roughness * roughness); &#x2F;&#x2F;计算分布 float3 kD &#x3D; (1.0 - F) * (1.0 - metalness); &#x2F;&#x2F;计算漫反射系数 &#x2F;&#x2F;计算直接光照结果 float3 directDiffuse &#x3D; kD * albedo &#x2F; BRDF_PI; &#x2F;&#x2F;计算漫反射 float3 directSpecular &#x3D; F * (D * G) &#x2F; (4.0 * max(NoV * NoL, EPSILSON)); &#x2F;&#x2F;计算高光 float3 directLightIn &#x3D; mylight.color * BRDF_PI; &#x2F;&#x2F;获取直接光照颜色 return (directDiffuse + directSpecular) * NoL * directLightIn; &#125; float2 IntegrateSpecularBRDF(float NoV, float roughness) &#123; const float4 c0 &#x3D; float4(-1, -0.0275, -0.572, 0.022); const float4 c1 &#x3D; float4(1, 0.0425, 1.04, -0.04); float4 r &#x3D; roughness * c0 + c1; float a004 &#x3D; min(r.x * r.x, exp2(-9.28 * NoV)) * r.x + r.y; return float2(-c1.z, c1.z) * a004 + r.zw; &#125; real3 SampleSH(real3 normalWS) &#123; &#x2F;&#x2F; LPPV is not supported in Ligthweight Pipeline real4 SHCoefficients[7]; SHCoefficients[0] &#x3D; unity_SHAr; SHCoefficients[1] &#x3D; unity_SHAg; SHCoefficients[2] &#x3D; unity_SHAb; SHCoefficients[3] &#x3D; unity_SHBr; SHCoefficients[4] &#x3D; unity_SHBg; SHCoefficients[5] &#x3D; unity_SHBb; SHCoefficients[6] &#x3D; unity_SHC; return max(real3(0, 0, 0), SampleSH9(SHCoefficients, normalWS)); &#125; &#x2F;&#x2F;计算间接光照 float3 CalcIndirectLight(float metalness, float roughness, float3 albedo, float3 F0, float3 normal, float3 viewDir, float NoV) &#123; &#x2F;&#x2F;准备参数 float3 F &#x3D; FresnelSchlick(NoV, F0); &#x2F;&#x2F;计算菲涅尔 float3 kD &#x3D; (1.0 - F) * (1.0 - metalness); &#x2F;&#x2F;计算漫反射系数 &#x2F;&#x2F;计算间接漫反射 &#x2F;&#x2F;float3 indirectDiffuse &#x3D; SAMPLE_TEXTURE2D(_IrradianceCube, normal).rgb; float3 indirectDiffuse &#x3D; SampleSH(normal); indirectDiffuse *&#x3D; kD * albedo; &#x2F;&#x2F;计算间接高光 float mip &#x3D; PerceptualRoughnessToMipmapLevel(roughness); &#x2F;&#x2F;计算粗糙度对应MIP float3 reflDir &#x3D; reflect(-viewDir, normal); &#x2F;&#x2F;计算视线反射方向 &#x2F;&#x2F;float3 indirectSpecular &#x3D; SAMPLE_TEXTURECUBE_LOD(_RadianceCube, float4(reflDir, mip)).rgb; float4 encodedIrradiance &#x3D; SAMPLE_TEXTURECUBE_LOD(unity_SpecCube0, samplerunity_SpecCube0, reflDir, mip); float3 indirectSpecular &#x3D; DecodeHDREnvironment(encodedIrradiance, unity_SpecCube0_HDR); &#x2F;&#x2F;高光积分#if USE_BRDF_INTEGRATION_MAP float2 envBRDF &#x3D; SAMPLE_TEXTURE2D(_BRDFIntegrationMap, sampler_BRDFIntegrationMap, float2(NoV, roughness)).rg;#else float2 envBRDF &#x3D; IntegrateSpecularBRDF(NoV, roughness);#endif indirectSpecular *&#x3D; F * envBRDF.x + envBRDF.y; &#x2F;&#x2F;计算间接光照结果 return (indirectDiffuse + indirectSpecular) * _IndirectIntensity; &#125; ENDHLSL Pass &#123; Tags&#123; &quot;LightMode&quot; &#x3D; &quot;UniversalForward&quot; &#125; HLSLPROGRAM #pragma vertex Vert #pragma fragment Frag #pragma shader_feature USE_BRDF_INTEGRATION_MAP Varyings Vert(Attributes i) &#123; Varyings o; VertexPositionInputs input &#x3D; GetVertexPositionInputs(i.positionOS.xyz); o.positionHS &#x3D; input.positionCS; VertexNormalInputs normalInput &#x3D; GetVertexNormalInputs(i.normalOS, i.tangentOS); o.tangentWS.xyz &#x3D; normalInput.tangentWS; o.BtangentWS.xyz &#x3D; normalInput.bitangentWS; o.normalWS.xyz &#x3D; normalInput.normalWS; &#x2F;&#x2F; 存一下世界空间坐标 o.tangentWS.w &#x3D; input.positionWS.x; o.BtangentWS.w &#x3D; input.positionWS.y; o.normalWS.w &#x3D; input.positionWS.z; o.uv &#x3D; TRANSFORM_TEX(i.uv, _MainTex); return o; &#125; float4 Frag(Varyings i) :SV_Target&#123; float3 positionWS &#x3D; float3(i.tangentWS.w,i.BtangentWS.w,i.normalWS.w); float metalness &#x3D; SAMPLE_TEXTURE2D(_MetalnessMap, sampler_MetalnessMap, i.uv).r; float roughness &#x3D; SAMPLE_TEXTURE2D(_RoughnessMap, sampler_RoughnessMap, i.uv).r; float4 mainColor &#x3D; SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv); float3 albedo &#x3D; _BaseColor.rgb * mainColor.rgb; float3x3 T2W &#x3D; &#123; i.tangentWS.xyz, i.BtangentWS.xyz, i.normalWS.xyz &#125;; float4 norTex &#x3D; SAMPLE_TEXTURE2D(_BumpMap, sampler_BumpMap, i.uv); float3 normalTS &#x3D; UnpackNormalScale(norTex, _BumpScale); normalTS.z &#x3D; pow(1 - pow(normalTS.x, 2) - pow(normalTS.y, 2), 0.5f); &#x2F;&#x2F;规范化 float3 normalWS &#x3D; normalize(mul(normalTS, T2W)); float3 viewDirWS &#x3D; normalize(_WorldSpaceCameraPos.xyz - positionWS); float3 F0 &#x3D; lerp(0.04f, albedo, metalness); float NoV &#x3D; dot(normalWS, viewDirWS); float3 directColor &#x3D; CalcDirectLight(metalness, roughness, albedo, F0, normalWS, viewDirWS, NoV, positionWS); float3 indirectColor &#x3D; CalcIndirectLight(metalness, roughness, albedo, F0, normalWS, viewDirWS, NoV); return float4(directColor + indirectColor, mainColor.a); &#125; ENDHLSL &#125; &#125;&#125; 总结草绘制基础代码效果展示总结浅水基础代码效果展示总结链接Unity3D游戏开发中100+效果的实现和源码大全 - 收藏起来肯定用得着URP HLSL入门学习高品质后处理：十种图像模糊算法的总结与实现","categories":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/categories/Unity/"}],"tags":[{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/tags/Graphics/"},{"name":"URP","slug":"URP","permalink":"https://skierhou.github.io/tags/URP/"}]},{"title":"URP学习汇总","slug":"Graphics/URP/URP学习汇总","date":"2021-11-21T06:30:01.000Z","updated":"2021-12-09T09:07:26.531Z","comments":true,"path":"2021/11/21/Graphics/URP/URP学习汇总/","link":"","permalink":"https://skierhou.github.io/2021/11/21/Graphics/URP/URP%E5%AD%A6%E4%B9%A0%E6%B1%87%E6%80%BB/","excerpt":"","text":"新建URP项目，Unity默认测试场景查看变化CameraCamera 基础设置解释 相机堆叠：RenderTypeCamera 特殊功能列举 分屏相机两个Camera，RenderType都设置成Base，设置ViewportRect即可相机分屏 Post-process Volume后处理盒子 添加Volume123456789101112131415namespace UnityEngine.Rendering.Universal&#123; [SerializeField, VolumeComponentMenu(&quot;Mypost&#x2F;ScreenSpacePlaneReflect&quot;)] public class ScreenSpacePlaneReflection : VolumeComponent &#123; public BoolParameter on &#x3D; new BoolParameter(false); public ClampedIntParameter RTsize &#x3D; new ClampedIntParameter(512, 128, 720, false); public FloatParameter ReflectHeight &#x3D; new FloatParameter(0.2f, false); public ClampedFloatParameter fadeOutRange &#x3D; new ClampedFloatParameter(0.3f, 0.0f, 1.0f, false); public bool IsActive() &#x3D;&gt; on.value; public bool IsTileCompatible() &#x3D;&gt; false; &#125;&#125; 获得组件： VolumeManager.instance.stack.GetComponent(); //获取自定义的volume组件 目前这种方式还是扩展后处理还是比较困难，由于流程最终走的uber shader，加新效果都需要再里面加一个处理，相当于改源码，因此使用RenderFeather添加后处理比较方便 Forward Renderer Data设置说明Renderer Features基础Features：Render Objects 初次理解，在渲染管线的某个时刻，过滤到需要的Object，并覆盖一些特殊设置，如遮挡显示等等URP手册 基础Features：SSAO环境遮挡Ambient Occlusion自定义Renderer Features 如何创建： Create / Rendering / URP / RenderFeature 创建脚本继承自：ScriptableRendererFeature， ScriptableRenderPass/ Create / Rendering / URP / RenderFeature创建123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051using UnityEngine;using UnityEngine.Rendering;using UnityEngine.Rendering.Universal;public class CustomRenderPassFeature : ScriptableRendererFeature&#123; class CustomRenderPass : ScriptableRenderPass &#123; &#x2F;&#x2F; This method is called before executing the render pass. &#x2F;&#x2F; It can be used to configure render targets and their clear state. Also to create temporary render target textures. &#x2F;&#x2F; When empty this render pass will render to the active camera render target. &#x2F;&#x2F; You should never call CommandBuffer.SetRenderTarget. Instead call &lt;c&gt;ConfigureTarget&lt;&#x2F;c&gt; and &lt;c&gt;ConfigureClear&lt;&#x2F;c&gt;. &#x2F;&#x2F; The render pipeline will ensure target setup and clearing happens in a performant manner. public override void OnCameraSetup(CommandBuffer cmd, ref RenderingData renderingData) &#123; &#125; &#x2F;&#x2F; Here you can implement the rendering logic. &#x2F;&#x2F; Use &lt;c&gt;ScriptableRenderContext&lt;&#x2F;c&gt; to issue drawing commands or execute command buffers &#x2F;&#x2F; https:&#x2F;&#x2F;docs.unity3d.com&#x2F;ScriptReference&#x2F;Rendering.ScriptableRenderContext.html &#x2F;&#x2F; You don&#39;t have to call ScriptableRenderContext.submit, the render pipeline will call it at specific points in the pipeline. public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) &#123; &#125; &#x2F;&#x2F; Cleanup any allocated resources that were created during the execution of this render pass. public override void OnCameraCleanup(CommandBuffer cmd) &#123; &#125; &#125; CustomRenderPass m_ScriptablePass; &#x2F;&#x2F;&#x2F; &lt;inheritdoc&#x2F;&gt; public override void Create() &#123; m_ScriptablePass &#x3D; new CustomRenderPass(); &#x2F;&#x2F; Configures where the render pass should be injected. m_ScriptablePass.renderPassEvent &#x3D; RenderPassEvent.AfterRenderingOpaques; &#125; &#x2F;&#x2F; Here you can inject one or multiple render passes in the renderer. &#x2F;&#x2F; This method is called when setting up the renderer once per-camera. public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) &#123; renderer.EnqueuePass(m_ScriptablePass); &#125;&#125; 用途： 实现URP没有提供的后处理效果 很多效果都可以放在RenderFeather中实现 //贴花 URP Decal Projector ShaderGraph使用解析URP默认ShaderGraph一些URP特殊用法SAMPLER 官网关于SAMPLER的使用说明“Point”, “Linear” or “Trilinear” (required) set up texture filtering mode. “Clamp”, “Repeat”, “Mirror” or “MirrorOnce” (required) set up texture wrap mode.Wrap modes can be specified per-axis (UVW), e.g. “ClampU_RepeatV”. “Compare” (optional) set up sampler for depth comparison; use with HLSL SamplerComparisonState type and SampleCmp / SampleCmpLevelZero functions. 使用方式sampler_&lt;过滤&gt;&lt;UV处理&gt; 形成一个变量名,用这个变量作为参数形成采样例如：sampler_LinearClamp 这个表示采样过滤是linear,超过(0,1)用clamp方式采样SAMPLER(sampler_LinearClamp);在shader里这样声明变量 采样是这样使用:float4 cloud = SAMPLE_TEXTURE2D_X(_CloudTex, sampler_LinearClamp, cloud_uv);也可以这样_CloudTex.Sample(sampler_LinearClamp, cloud_uv); 定义纹理和纹理采样器TEXTURE2D(textureName);SAMPLER(sampler_textureName); TEXTURE2D TEXTURE2D_X(_MainTex); TEXTURE2D_X_FLOAT(_CameraDepthTexture); CBufferConstant Buffer 是GPU中的一处常量缓冲区。 Unity Shader中使用CBUFFER_START和CBUFFER_END来定义缓冲区变量。当前Unity内部使用的缓冲区有 UnityPerCameraUnityLightingUnityShadowsUnityPerDrawUnityPerFrameUnityPerMaterialUnityPerObject这些缓冲区是根据各自数据的刷新频率来定义的。 例如UnityPerCamera中的数据，仅在渲染的Camera发生变化时刷新。里面存的即是与Camera相关的数据。UnityPerMaterial则在材质球发生变化的时候刷新。 CBuffer pragma multi_compileURP 支持变体 ，你可能需要某些功能 #pragma multi_compile 添加以下关键字 _MAIN_LIGHT_SHADOWS _MAIN_LIGHT_SHADOWS_CASCADE _ADDITIONAL_LIGHTS_VERTEX _ADDITIONAL_LIGHTS _ADDITIONAL_LIGHT_SHADOWS _SHADOWS_SOFT _MIXED_LIGHTING_SUBTRACTIVE https://www.bilibili.com/read/cv7359952/","categories":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/categories/Unity/"},{"name":"URP","slug":"Unity/URP","permalink":"https://skierhou.github.io/categories/Unity/URP/"}],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/tags/Unity/"},{"name":"URP","slug":"URP","permalink":"https://skierhou.github.io/tags/URP/"}]},{"title":"ComputeShader学习","slug":"Graphics/URP/ComputeShader","date":"2021-11-20T06:30:01.000Z","updated":"2021-12-06T11:55:30.330Z","comments":true,"path":"2021/11/20/Graphics/URP/ComputeShader/","link":"","permalink":"https://skierhou.github.io/2021/11/20/Graphics/URP/ComputeShader/","excerpt":"","text":"基础 Compute Shaders是在GPU运行却又在普通渲染管线之外的程序。用于运行GPGPU program。 平行算法被拆分成很多线程组，而线程组包含很多线程。例如一个线程处理一个像素点，而一定要注意这种处理是无序的随机的，并不一定是固定的处理顺序，例如不一定是从左到右挨个处理像素点。 线程组A Thread Group 运行在一个GPU单元 （A single multiprocesser）,如果GPU有16个multiprocesser，那么程序至少要分成16个 Thread Group使得每个multiprocesser都参与计算。组之间不分享内存。 线程一个线程组包含n个线程，每32个thread称为一个warp（nvidia：warp=32 ,ati:wavefront=64,因此未来此数字可能会更高）。从效率考虑，一个线程组包含的线程数最好的warp的倍数，256是一个比较合适的数字。 语法 numthreads中定义单个线程组，这个线程组为三维线程矩阵881个线程 在外面调用computeShader.Dispath(2,2,1)，表示定义221个线程组 SV_DispatchThreadID表示当前线程Id，取值范围为(0,0,0)~(threadxthread_groupx-1,threadythread_groupy-1,threadz*thread_groupz-1) 因此在使用是根据实际处理图片等分辨率，来写thread以及thread_group满足SV_DispatchThreadID的xy值可以覆盖图片分辨率，这样可以做到处理每个像素打个比方：图片像素为512*512，那么thread写成(8,8,1), thread_group写成(512/8,512/8,1)ComputeShader如下，相当于对图片每个像素写入红色，因为Id.xy的范围在(0511,0511) 一维调度：DispatchIndex=DispatchThreadID.x+DispatchThreadID.ynumthreads.xDispatch.x+DispatchThreadID.znumthreads.xDispatch.xnumthreads.yDispatch.y 123456789101112#pragma kernel FillWithRedRWTexture2D&lt; float4 &gt; res;&#x2F;&#x2F; numthreads中定义单个线程组，这个线程组为三维线程矩阵8*8*1个线程&#x2F;&#x2F; 在外面调用computeShader.Dispath(2,2,1)，表示定义2*2*1个线程组&#x2F;&#x2F; SV_DispatchThreadID表示当前线程Id，取值范围为(0,0,0)~(threadx*thread_groupx-1,thready*thread_groupy-1,threadz*thread_groupz-1)[numthreads(8,8,1)] void FillWithRed (uint3 id : SV_DispatchThreadID)&#123; res[id.xy] &#x3D; float4(1,0,0,1);&#125; 测试代码 Shader 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061Shader &quot;Unlit&#x2F;ComputTest&quot;&#123; Properties &#123; _Color (&quot;Color&quot;, Color) &#x3D; (1,1,1,1) &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; Blend SrcAlpha OneMinusSrcAlpha HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Lighting.hlsl&quot; CBUFFER_START(UnityPerMaterial) float4 _Color; CBUFFER_END struct data &#123; float3 position; float4 color; &#125;; StructuredBuffer&lt;data&gt; Result; ENDHLSL Pass &#123; Blend SrcAlpha OneMinusSrcAlpha HLSLPROGRAM #pragma vertex vert #pragma fragment frag struct v2f &#123; float4 vertex : SV_POSITION; float4 color : COLOR; &#125;; sampler2D _MainTex; float4 _MainTex_ST; v2f vert (uint id : SV_VertexID) &#123; v2f o; o.vertex &#x3D; TransformObjectToHClip(float4(Result[id].position, 1.0)); o.color &#x3D; Result[id].color; return o; &#125; float4 frag (v2f i) : SV_Target &#123; return i.color; &#125; ENDHLSL &#125; &#125;&#125; C# 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061using System.Collections;using System.Collections.Generic;using UnityEngine;public struct ParticleData&#123; Vector3 position; Color color;&#125;public class ComputeTest : MonoBehaviour&#123; public ComputeShader computeShader; ParticleData[] particleDatas; public int count &#x3D; 64; public Color color; public int size &#x3D; 1; public Material material; private ComputeBuffer ComputeBuffer; private int id; &#x2F;&#x2F; Start is called before the first frame update void Start() &#123; int vec3Stride &#x3D; sizeof(float) * 3; int colorStride &#x3D; sizeof(float) * 4; ComputeBuffer &#x3D; new ComputeBuffer(count, vec3Stride + colorStride); id &#x3D; computeShader.FindKernel(&quot;CSMain&quot;); particleDatas &#x3D; new ParticleData[count]; for (int i &#x3D; 0; i &lt; count; i++) &#123; particleDatas[i] &#x3D; new ParticleData(); &#125; ComputeBuffer.SetData(particleDatas); computeShader.SetBuffer(id, &quot;Result&quot;, ComputeBuffer); material.SetBuffer(&quot;Result&quot;, ComputeBuffer); &#125; &#x2F;&#x2F; Update is called once per frame void OnRenderObject() &#123; computeShader.SetFloat(&quot;time&quot;, Time.time); computeShader.SetFloat(&quot;size&quot;, size); computeShader.SetVector(&quot;color&quot;, color); computeShader.SetVector(&quot;_threadGroup&quot;, new Vector3(10, 10, 100)); computeShader.Dispatch(id, 10, 10, 100); material.SetPass(0); Graphics.DrawProceduralNow(MeshTopology.Points, ComputeBuffer.count); &#125; private void OnDestroy() &#123; ComputeBuffer.Release(); ComputeBuffer.Dispose(); &#125;&#125; CS 1234567891011121314151617181920212223242526272829&#x2F;&#x2F; Each #kernel tells which function to compile; you can have many kernels#pragma kernel CSMainfloat time;float4 color;float size;struct ParticleData&#123; float3 position; float4 color;&#125;;RWStructuredBuffer&lt;ParticleData&gt; Result;float3 _threadGroup;[numthreads(10,10,10)]void CSMain (uint3 id : SV_DispatchThreadID)&#123; int DispatchIndex &#x3D; id.x + (id.y * 10 * _threadGroup.x) + (id.z * 10 * 10 * _threadGroup.x * _threadGroup.y); &#x2F;&#x2F; x*x, x*y*x*y ParticleData data &#x3D; Result[DispatchIndex]; data.color &#x3D; color; data.position &#x3D; float3(size * sin(DispatchIndex + time), DispatchIndex * 0.002,size * cos(DispatchIndex + time)); data.position.xy *&#x3D; abs(sin(data.position.y + time * 0.3)); Result[DispatchIndex] &#x3D; data;&#125; 作用只要有涉及大量数据的处理都可以放在ComputeShader中计算 Unity新版VFX 布料/头发模拟 光追 后处理 参考链接Compute Shader介绍（一）Compute Shader介绍（二）初识ComputeShaderShader第二十八讲 Compute Shaders","categories":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/categories/Unity/"}],"tags":[{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/tags/Graphics/"},{"name":"ComputeShader","slug":"ComputeShader","permalink":"https://skierhou.github.io/tags/ComputeShader/"}]},{"title":"URP 后处理效果实现","slug":"Graphics/URP/后处理效果汇总","date":"2021-11-20T06:30:01.000Z","updated":"2021-12-09T09:09:27.482Z","comments":true,"path":"2021/11/20/Graphics/URP/后处理效果汇总/","link":"","permalink":"https://skierhou.github.io/2021/11/20/Graphics/URP/%E5%90%8E%E5%A4%84%E7%90%86%E6%95%88%E6%9E%9C%E6%B1%87%E6%80%BB/","excerpt":"","text":"Blur 模糊URPLearn/Blur 基础概念图形处理中有一个基础概念: 卷积核(kernel).kernel是矩阵形式的存在，一个3x3的kernel，3称作KernelSize，将其作用与(x,y)位置的像素，等效于采集(x,y)周围3x3范围的像素值，分别与a ~ i进行加权平均运算。不同的模糊算法，实质上就是取不同的卷积核。 Box Blur 均值模糊均值模糊。 即取指定大小(size * size)范围内的像素，相加后取平均值。 性能：n * n123456789101112half4 BoxBlur(Texture2D tex, float2 pixelCoord, float halfKernelSize)&#123; half4 color &#x3D; half4(0,0,0,1); int kernelSize &#x3D; 2 * halfKernelSize + 1; float weight &#x3D; rcp(kernelSize * kernelSize); for(int i &#x3D; -halfKernelSize ; i &lt;&#x3D; halfKernelSize ; i ++)&#123; for(int j &#x3D; -halfKernelSize ; j &lt;&#x3D; halfKernelSize ; j ++)&#123; color +&#x3D; LOAD_TEXTURE2D_X(tex,pixelCoord + float2(i,j)) * weight; &#125; &#125; return color ;&#125; 性能：2 * n12345678910111213141516half4 BoxBlur(Texture2D tex, float2 pixelCoord, float halfKernelSize, float2 offset) &#123; half4 color &#x3D; half4(0, 0, 0, 1); float weight &#x3D; rcp(2 * halfKernelSize + 1); for (int i &#x3D; -halfKernelSize; i &lt;&#x3D; halfKernelSize; i++) &#123; color +&#x3D; LOAD_TEXTURE2D_X(tex, pixelCoord + offset * i) * weight; &#125; return color;&#125;&#x2F;&#x2F; 水平采样half4 BoxBlurH(Texture2D tex, float2 pixelCoord, int halfKernelSize, float radiusScale) &#123; return BoxBlur(tex, pixelCoord, halfKernelSize, float2(radiusScale, 0));&#125;&#x2F;&#x2F; 垂直采样half4 BoxBlurV(Texture2D tex, float2 pixelCoord, int halfKernelSize, float radiusScale) &#123; return BoxBlur(tex, pixelCoord, halfKernelSize, float2(0, radiusScale));&#125; 性能：n + 1 ， 思想：中心点往左右两边采样，一次循环采样2次123456789101112131415161718192021222324252627282930313233343536373839404142434445half4 BoxBlurBilinear(Texture2D tex, sampler linearSampler, float2 uv, int halfKernelSize, float2 offset) &#123; half4 color &#x3D; half4(0, 0, 0, 1); float weight &#x3D; rcp(halfKernelSize * 2 + 1); if (halfKernelSize % 2 &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F;even color +&#x3D; SAMPLE_TEXTURE2D_X(tex, linearSampler, uv) * weight; int quartKernelSize &#x3D; floor(halfKernelSize &#x2F; 2); for (int i &#x3D; 1; i &lt;&#x3D; quartKernelSize; i++) &#123; float uvOffset &#x3D; (i * 2 - 0.5); color +&#x3D; SAMPLE_TEXTURE2D_X(tex, linearSampler, uv + offset * uvOffset) * 2 * weight; color +&#x3D; SAMPLE_TEXTURE2D_X(tex, linearSampler, uv - offset * uvOffset) * 2 * weight; &#125; &#125; else &#123; &#x2F;&#x2F;odd color +&#x3D; SAMPLE_TEXTURE2D_X(tex, linearSampler, uv + 0.75 * offset) * 1.5 * weight; color +&#x3D; SAMPLE_TEXTURE2D_X(tex, linearSampler, uv - 0.75 * offset) * 1.5 * weight; int quartKernelSize &#x3D; floor((halfKernelSize - 1) &#x2F; 2); for (int i &#x3D; 1; i &lt;&#x3D; quartKernelSize; i++) &#123; float uvOffset &#x3D; (i * 2 + 0.5); color +&#x3D; SAMPLE_TEXTURE2D_X(tex, linearSampler, uv + offset * uvOffset) * 2 * weight; color +&#x3D; SAMPLE_TEXTURE2D_X(tex, linearSampler, uv - offset * uvOffset) * 2 * weight; &#125; &#125; return color;&#125;#define BOX_BLUR_BILINEAR(tex,uv,halfKernelSize,offset) BoxBlurBilinear(tex,sampler_LinearClamp,uv,halfKernelSize,offset)&#x2F;&#x2F; 水平采样 在水平模糊Pass时，令offset &#x3D; (1 &#x2F; textureWidth, 0);float4 FragH(Varyings i) : SV_Target&#123; #if _BilinearMode return BOX_BLUR_BILINEAR(_MainTex,i.uv,_KernelSize,float2(_BlurScale,0) * _MainTex_TexelSize.xy); #else return BoxBlur(_MainTex,i.uv * _MainTex_TexelSize.zw,_KernelSize,float2(_BlurScale,0)); #endif&#125;&#x2F;&#x2F; 垂直采样 在垂直模糊Pass时，令offset &#x3D; (0, 1 &#x2F; textureHeight);float4 FragV(Varyings i) : SV_Target&#123; #if _BilinearMode return BOX_BLUR_BILINEAR(_MainTex,i.uv,_KernelSize,float2(0,_BlurScale) * _MainTex_TexelSize.xy); #else return BoxBlur(_MainTex,i.uv * _MainTex_TexelSize.zw,_KernelSize,float2(0,_BlurScale)); #endif&#125; Gaussian Blur 高斯模糊不同于均值模糊，高斯模糊使用正态分布来为周围的像素分配权重。这里有一个网站，可以计算高斯模糊采用的卷积核: gaussian-kernel-calculator要确定一个高斯卷积核，需要提供两个参数: sigma 和 kernelSizekernelSize我们前面已经说了，sigma则是正态分布公式中的标准差。sigma的值越小，正态分布曲线越尖锐，反之则越平坦。因此，对于固定kernelSize的高斯模糊算子，取的sigma越大，则结果越模糊 123456789101112&#x2F;&#x2F;&#x2F;kernel size &#x3D; 7,sigma &#x3D; 1half4 GaussianBlur7Tap(Texture2D tex, float2 pixelCoord, float2 offset) &#123; half4 color &#x3D; half4(0, 0, 0, 0); color +&#x3D; 0.383103 * LOAD_TEXTURE2D_X(tex, pixelCoord); color +&#x3D; 0.241843 * LOAD_TEXTURE2D_X(tex, pixelCoord + offset); color +&#x3D; 0.241843 * LOAD_TEXTURE2D_X(tex, pixelCoord - offset); color +&#x3D; 0.060626 * LOAD_TEXTURE2D_X(tex, pixelCoord + offset * 2); color +&#x3D; 0.060626 * LOAD_TEXTURE2D_X(tex, pixelCoord - offset * 2); color +&#x3D; 0.00598 * LOAD_TEXTURE2D_X(tex, pixelCoord + offset * 3); color +&#x3D; 0.00598 * LOAD_TEXTURE2D_X(tex, pixelCoord - offset * 3); return color;&#125; 没看懂12345678910&#x2F;&#x2F;&#x2F;kernel size &#x3D; 7,sigma &#x3D; 1half4 GaussianBlur7TapBilinear(Texture2D tex, sampler texSampler, float2 uv, float2 offset) &#123; half4 color &#x3D; half4(0, 0, 0, 0); color +&#x3D; 0.4333945 * SAMPLE_TEXTURE2D_X(tex, texSampler, uv + offset * 0.558020); color +&#x3D; 0.4333945 * SAMPLE_TEXTURE2D_X(tex, texSampler, uv - offset * 0.558020); color +&#x3D; 0.066606 * SAMPLE_TEXTURE2D_X(tex, texSampler, uv + offset * 2.089782); color +&#x3D; 0.066606 * SAMPLE_TEXTURE2D_X(tex, texSampler, uv - offset * 2.089782); return color;&#125;#define GAUSSIAN_BLUR_7TAP_BILINEAR(tex,uv,offset) GaussianBlur7TapBilinear(tex,sampler_LinearClamp,uv,offset) Bloom 全屏泛光基础理论让超过一定亮度的像素点变的更亮，并向四周扩散。实现原理： 拿到源RT，进行过滤，过滤规则可以颜色值大于一定阈值就写入，小于则不写入，得到BloomRT BloomRT进行模糊操作(向四周扩散) 将BloomRT叠加到源RT上(合并) 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108using System.Collections;using System.Collections.Generic;using UnityEngine;using UnityEngine.Rendering;using UnityEngine.Rendering.Universal;namespace URPLearn&#123; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 全屏泛光 &#x2F;&#x2F;&#x2F; 1.降采样 &#x2F;&#x2F;&#x2F; 2.高斯模糊 &#x2F;&#x2F;&#x2F; 3.颜色叠加 &#x2F;&#x2F;&#x2F; 参数：threshold(阈值)，Intensity(强度)，Scatter(散射) &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; [CreateAssetMenu(menuName &#x3D; &quot;URPLearn&#x2F;Bloom&quot;)] public class Bloom : PostProcessingEffect &#123; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; Shader &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; public Shader shader; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 阈值 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; [Range(0, 1)] public float threshold; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 降采样 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; [Range(1, 4)] public int downSample &#x3D; 1; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 模糊次数 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; [Range(1, 10)] public int blurIterations &#x3D; 1; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 强度 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; public float intensity; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 散射 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt;121 public float scatter; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 颜色 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; public Color tint; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 材质 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private Material _material; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 模糊处理 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private BlurBlitter _blurBlitter &#x3D; new BlurBlitter(); public override void Render(CommandBuffer cmd, ref RenderingData renderingData, PostProcessingRenderContext context) &#123; if (!shader) &#123; return; &#125; if (_material &#x3D;&#x3D; null) &#123; _material &#x3D; new Material(shader); &#125; _material.SetFloat(&quot;_Threshold&quot;, threshold); _material.SetColor(&quot;_Tint&quot;, tint); _material.SetFloat(&quot;_Intensity&quot;, intensity); var descriptor &#x3D; context.sourceRenderTextureDescriptor; var temp1 &#x3D; context.GetTemporaryRT(cmd, descriptor, FilterMode.Bilinear); &#x2F;&#x2F;first pass，提取光亮部分 cmd.Blit(context.activeRenderTarget, temp1, _material, 0); &#x2F;&#x2F;模糊处理 _blurBlitter.SetSource(temp1, descriptor); _blurBlitter.downSample &#x3D; downSample; _blurBlitter.iteratorCount &#x3D; blurIterations; _blurBlitter.blurType &#x3D; BlurType.Box; _blurBlitter.Render(cmd); cmd.SetGlobalTexture(&quot;_BloomTex&quot;, temp1); &#x2F;&#x2F;combine context.BlitAndSwap(cmd, _material, 3); context.ReleaseTemporaryRT(cmd, temp1); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128Shader &quot;URPLearn&#x2F;PostProcessing&#x2F;Bloom&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; &#125; SubShader &#123; ZTest Always ZWrite Off Cull Off Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; HLSLINCLUDE &#x2F;&#x2F; 宏定义 Material.EnableKeyword #pragma shader_feature _BloomDebug #include &quot;Packages&#x2F;com.unity.render-pipelines.core&#x2F;ShaderLibrary&#x2F;Common.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.core&#x2F;ShaderLibrary&#x2F;Filtering.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Input.hlsl&quot; #include &quot;..&#x2F;Blur&#x2F;Blur.hlsl&quot; &#x2F;&#x2F; 源RT TEXTURE2D_X(_MainTex); SAMPLER(sampler_MainTex); &#x2F;&#x2F; BloomRT TEXTURE2D_X(_BloomTex); SAMPLER(sampler_BloomTex); CBUFFER_START(UnityPerMaterial) float4 _MainTex_TexelSize; float4 _Tint; float _Threshold; float _Intensity; float _KernelSize; float _BlurScale; CBUFFER_END struct Attributes &#123; float4 positionOS : POSITION; float2 uv : TEXCOORD0; UNITY_VERTEX_INPUT_INSTANCE_ID &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; UNITY_VERTEX_OUTPUT_STEREO &#125;; float4 SampleColor(float2 uv) &#123; return SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, uv); &#125; Varyings Vert(Attributes input) &#123; Varyings output; UNITY_SETUP_INSTANCE_ID(input); &#x2F;&#x2F;为支持GPUInstance？ UNITY_INITIALIZE_VERTEX_OUTPUT_STEREO(output); &#x2F;&#x2F;將output变量初始化 output.positionHS &#x3D; TransformObjectToHClip(input.positionOS); &#x2F;&#x2F;模型空间变化到齐次裁剪空间 output.uv &#x3D; input.uv; return output; &#125; &#x2F;&#x2F;&#x2F; 通过阈值获取高亮区域 float4 FragGetLight(Varyings i) :SV_Target&#123; float4 color &#x3D; SampleColor(i.uv); float luminance &#x3D; dot(float3(0.299,0.587,0.114),color.rgb); return color * clamp(luminance - _Threshold, 0, 1) * _Intensity; &#125; &#x2F;&#x2F;&#x2F;水平blur float4 FragBlurH(Varyings i) : SV_Target &#123; return GaussianBlur7Tap(_MainTex,i.uv * _MainTex_TexelSize.zw, float2(_BlurScale,0)); &#125; &#x2F;&#x2F;垂直blur float4 FragBlurV(Varyings i) : SV_Target &#123; return GaussianBlur7Tap(_MainTex,i.uv * _MainTex_TexelSize.zw, float2(0,_BlurScale)); &#125; &#x2F;&#x2F;颜色叠加 float4 Bloom(Varyings i) : SV_Target &#123; return SampleColor(i.uv) + SAMPLE_TEXTURE2D_X(_BloomTex, sampler_BloomTex, i.uv) * _Tint; &#125; ENDHLSL Pass&#123; HLSLPROGRAM #pragma vertex Vert #pragma fragment FragGetLight ENDHLSL &#125; Pass&#123; HLSLPROGRAM #pragma vertex Vert #pragma fragment FragBlurH ENDHLSL &#125; Pass&#123; HLSLPROGRAM #pragma vertex Vert #pragma fragment FragBlurV ENDHLSL &#125; Pass&#123; HLSLPROGRAM #pragma vertex Vert #pragma fragment Bloom ENDHLSL &#125; &#125;&#125; 总结 float luminance = dot(float3(0.299,0.587,0.114),color.rgb); // 计算像素的亮度值，中间的参数可以按自己的来，总和等于1即可 Depth Of Field 景深Depth Of Field 理论基础景深效果产生的本质原因，是相机的对焦和散焦机制。而其背后的光学原理，则是透镜成像。根据凸透镜高斯成像公式:1/f = 1/u + 1/vf: 焦距 - 由凸透镜本身决定v: 物距 - 物体到凸透镜的距离u: 像距 - 物体经过凸透镜后，成像位置与镜片的距离. 当物体通过凸透镜形成的象距正好在胶片位置时，那么我们就能得到一个清晰的成像。反之，象距和胶片差距越大，成像越模糊。 整理下运算公式对应URP Mode = Bokeh准备一下，输入参数有: focalLength 胶片到镜片的距离 (胶距)focusDistance 对焦距离 (物距)aperture 光圈参数 (定义为 镜片焦距/镜片直径)运算符号: rcp 为倒数运算那么有: 焦距公式 f = rcp(rcp(focalLength) + rcp(focusDistance))镜片直径: lensDiam = f * rcp(aperture)根据物距计算像距: 输入参数: objDis输出: imageDis = rcp(rcp(f) - rcp(objDis));根据物距，计算弥散圆直径(CoC): 输入参数: objDis 输出: imageDis = CalculateImageDistance(objDis); CoC = abs(imageDis - focalLength) * lensDiam / focalLength ; 输入参数： depth focalLength输出： objDis = depth - focalLength 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111using System.Collections;using System.Collections.Generic;using UnityEngine;using UnityEngine.Rendering;using UnityEngine.Rendering.Universal;namespace URPLearn&#123; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 景深 &#x2F;&#x2F;&#x2F; 对应URP PPS中DOF的Bokeh模式 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; [CreateAssetMenu(menuName &#x3D; &quot;URPLearn&#x2F;DepthOfField&quot;)] public class DepthOfField : PostProcessingEffect &#123; [Tooltip(&quot;相机对焦的物距，单位m，在公式中记为u&quot;)] [SerializeField] private float _focusDistance &#x3D; 1; [Tooltip(&quot;相机的焦距(这里其实应该是成像胶片到镜头的距离),单位毫米，在公式中记为v&quot;)] [SerializeField] private float _focalLength; [Tooltip(&quot;相机的光圈值F &#x3D; f &#x2F; 镜片直径&quot;)] [SerializeField] private float _aperture &#x3D; 6.3f; [Tooltip(&quot;Blur迭代次数，对性能有影响&quot;)] [SerializeField] private int _blurIteratorCount &#x3D; 1; [SerializeField] private Shader _shader; private Material _material; private void OnValidate() &#123; _aperture &#x3D; Mathf.Clamp(_aperture, 1, 32); _focalLength &#x3D; Mathf.Clamp(_focalLength, 1, 300); _focusDistance &#x3D; Mathf.Max(_focusDistance, 0.1f); _blurIteratorCount &#x3D; Mathf.Clamp(_blurIteratorCount, 1, 5); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 焦距倒数 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private float rcpf &#123; get &#123; return (0.001f &#x2F; _focusDistance + 1 &#x2F; _focalLength); &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 计算成像距离 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private float CalculateImageDistance(float objDis) &#123; return 1 &#x2F; (rcpf - 0.001f &#x2F; objDis); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 计算弥散圆直径 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private float CalculateConfusionCircleDiam(float objDis) &#123; var imageDis &#x3D; CalculateImageDistance(objDis); return Mathf.Abs(imageDis - _focalLength) &#x2F; (_focalLength * rcpf * _aperture); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 光圈直径 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private float apertureDiam &#123; get &#123; return (1 &#x2F; (rcpf * _aperture)); &#125; &#125; public override void Render(CommandBuffer cmd, ref RenderingData renderingData, PostProcessingRenderContext context) &#123; if (_shader &#x3D;&#x3D; null) &#123; return; &#125; if (_material &#x3D;&#x3D; null) &#123; _material &#x3D; new Material(_shader); &#125; var DOFParams &#x3D; new Vector4( rcpf, _focalLength, 1 &#x2F; (_focalLength * rcpf * _aperture), 0 ); _material.SetVector(&quot;_DOFParams&quot;, DOFParams); for (int i &#x3D; 0; i &lt; _blurIteratorCount; i++) &#123; context.BlitAndSwap(cmd, _material, 0); context.BlitAndSwap(cmd, _material, 1); &#125; &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112Shader &quot;URPLearn&#x2F;PostProcessing&#x2F;DepthOfField&quot;&#123; Properties &#123; _MainTex(&quot;Texture&quot;, 2D) &#x3D; &quot;white&quot; &#123;&#125; &#125; SubShader &#123; ZTest Always ZWrite Off Cull Off Tags &#123; &quot;RenderType&quot; &#x3D; &quot;Opaque&quot; &quot;RenderPipeline&quot; &#x3D; &quot;UniversalPipeline&quot;&#125; HLSLINCLUDE #include &quot;Packages&#x2F;com.unity.render-pipelines.core&#x2F;ShaderLibrary&#x2F;Common.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.core&#x2F;ShaderLibrary&#x2F;Filtering.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Core.hlsl&quot; #include &quot;Packages&#x2F;com.unity.render-pipelines.universal&#x2F;ShaderLibrary&#x2F;Input.hlsl&quot; #include &quot;..&#x2F;Blur&#x2F;Blur.hlsl&quot; TEXTURE2D_X(_MainTex); TEXTURE2D_X_FLOAT(_CameraDepthTexture); CBUFFER_START(UnityPerMaterial) float4 _MainTex_TexelSize; float4 _DOFParams; CBUFFER_END #define rcpF _DOFParams.x #define focalLength _DOFParams.y #define rcpFFA _DOFParams.z &#x2F;&#x2F; rcp(_focalLength * rcpf * _aperture) struct Attributes &#123; float4 positionOS : POSITION; float2 uv : TEXCOORD0; UNITY_VERTEX_INPUT_INSTANCE_ID &#125;; struct Varyings &#123; float4 positionHS : SV_POSITION; float2 uv : TEXCOORD0; UNITY_VERTEX_OUTPUT_STEREO &#125;; Varyings Vert(Attributes input) &#123; Varyings output; UNITY_SETUP_INSTANCE_ID(input); &#x2F;&#x2F;为支持GPUInstance？ UNITY_INITIALIZE_VERTEX_OUTPUT_STEREO(output); &#x2F;&#x2F;將output变量初始化 output.positionHS &#x3D; TransformObjectToHClip(input.positionOS); &#x2F;&#x2F;模型空间变化到齐次裁剪空间 output.uv &#x3D; input.uv; return output; &#125; &#x2F;&#x2F; 采样深度 float SampleDepth(float2 uv) &#123; return LOAD_TEXTURE2D_X(_CameraDepthTexture, _MainTex_TexelSize.zw * uv).x; &#125; &#x2F;&#x2F; 线性深度 float SampleEyeLinearDepth(float2 uv) &#123; return LinearEyeDepth(SampleDepth(uv), _ZBufferParams); &#125; &#x2F;&#x2F;计算像距 float4 CalculateImageDistance(float objDis) &#123; return rcp(rcpF - rcp(objDis)); &#125; &#x2F;&#x2F;弥散圆直径 float CalculateConfusionCircleDiam(float objDis) &#123; float imageDis &#x3D; CalculateImageDistance(objDis); return abs(imageDis - focalLength) * rcpFFA; &#125; float CalculateBlurFactor(float2 uv) &#123; float depth &#x3D; SampleEyeLinearDepth(uv); &#x2F;&#x2F; Depth大小为m float objDis &#x3D; 1000 * depth - focalLength; &#x2F;&#x2F; 传入的focalLength为mm float diam &#x3D; CalculateConfusionCircleDiam(objDis); return diam; &#125; float4 FragH(Varyings i) :SV_Target&#123; float factor &#x3D; CalculateBlurFactor(i.uv); return BoxBlur(_MainTex, i.uv * _MainTex_TexelSize.zw, 2, float2(factor, 0)); &#125; float4 FragV(Varyings i) : SV_Target&#123; float factor &#x3D; CalculateBlurFactor(i.uv); return BoxBlur(_MainTex, i.uv * _MainTex_TexelSize.zw, 2, float2(0, factor)); &#125; ENDHLSL Pass &#123; HLSLPROGRAM #pragma vertex Vert #pragma fragment FragH ENDHLSL &#125; Pass &#123; HLSLPROGRAM #pragma vertex Vert #pragma fragment FragV ENDHLSL &#125; &#125;&#125; 总结学习各类效果前，需要先清楚其效果原理，大问题拆分成多个小问题，一个个问题对症下药的去解决目前对于基础原理也不懂，只会直接套公式 SSAO 屏幕空间环境光遮蔽理论基础代码总结","categories":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/categories/Unity/"},{"name":"Shader","slug":"Unity/Shader","permalink":"https://skierhou.github.io/categories/Unity/Shader/"}],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/tags/Unity/"},{"name":"Shader","slug":"Shader","permalink":"https://skierhou.github.io/tags/Shader/"}]},{"title":"SRP学习汇总","slug":"Graphics/SRP学习汇总","date":"2021-08-24T16:00:00.000Z","updated":"2021-10-28T02:26:10.648Z","comments":true,"path":"2021/08/25/Graphics/SRP学习汇总/","link":"","permalink":"https://skierhou.github.io/2021/08/25/Graphics/SRP%E5%AD%A6%E4%B9%A0%E6%B1%87%E6%80%BB/","excerpt":"","text":"","categories":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/categories/Unity/"},{"name":"Shader","slug":"Unity/Shader","permalink":"https://skierhou.github.io/categories/Unity/Shader/"}],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/tags/Unity/"},{"name":"Shader","slug":"Shader","permalink":"https://skierhou.github.io/tags/Shader/"}]},{"title":"BuildInShader学习汇总","slug":"Graphics/BuildInShader学习汇总","date":"2021-08-24T16:00:00.000Z","updated":"2021-11-02T06:09:09.276Z","comments":true,"path":"2021/08/25/Graphics/BuildInShader学习汇总/","link":"","permalink":"https://skierhou.github.io/2021/08/25/Graphics/BuildInShader%E5%AD%A6%E4%B9%A0%E6%B1%87%E6%80%BB/","excerpt":"","text":"","categories":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/categories/Unity/"},{"name":"Shader","slug":"Unity/Shader","permalink":"https://skierhou.github.io/categories/Unity/Shader/"}],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/tags/Unity/"},{"name":"Shader","slug":"Shader","permalink":"https://skierhou.github.io/tags/Shader/"}]},{"title":"Unity大世界模块记录","slug":"Graphics/Unity大世界模块记录","date":"2021-08-22T16:00:00.000Z","updated":"2021-08-23T07:58:59.310Z","comments":true,"path":"2021/08/23/Graphics/Unity大世界模块记录/","link":"","permalink":"https://skierhou.github.io/2021/08/23/Graphics/Unity%E5%A4%A7%E4%B8%96%E7%95%8C%E6%A8%A1%E5%9D%97%E8%AE%B0%E5%BD%95/","excerpt":"","text":"地形分割/场景分割/异步加载 Terrian分割，一个地形块 = 一个场景， 场景异步加载卸载 场景物体的加载卸载 多场景编辑操作 目前工作流：大世界由一个大场景(所有场景物体)分割 光照烘培 Terrian光照信息烘培以及正确加载 场景物体光照信息烘培以及正确加载 烘培完大场景的Lightmap后，再将光照贴图打包，记录每张贴图 运行时动态设置当前lightmap以及刷新场景物体的Lightmap数据 静态物体合批操作 静态合批：会增加包体以及内存大小，不考虑使用，动态合批：限制过多也不考虑使用， GPUInstacing：减少DC，使用CommandBuffer.DrawMeshInstanced更好GPUinstacing光照贴图：https://www.xuanyusong.com/archives/4640优化GPUInstancing：https://www.xuanyusong.com/archives/4683BatchRendererGroup：https://zhuanlan.zhihu.com/p/105616808 SRPBatcher：不减少DC，加速CPU设置（减少SetPass Call），对于移动平台提升不是很明显，SRPBatcher与GPUInstacing只能同时使用一种，GPUInstacing主要用于场景内重复的树等，交互和碰撞等可以使用一个空碰撞体来实现，而SRPBatcher拥有实体，使用起来更方便如果场景里Material多于5个 使用SRPBatcher会优于GPUInstacing 动态/静态合批/GPUInstancing/SRP Batcher：https://shimo.im/docs/6wk89JDtgQ6jcxjT/read 关于场景物体优化策略： GPUInstancing用于不可交互的草/树 BatchRendererGroup需要com.unity.rendering.hybrid包，官方用于DOTS渲染 SPRBatcher： SRP材质支持就行 使用它就不用管静态/动态合批了 静态合批：不使用SRP还是要用，不过目前来说用处不大，还会影响内存 动态合批：条件太多，使用不当还会造成性能下降，不用 阴影 光照烘培能够正常设置，其烘培的阴影也正确了 地形刷 不能使用内置的，很耗性能地形拼接问题 接缝处插值过渡(高度+贴图等)结合天气系统项目链接相关链接 Unity手游开发札记——2.5D大世界动态加载实战 祖龙技术总监：我们是怎么做“开放世界”的？ Unity大世界超多物体渲染—BatchRendererGroup Unity实现移动平台超大地形RVT Unity的RVT应用（一） Unity的RVT应用（二）地上物与地形衔接","categories":[{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/categories/Graphics/"}],"tags":[{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/tags/Graphics/"}]},{"title":"渲染课程总结","slug":"Graphics/渲染课程总结","date":"2021-06-07T06:30:01.000Z","updated":"2021-12-21T11:48:30.700Z","comments":true,"path":"2021/06/07/Graphics/渲染课程总结/","link":"","permalink":"https://skierhou.github.io/2021/06/07/Graphics/%E6%B8%B2%E6%9F%93%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/","excerpt":"","text":"渲染综述色彩空间 线性空间：物理世界的色彩空间，如果光照强一倍，亮度也会增强一倍 伽马(Gamma)空间： 显示器用于颜色矫正，通常值为2.2，对颜色进行灰度，亮度矫正打个比方，功率为50%的灰色，人眼实际感知亮度为：0.5的2.2开根 = 0.7297而人眼认为的50%中灰色，实际功率为：0.5的2.2次幂 = 0.2176 sRGB色彩空间：sRGB对应的是Gamma0.45所在的空间，如储存的照片相当于对图片先进行了Gamma0.45的矫正，在显示器输出时又进行了Gamma2.2矫正通常使用时，基础颜色等都勾选sRGB，如法线/粗糙度/金属度等贴图需要取消勾选sRGB 渲染技术术语 坐标系：在渲染过程中需要将坐标点以及向量等在不同坐标空间转换（模型空间，齐次裁剪空间，屏幕空间，相机空间，世界空间，光源空间等） 顶点，片段，像素：模型上的顶点，片段是光栅化的产物，像素是屏幕空间像素 深度测试，蒙版测试：1234567891011121314深度测试：ZTest 可取值为：Greater , GEqual , Less , LEqual , Equal , NotEqual , Always , Never , Off，默认是 LEqual，ZTest Off 等同于 ZTest Always。ZWrite 可取值为：On , Off，默认是 On。蒙版测试：Stencil&#123; Ref 1 &#x2F;&#x2F;Reference Value ReadMask 255 &#x2F;&#x2F;读取的时候将该值 maskValue 与 referenceValue 和 stencilBufferValue 分别进行按位与（&amp;）操作 WriteMask 255 &#x2F;&#x2F;写入的时候将该值与 referenceValue 和 stencilBufferValue 分别进行按位与（&amp;）操作 Comp Always &#x2F;&#x2F;拿当前参考值与像素缓存值比较 Pass Replace &#x2F;&#x2F;两个测试都通过了 进行处理 Fail Keep &#x2F;&#x2F;两个测试都没通过 进行处理 ZFail Replace &#x2F;&#x2F;模板测试通过而深度测试没通过 进行处理&#125; Shader： 渲染管线 裁剪(Culling)： 对象级裁剪：类型裁剪，几何体裁剪，遮挡裁剪 顶点级裁剪：视口裁剪 像素级裁剪：EarlyZ 渲染物件： 渲染状态 材质，纹理，各种参数 渲染顺序 后处理(Post Processing)：对屏幕渲染结果进行加工 光照框架对于N个物体受M盏光的影响框架|算法复杂度|优点|缺点:–|:–|:–|:–forward shading(前向渲染)|O(N*M)|实现简单，兼容性好|性能较低，光源个数限制严格deffered shading(延迟渲染)|O(N+M)|支持多光源，性能较好|forward+ shading(前向+渲染)||| 硬件 GPU：寄存器，Cache，显存 （GPU读取顺序：寄存器找不到-&gt;Cache-&gt;显存-&gt;CPU） 带宽 图形API DirectX，OpenGL，OpenGL ES，WebGL，Vulkan，Metal 渲染应用方式 离线渲染：电影，动画，烘培LightMap 实时渲染：游戏，VR 基础光照模型 Lambert： max(0,dot(L,N)) HalfLambert： max(0,dot(L,N)) * 0.5 + 0.5 Phong： pow(max(0,dot(reflect(-L,N), V)), Gloss) BlinnPhong： pow(max(0,dot(normalize(L+V), N)), Gloss) PBR 满足以下几点的光照模型，符合PBR模型： 微表面：不同材质的平面，有很多不同朝向不一的微小平面 能量守恒：出射光的总量不超过入射光的总量 反射方程：使用基于物理的BRDF(双向反射分布函数) PBR反射方程：L(o) = f(fr(p,wi,wo) * Li(p,wi) * dot(n,wi) * dwi) brdf方程： fr(p,wi,wo) = k(d)*f(lambert) + K(s)*f(cook-torrance) f(lamber) = c / Π ∫(cook-torrance) = DFG / (4*dot(wo,n)*dot(wi,n)) D：法线分布函数（NDF），估算微平面的整体取向，公式：a^2 / (Π * (NdotH^2) * (a^2-1) + 1)^2 （注：a表示粗糙度） F: 菲尼尔方程，用于描述表面反射光所占比例， 公式： F0 + (1 - F0) * pos(1 - cosTheta, 5) （注：F0表示不同材质的垂直方向的反射率，直接光照中cosTheta：HdotV或HdotL，间接光照中cosTheta：NdotV） G：几何函数，用于计算微表面，自阴影， 公式：NdotV / (NdotV(1.0 - k) + k) （注：k由粗糙度a计算，直接光照：k=(a+1)^2 / 8， 间接光照：k=a^2 / 2） K(d)：(1-F)*(1-metallic) 1234567891011121314151617181920212223242526272829303132333435363738394041424344&#x2F;&#x2F;计算直接光照half3 CalcDirectLight(half metalness, half roughness, half3 albedo, half3 F0, half3 normal, half3 viewDir, half NoV, float3 worldPos)&#123; &#x2F;&#x2F;准备参数 half3 lightDir &#x3D; normalize(_WorldSpaceLightPos0.xyz - worldPos * _WorldSpaceLightPos0.w); &#x2F;&#x2F;获取光线方向 half3 halfDir &#x3D; normalize(viewDir + lightDir); &#x2F;&#x2F;计算半角方向 half NoL &#x3D; saturate(dot(normal, lightDir)); &#x2F;&#x2F;计算法线光线点积 half NoH &#x3D; saturate(dot(normal, halfDir)); &#x2F;&#x2F;计算法线半角点积 half HoL &#x3D; saturate(dot(halfDir, lightDir)); &#x2F;&#x2F;计算半角光线点积，同半角视线点积 &#x2F;&#x2F;计算方程参数 half3 F &#x3D; FresnelSchlick(HoL, F0); &#x2F;&#x2F;计算菲涅尔 half G &#x3D; GeometrySmith(NoV, NoL, pow(roughness + 1.0, 2) &#x2F; 8.0); &#x2F;&#x2F;计算遮挡 half D &#x3D; DistributionGGX(NoH, roughness * roughness); &#x2F;&#x2F;计算分布 half3 kD &#x3D; (1.0 - F) * (1.0 - metalness); &#x2F;&#x2F;计算漫反射系数 &#x2F;&#x2F;计算直接光照结果 half3 directDiffuse &#x3D; kD * albedo &#x2F; BRDF_PI; &#x2F;&#x2F;计算漫反射 half3 directSpecular &#x3D; F * (D * G) &#x2F; (4.0 * max(NoV * NoL, EPSILSON)); &#x2F;&#x2F;计算高光 half3 directLightIn &#x3D; _LightColor0.rgb * BRDF_PI; &#x2F;&#x2F;获取直接光照颜色 return (directDiffuse + directSpecular) * NoL * directLightIn;&#125;&#x2F;&#x2F;菲涅尔函数half3 FresnelSchlick(half NoV, half3 F0)&#123; return F0 + (1.0 - F0) * pow(1.0 - NoV, 5);&#125;&#x2F;&#x2F;几何函数half GeometrySchlickGGX(half NoV, half k)&#123; return NoV &#x2F; max(NoV * (1.0 - k) + k, EPSILSON);&#125;&#x2F;&#x2F;几何函数half GeometrySmith(half NoV, half NoL, half k)&#123; return GeometrySchlickGGX(NoV, k) * GeometrySchlickGGX(NoL, k);&#125;&#x2F;&#x2F;分布函数 alpha&#x3D;roughness*roughnesshalf DistributionGGX(half NoH, half alpha)&#123; half a2 &#x3D; alpha * alpha; half denom &#x3D; pow2(NoH * NoH * (a2 - 1.0) + 1.0); return a2 &#x2F; max(denom * BRDF_PI, EPSILSON);&#125; IBL间接光照 CubeMap IrradianceMap 或者ShadeSH9() 计算间接光照的diffuse 预高光积分图，或者高光积分算法计算间接光照的specular 123456789101112131415161718192021222324252627282930313233343536373839&#x2F;&#x2F;计算间接光照half3 CalcIndirectLight(half metalness, half roughness, half3 albedo, half3 F0, half3 normal, half3 viewDir, half NoV)&#123; &#x2F;&#x2F;准备参数 half3 F &#x3D; FresnelSchlick(NoV, F0); &#x2F;&#x2F;计算菲涅尔 half3 kD &#x3D; (1.0 - F) * (1.0 - metalness); &#x2F;&#x2F;计算漫反射系数 &#x2F;&#x2F;计算间接漫反射 &#x2F;&#x2F;half3 indirectDiffuse &#x3D; texCUBE(_IrradianceCube, normal).rgb; half3 indirectDiffuse &#x3D; ShadeSH9(half4(normal, 1.0)); indirectDiffuse *&#x3D; kD * albedo; &#x2F;&#x2F;计算间接高光 half mip &#x3D; GetMipLevelFromRoughness(roughness); &#x2F;&#x2F;计算粗糙度对应MIP half3 reflDir &#x3D; reflect(-viewDir, normal); &#x2F;&#x2F;计算视线反射方向 &#x2F;&#x2F;half3 indirectSpecular &#x3D; texCUBElod(_RadianceCube, half4(reflDir, mip)).rgb; half4 rgbm &#x3D; UNITY_SAMPLE_TEXCUBE_LOD(unity_SpecCube0, reflDir, mip); half3 indirectSpecular &#x3D; DecodeHDR(rgbm, unity_SpecCube0_HDR); &#x2F;&#x2F;高光积分#if USE_BRDF_INTEGRATION_MAP half2 envBRDF &#x3D; tex2D(_BRDFIntegrationMap, half2(NoV, roughness)).rg;#else half2 envBRDF &#x3D; IntegrateSpecularBRDF(NoV, roughness);#endif indirectSpecular *&#x3D; F * envBRDF.x + envBRDF.y; &#x2F;&#x2F;计算间接光照结果 return (indirectDiffuse + indirectSpecular) * _IndirectIntensity;&#125;half2 IntegrateSpecularBRDF(half NoV, half roughness)&#123; const half4 c0 &#x3D; half4(-1, -0.0275, -0.572, 0.022); const half4 c1 &#x3D; half4(1, 0.0425, 1.04, -0.04); half4 r &#x3D; roughness * c0 + c1; half a004 &#x3D; min(r.x * r.x, exp2(-9.28 * NoV)) * r.x + r.y; return half2(-c1.z, c1.z) * a004 + r.zw;&#125; PBR两种工作流 metaillic/roughness工作流（金属/粗糙度） specular/glossness工作流（高光/光泽度）区别： 渲染管线Bulid-in内置管线，不可自定义 SRP可编程的渲染管线 URP通用渲染管线：Unity 2019.2.0版本后支持Universal Render Pipeline HDRP高清渲染管线 LWRPURP的前身 后处理 LUT（ColorGrading） 颜色分级(调整暖色/饱和度这种) Bloom 全屏泛光 GaussianBlur 高斯模糊 DepthOfField 景深模糊 RadialBlur 径向模糊 Post-ProcessStack角色渲染头发 各项异性光照 Kajiya-Kay光照模型：使用切线/副切线计算高光，高光计算两层，往法线方向偏移。 123456789101112131415&#x2F;&#x2F; 计算高光值float StrandSpecular (float3 T, float3 V, float3 L, float p)&#123; float3 H &#x3D; normalize(L + V); float dotTH &#x3D; dot(T, H); float sinTH &#x3D; sqrt(1.0 - dotTH*dotTH); float dirAtten &#x3D; smoothstep(-1.0, 0.0, dotTH); return dirAtten * pow(sinTH, p);&#125;&#x2F;&#x2F; 计算偏移值 传入StrandSpecular中的Tfloat3 ShiftTangent(float3 T,float3 N,float shift)&#123; return normalize(T + shift * N); &#125; 皮肤 次表面散射(SSS) 阴影渲染 标准阴影算法步骤：(1) 以光源空间绘制：生成深度图(2) 以相机空间绘制：将顶点坐标转换值光源空间的顶点z值得到d值(3) 以顶点再光源空间的xy值为uv采样ShadowMap，获取阴影z值(4) d &gt;= z 阴影内， d &lt; z阴影外 软阴影：通常使用PCF，PCSS PCF：从目标点周围多个点做偏移采样，取平均阴影值 PCSS： 阴影失真：Shadow Acne，Peter Panning 级联阴影 Cascade Shadowmap： ScreenSpaceShadow： ShadowVolume： GI Ray Tracing Path Tracing Shader调试工具Frame DebugerRenderdocXCode环境效果动画与特效NPR(Non Photorealistic Rendering) 非真实渲染","categories":[{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/categories/Graphics/"}],"tags":[{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/tags/Graphics/"}]},{"title":"ZeroMQ使用","slug":"Service/ZeroMQ使用","date":"2021-04-20T06:30:01.000Z","updated":"2021-04-20T12:17:20.978Z","comments":true,"path":"2021/04/20/Service/ZeroMQ使用/","link":"","permalink":"https://skierhou.github.io/2021/04/20/Service/ZeroMQ%E4%BD%BF%E7%94%A8/","excerpt":"","text":"ZeroMQ简介消息模型ZeroMQ将消息通信分成4种模型，分别是一对一结对模型（Exclusive-Pair）、请求回应模型（Request-Reply）、发布订阅模型（Publish-Subscribe）、推拉模型（Push-Pull）。 参考官方C#官方github Samples文章1文章2","categories":[{"name":"Service","slug":"Service","permalink":"https://skierhou.github.io/categories/Service/"}],"tags":[{"name":"ZeroMQ","slug":"ZeroMQ","permalink":"https://skierhou.github.io/tags/ZeroMQ/"}]},{"title":"KCP使用","slug":"Service/KCP网络协议使用","date":"2021-04-20T06:30:01.000Z","updated":"2021-04-25T06:27:04.258Z","comments":true,"path":"2021/04/20/Service/KCP网络协议使用/","link":"","permalink":"https://skierhou.github.io/2021/04/20/Service/KCP%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E4%BD%BF%E7%94%A8/","excerpt":"","text":"API介绍 表头 表头 ikcp_waitsnd 检查等待发送的消息，如果超出最大等待大小，应该断开连接 ikcp_recv kcp将接收到的kcp数据包还原成之前kcp发送的buffer数据 ikcp_input kcp接收到下层协议UDP传进来的数据底层数据buffer转换成kcp的数据包格式 ikcp_flush 将发送队列中的数据通过下层协议UDP进行发送 ikcp_send 把要发送的buffer分片成KCP的数据包格式，插入待发送队列中 ikcp_nodelay //nodelay: 0 不启用，1启用快速重传模式//interval： 内部flush刷新时间//resend: 0（默认）表示关闭。可以自己设置值，若设置为2（则2次ACK跨越将会直接重传）//nc: 是否关闭拥塞控制，0（默认）代表不关闭，1代表关闭 参考文章","categories":[{"name":"Service","slug":"Service","permalink":"https://skierhou.github.io/categories/Service/"}],"tags":[{"name":"KCP","slug":"KCP","permalink":"https://skierhou.github.io/tags/KCP/"}]},{"title":"OpenGL学习","slug":"Graphics/OpenGL","date":"2021-03-31T06:30:01.000Z","updated":"2021-03-31T05:44:17.875Z","comments":true,"path":"2021/03/31/Graphics/OpenGL/","link":"","permalink":"https://skierhou.github.io/2021/03/31/Graphics/OpenGL/","excerpt":"","text":"环境安装OpenGL安装教程计算机图形学入门教程 使用说明","categories":[{"name":"OpenGL","slug":"OpenGL","permalink":"https://skierhou.github.io/categories/OpenGL/"}],"tags":[{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/tags/Graphics/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://skierhou.github.io/tags/OpenGL/"}]},{"title":"UnityShader基础渲染知识点概况","slug":"Graphics/UnityShader","date":"2021-03-31T06:30:01.000Z","updated":"2021-04-25T08:56:39.486Z","comments":true,"path":"2021/03/31/Graphics/UnityShader/","link":"","permalink":"https://skierhou.github.io/2021/03/31/Graphics/UnityShader/","excerpt":"","text":"渲染管线前向渲染 “LightMode” = “ForwardBase”， 延迟渲染后处理灯光设置 灯光可以设置Auto/Important/UnImportant，Auto：当满足逐像素光照则为逐像素，不满足则为逐顶点，都不满足则SH处理，Important：逐像素光照，UnImportant：逐顶点光照或SH处理。 光源的Cookie：灯光照下的样子，点光源使用立方体贴图CubeMap，聚光灯使用2D贴图，使用时需要将贴图类型设置为Cookie 平行光(Directional Light)，全局平行光， 点光源(Point Light)，球形灯光，一般用SH球谐函数在ForwardBase中就算顶点光照 聚光灯(Spot Light)，锥形灯光,一般用SH球谐函数在ForwardBase中就算顶点光照 伽马(Gamma) 显示器用于颜色矫正，通常值为2.2，对颜色进行灰度，亮度矫正打个比方，功率为50%的灰色，人眼实际感知亮度为：0.5的2.2开根 = 0.7297而人眼认为的50%中灰色，实际功率为：0.5的2.2次幂 = 0.2176 Unity中可选择的颜色空间线性空间，伽马空间。 常用API记录 API 定义 注释 EnergyConservationBetweenDiffuseAndSpecular 定义于UnityStandardUtils.cgine 漫反射和镜面反射的能力守恒函数 DiffuseAndSpecularFromMetallic 定义于UnityStandardUtils.cgine 金属性设置,其中金属性参数需要标记[Gamma]，受Gamma矫正后的参数 UNITY_BDRP_PBS 定义于UnityPBSLighting.cgine 基于物理的着色，双向反射率分布函数 UNITY_LIGHT_ATTENUATION 定义于AutoLight.cginc 光照衰减值 #pragma multi_compile 多重定义宏 如#pragma multi_compile DIRECTIONAL POINT SPOT 可以define(..)判断哪些宏被定义了，然后执行特定的逻辑，C#处可以启用/关闭Shader宏：Shader.EnableKeyword(string);Shader.DisableKeyword(string); ShadeSH9 UnityCG.cginc 球谐函数， ComputeScreenPos 计算屏幕坐标 计算屏幕坐标：参数 顶点坐标 COMPUTE_EYEDEPTH 计算视野深度 计算视野深度：参数 返回值(视野深度) UNITY_DECLARE_DEPTH_TEXTURE(_CameraDepthTexture) 获取相机深度图 获取相机深度图 SAMPLE_DEPTH_TEXTURE_PROJ 采样深度图 相当于：tex2Dproj(sampler, uv).r LinearEyeDepth 线性视野深度0-1区间 ddx,ddy 求当前像素的值其临近像素上的变化率，分别对应x轴/y轴 常见效果实现记录参考基础渲染系列教程20篇UnityShader入门精要计算渐变颜色网站免费材质贴图","categories":[{"name":"UnityShader","slug":"UnityShader","permalink":"https://skierhou.github.io/categories/UnityShader/"}],"tags":[{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/tags/Graphics/"},{"name":"UnityShader","slug":"UnityShader","permalink":"https://skierhou.github.io/tags/UnityShader/"}]},{"title":"Games101作业","slug":"Graphics/Games101作业","date":"2021-03-31T06:30:01.000Z","updated":"2021-05-19T09:10:21.919Z","comments":true,"path":"2021/03/31/Graphics/Games101作业/","link":"","permalink":"https://skierhou.github.io/2021/03/31/Graphics/Games101%E4%BD%9C%E4%B8%9A/","excerpt":"","text":"Game101学习笔记作业0112345678910作业01：本次作业的任务是填写一个旋转矩阵和一个透视投影矩阵。给定三维下三个 点 v0(2.0,0.0,−2.0),v1(0.0,2.0,−2.0),v2(−2.0,0.0,−2.0), 你需要将这三个点的坐 标变换为屏幕坐标并在屏幕上绘制出对应的线框三角形 (在代码框架中，我们已 经提供了 draw_triangle 函数，所以你只需要去构建变换矩阵即可)。简而言之， 我们需要进行模型、视图、投影、视口等变换来将三角形显示在屏幕上。在提供 的代码框架中，我们留下了模型变换和投影变换的部分给你去完成。 如果你对上述概念有任何不清楚或疑问，请复习课堂笔记或询问助教。 以下是你需要在 main.cpp 中修改的函数（请不要修改任何的函数名和其他 已经填写好的函数，并保证提交的代码是已经完成且能运行的）：• get_model_matrix(float rotation_angle): 逐个元素地构建模型变换矩 阵并返回该矩阵。在此函数中，你只需要实现三维中绕 z 轴旋转的变换矩阵， 而不用处理平移与缩放。• get_projection_matrix(float eye_fov, float aspect_ratio, float zNear, float zFar):使用给定的参数逐个元素地构建透视投影矩阵并返回 该矩阵。• [Optional] main(): 自行补充你所需的其他操作。当你在上述函数中正确地构建了模型与投影矩阵，光栅化器会创建一个窗口 显示出线框三角形。由于光栅化器是逐帧渲染与绘制的，所以你可以使用 A 和 D 键去将该三角形绕 z 轴旋转 (此处有一项提高作业，将三角形绕任意过原点的 轴旋转)。当你按下 Esc 键时，窗口会关闭且程序终止。 代码： 效果显示如下图： 作业021234567891011121314作业02：在上次作业中，虽然我们在屏幕上画出一个线框三角形，但这看起来并不是 那么的有趣。所以这一次我们继续推进一步——在屏幕上画出一个实心三角形， 换言之，栅格化一个三角形。上一次作业中，在视口变化之后，我们调用了函数 rasterize_wireframe(const Triangle&amp; t)。但这一次，你需要自己填写并调用 函数 rasterize_triangle(const Triangle&amp; t)。该函数的内部工作流程如下： 1. 创建三角形的 2 维 bounding box。 2. 遍历此 bounding box 内的所有像素（使用其整数索引）。然后，使用像素中 心的屏幕空间坐标来检查中心点是否在三角形内。 3. 如果在内部，则将其位置处的插值深度值 (interpolated depth value) 与深度 缓冲区 (depth buffer) 中的相应值进行比较。 4. 如果当前点更靠近相机，请设置像素颜色并更新深度缓冲区 (depth buffer)。你需要修改的函数如下： • rasterize_triangle(): 执行三角形栅格化算法 • static bool insideTriangle(): 测试点是否在三角形内。你可以修改此函 数的定义，这意味着，你可以按照自己的方式更新返回类型或函数参数。因为我们只知道三角形三个顶点处的深度值，所以对于三角形内部的像素， 我们需要用插值的方法得到其深度值。我们已经为你处理好了这一部分，因为有 关这方面的内容尚未在课程中涉及。插值的深度值被储存在变量z_interpolated 中。请注意我们是如何初始化 depth buffer 和注意 z values 的符号。为了方便 同学们写代码，我们将 z 进行了反转，保证都是正数，并且越大表示离视点越远。 效果显示如下图： 作业031234567891011作业03：在这次编程任务中，我们会进一步模拟现代图形技术。我们在代码中添加了 Object Loader(用于加载三维模型), Vertex Shader 与 Fragment Shader，并且支持 了纹理映射。 而在本次实验中，你需要完成的任务是: 1. 修改函数 rasterize_triangle(const Triangle&amp; t) in rasterizer.cpp: 在此 处实现与作业02类似的插值算法，实现法向量、颜色、纹理颜色的插值。 2. 修改函数 get_projection_matrix() in main.cpp: 将你自己在之前的实验中 实现的投影矩阵填到此处，此时你可以运行.&#x2F;Rasterizer output.png normal 来观察法向量实现结果。 3. 修改函数 phong_fragment_shader() in main.cpp: 实现 Blinn-Phong 模型计 算 Fragment Color. 4. 修改函数 texture_fragment_shader() in main.cpp: 在实现 Blinn-Phong 的基础上，将纹理颜色视为公式中的 kd，实现 Texture Shading Fragment Shader. 5. 修改函数 bump_fragment_shader() in main.cpp: 在实现 Blinn-Phong 的 基础上，仔细阅读该函数中的注释，实现 Bump mapping. 6. 修改函数 displacement_fragment_shader() in main.cpp: 在实现 Bump mapping 的基础上，实现 displacement mapping.代码： 作业04作业05作业06作业07作业08作业09作业10作业11参考GAMES101-现代计算机图形学入门-闫令琪","categories":[{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/categories/Graphics/"}],"tags":[{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/tags/Graphics/"}]},{"title":"Games101学习笔记","slug":"Graphics/Games101学习笔记","date":"2021-03-31T06:30:01.000Z","updated":"2021-05-19T07:33:33.748Z","comments":true,"path":"2021/03/31/Graphics/Games101学习笔记/","link":"","permalink":"https://skierhou.github.io/2021/03/31/Graphics/Games101%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"相关链接 矩阵向量等基础3D数学知识 Games101作业 几何变换应用（几何变换的详细计算步骤）Model Tranform(模型变换)在空间中摆放需要相机，模型等操作，放置模型。 View Tranform(视图变换)原理：将场景相机移动到坐标原点，并朝向-z方向，其他物体顶点于相机相对位置保持一致，即乘上相同的变换矩阵移动相机到坐标原点需要平移+旋转矩阵，平移矩阵可以直接通过坐标得出旋转矩阵计算步骤： 需要将原y轴旋转至(0,1,0)方向，将原z轴旋转至(0,0,-1)方向，将原x轴旋转至(1,0,0)方向 先设当前相机坐标轴表示为[X:g×t,Y:t,Z:g] (注：g×t，g叉乘t)，原点规范的坐标轴为X(1,0,0),Y(0,1,0),Z(0,0,1)。从当前旋转至规范坐标轴较为困难，但从规范坐标轴旋转至当前坐标轴非常简单，求y轴旋转：M1*(0,1,0,1)=( X(t),Y(t),Z(t),1 )求z轴旋转：M2*(0,0,-1,1)=( X(g),Y(g),Z(g),1 ) 注：朝向-z轴求x轴旋转：M3*(1,0,0,1)=( X(gxt),Y(gxt),Z(gxt),1 )M1+M2+M3最终计算的旋转矩阵如下： 得到的旋转矩阵为：规范朝向-相机当前朝向的矩阵，我们需要求出：相机当前朝向-规范朝向的矩阵，这相当于求矩阵的逆需要掌握前提条件：旋转矩阵满足一个原则，矩阵的转置=矩阵的逆。 通过转置这个矩阵得到最终旋转矩阵如下： 旋转矩阵*平移矩阵即得到最终的MV矩阵 Projection Tranform(投影变换)投影分为:正交投影(Orthographic Projection)，透视投影(Perspective Projection)。 正交投影计算过程最终目的：将可视范围移动到x:[-1,1],y:[-1,1],z:[-1,1]的原点Cube中 通过可视范围的中心点得到平移矩阵 由于正交投影：其可是范围为长方体，只需要通过缩放矩阵，将大小压缩到标准大小即可 透视投影计算过程由于透视投影的可视范围是一个锥形，为了计算压缩成长方体，再进行正交投影，原理如下图所示，将Frustum压缩成Cuboid虽然只是压缩，但其中的计算过程比前面的都要复杂很多。 拆分其变换过程，如下，近平面于原平面形成一个相似三角形得到变换后的x轴以及y轴值：y’ = y * n/z; x’ = x * n/z; 而z轴暂时还不知道,得到如下变换后的坐标 由第1部分求得坐标可以推算出变换矩阵的部分值：M * (x,y,z,1) = (nx,ny,unknown,z), M如下： 已知条件：(1)所有近平面的点压缩后都保持不变(2)远平面的点压缩z值不变分别将其中的坐标带入矩阵计算：(1) 近平面点带入： M * (x,y,n,1) = (nx,ny,n * n,n)，注释：变换后的z = n * n 于x,y不存在任何关系，因此可以得到(0,0,A,B)(2) 远平面点带入： M * (x,y,f,1) = (unknown,unknown,f*f,f)最终得到两条方程式：(1)An + B = n * n(2)Af + B = f * f求解得：A = n + f； B = -n * f 最终其压缩矩阵如下图： Viewport Tranform(视口变换)原理：先定义好平面的height和width，即平面的像素比，屏幕坐标空间中左下角为(0,0)，再经过MVP变换后，当前图片所在空间为[x:[-1,1],y:[-1,1]]，需要将其大小变大，再平移至左下角到(0,0)点 光栅化阶段经过视口变换后，所有图形信息都存在屏幕空间，这时需要考虑怎么将其显示出来，这个显示的过程就是光栅化。 三角形遍历为什么使用的是三角形？ 三角形是最基本的图形， 一个三角形一定在一个平面上 可以很方便计算一个点在三角形的内外，使用叉乘 三角形遍历原理：遍历每个可能的像素的中心点是否在三角形内部但是通过这种方式遍历后，就会出现一个问题：走样(Aliasing)，或称为锯齿 反走样(抗锯齿) (Anti-aliasing)走样是怎么形成的？根本原因是采样的频率跟不上变化的频率 频域(Frequency Domain) 正弦/余弦频谱 傅里叶变换(Fourier Transform)将非常多按照公式计算的频谱相加最终会越来越趋向于方形的频谱(1) 通过傅里叶变换可以将图片从 空间域转换到频域(2) 通过逆傅里叶变换可以将图片从 频域转换到空间域 频谱采样的一种特殊情况，如下图：对于两个不同频谱采样结果相同造成了走样 滤波器(Filter)滤波器是针对空间域(Spatial Domain)中的图片进行卷积计算，但滤波器实际可以表示为对频域的操作。如下图傅里叶变换结果：低频越趋向于白色，高频趋向于黑色，低频普遍存在于图片中心部分。 低通滤波器：低频通过，实际对频域进行低通滤波，可以达到模糊图片的效果实际原理就是将频域图片的高频部分全部过滤，只有低频通过。 高通滤波器：高频通过，可以达到描边的效果（高频表示图片中变化差异很大的部分,相当于是描边） 卷积如以3x3的box对图片进行卷积，每个像素的颜色至就相当于当前像素为中心周围9个像素点按照卷积核的比例相加。在空间域对图片进行卷积，相当于在频域中的两个图片的乘积，如下图验证了这一点： 实现反走样：在三角形遍历之前先进行模糊操作，再进行三角形遍历，每个像素保持模糊后的颜色值，模糊就是使用低通滤波对像素进行卷积操作 深度缓存(Z/Depth Buffer)在三角形遍历后，我们知道了所有需要渲染的三角形，现在需要考虑将它们画出来，这时需要考虑绘制三角形的先后顺序，正确的先后顺序以保证最终显示的图形是我们想要的图形，最初有一种算法油画家算法，从远到近依次绘制所有三角形，但是对于多个三角形互相穿插的问题无法得到解决，ZBuffer可以很好的规避渲染顺序问题，通过对每一个像素维护一个深度值，绘制三角形不需要考虑顺序，每次绘制时只考虑深度值是否小于缓存值，小于则绘制，大于则剔除，绘制时间复杂度只有O(N)。 着色(Shading)渲染管线(Rendering pipeline)实时渲染管线的整体顺序：应用阶段-&gt;几何阶段-&gt;光栅化阶段 应用阶段： 几何阶段： 光栅化阶段： 标准着色(Lambert + Ambient + Specular) 漫反射(Lambert) 高光反射(Specular)Phone和Blinn-Phone 环境光(Ambient) 重心坐标(Barycentric Coordinates)通过三角形的重心坐标可以做到由三角形的三个顶点插值到重心坐标处的值，这个值包括可以包括任何信息(法线，颜色等)同时可以扩展：三角形内的顶点 Q = aP1 + bP2 + c*P3， 且 a+b+c = 1 &amp;&amp; a&gt;0 &amp;&amp; b&gt;0 &amp;&amp; c&gt;0 纹理映射(Texture Mapping)通过使用一张纹理图片定义不同像素处的不同值。这些值可以用来做：颜色，高度图，噪声图等等。将纹理贴图的长宽定义成u,v，范围[0,1]区间方便计算。 纹理贴图首先定义：一个像素在纹理中的名字叫做纹素(texel)，且一个像素内只存在同样的颜色信息下面介绍纹理贴图在使用过程中遇到的问题以及如何优化 当纹理图片太小 问题描述：如果需要渲染一个在屏幕上为200x200像素的网格而纹理只有100x100像素大小，这时为了达到完整的渲染会将纹理图片拉伸至200x200像素大小，拉伸后一个纹素相当于原来的4倍，然后网格通过uv读取，可以发现网格中的采样4个像素才相当于原先纹理的1个像素，这导致这些像素使用了相同的颜色信息，因此会出现模糊。 解决方法：双线性插值(Bilinear Interpolation)，双立方插值(Bicubic Interpolation) 双线性插值(Bilinear Interpolation)核心思路：当采样一个点时，拿到其周围4个最近的采样坐标，拿到这4个采样像素的值，插值出当前采样点的颜色信息。 双立方插值(Bicubic Interpolation)思路于双线性插值一样，只是采样点从4个增加到16个 当纹理图片太大 问题描述：如果需要渲染一个三角形实际可能很大，但其在屏幕上占据像素为1x1px,而其纹理图片大小100x100px，进行普通采样只会获得其采样点对于的颜色，并不是我们想要的颜色，如下图可以看出摩尔纹以及锯齿(走样)问题。 在之前学习过走样形成的根本原因：采样频率低于变化频率，遇到这个问题当然可以通过超采样来避免，将1像素进行512个采样点采样，确实可以避免走样问题，采样结果如下，但是其消耗太大了： 为什么普通点采样会出现上面的走样问题：越远的三角面在屏幕中占据的像素越少，而对于一个像素在纹理中占的范围就越大这时通过点采样出来的信息一定是不满足的，采样范围的平均值反而更适合，那么怎么快速采样范围的平均值，一个新的概念使用MipMap。 MipMap MipMap允许做快速，近似的正方形的范围查询。 MipMap是预先生成的，从原图比例开始，每次长宽变小为原图的一半，直到像素为1x1px。 MipMap只多使用了原图的1/3的内存空间。 计算当前在MipMap中采样第几层的纹理数据 三线性插值(Trilinear Interpolation)在MipMap中如果得到层级在2.5层怎么正确获取颜色值？同时拿到第2，3层，分别进行双线性插值，将其结果再进行一次插值。 MipMap处理后的效果图，出现了一个新的问题，远处过度模糊(OverBlur) 各向异性过滤(Anisotropic Filtering)使用更多的内存保存更多分辨率的图片，MipMap只保存正方形大小，而各项异性过滤需要额外保存长方形的图片。效果图： 环境贴图(Environment Map)/立方体贴图(Cube Map) 环境贴图：将环境反射的颜色信息存储在一个球上 立方体贴图：将环境反射信息存储在立方体上 法线贴图/凹凸贴图(Bump Mapping) 作用于顶点法线上，使得表面看起来有一定凹凸感 作用原理：相当于将法线贴图的信息当作顶点的偏移值，就会造成一些顶点凹，一些凸，但是并不实际作用于顶点，只是用偏移后的顶点坐标再进行法线计算，就可以得到新的法线，将这个法线用于光照即得到新的视觉效果。 二维法线计算过程：如计算n，取贴图当前坐标值以及偏移1的值的差求出dp = c * [h(p+1) - h(p)],(注：h(p)，凹凸贴图定义的是切线，通过贴图拿到值)，逆时针旋转90度求得n，如图 三维法线计算过程： 注：其h(u)，也是通过贴图直接拿到值，h:纹理高度，w:纹理宽度(1) dp/du = c1 * [h(u+1/w,v) - h(u,v)](2) dp/dv = c2 * [h(u,v+1/h) - h(u,v)](3) 最终：n = (-dp/du, -dp/dv, 1) 位移法线：将贴图影响的偏移应用到顶点上，其效果更好 阴影 (Shadow) 相机可以看到，而光线看不到即有阴影，如下图：相机看到的深度与光线位置看到的深度不同则说明光线被阻挡，即该点产生阴影。 阴影又分为硬阴影，软阴影，硬阴影是由于将光线源当成点光源处理，而软阴影是将光源当成范围光处理。 几何(Geometry)什么是几何？几何就是拥有某种空间结构的形状。 几何模型 几何模型的隐式表达式，通过函数来表示一个几何模型。 通过函数可以表达一些基本的几何模型如立方体，球，圆环，圆等规则的模型，但对于非常复杂的模型，使用隐式表达式几乎不现实，且不直观，因此需要显示表达来表示各种复杂模型：(三角面模型)Triangle Mesh,(贝塞尔曲面)Bezier surfaces,(点云)point clouds,(曲面细分)subdivision surfaces等等方式来表示复杂模型。 贝塞尔曲线 (Bézier Curves) 由多个点共同决定的曲线，关于贝塞尔曲线的计算，如下图黑点左到右a,b,c,d，计算过程。 由于通过超多个点决定贝塞尔曲线，会由于点越来越多，越难控制，因此在实际使用时，通常使用分段式的贝塞尔曲线，将一条分成多条，方便控制。 贝塞尔曲面 (Bézier Surfaces) 由多个点共同决定的曲面，计算过程描述，如图4x4的曲面，对4条边做贝塞尔曲线，取4条边的值再做一次贝塞尔曲线，对所有uv做同样操作就形成了贝塞尔曲面。 模型 (Mesh) 一个Mesh由很多面组成 一个模型文件.obj中存储的数据内容包括：顶点，顶点切线，顶点法线，三角面(一组顶点链接的顺序并组成面) 模型优化方法模型细分(Mesh subdivision)目的：达到更精细的显示效果，细分后模型面会增多，顶点数量也会增多 Loop Subdivision (只适用于三角面细分)思路：将1个三角形等分成4个三角形 Catmull-Clark Subdivision (通常模型的细分,将多边形统一细分成四边形)思路：将所有不是四边形的面都转换成四边形，再将1个四边形分成4个四边形 模型简化(Mesh simplification)目的：减少渲染计算压力，避免不必要的计算 模型规则化(Mesh regularization)目的：提高模型质量，将所有三角面都转成等边三角形 光线追踪(Ray Tracing)Whitted-Style Ray Tracing如何检测射线命中三角面加速射线检测如何进行射线检测如何进行场景分块Path Tracing材质(Materials and Appearances)动画(Animation)参考GAMES101-现代计算机图形学入门-闫令琪","categories":[{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/categories/Graphics/"}],"tags":[{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/tags/Graphics/"}]},{"title":"雾效学习","slug":"Graphics/雾效","date":"2021-03-31T06:30:01.000Z","updated":"2021-11-24T08:59:46.940Z","comments":true,"path":"2021/03/31/Graphics/雾效/","link":"","permalink":"https://skierhou.github.io/2021/03/31/Graphics/%E9%9B%BE%E6%95%88/","excerpt":"","text":"目标了解如下效果原理，并实现以及运用 深度雾 高度雾 体积雾 高度雾深度雾体积雾","categories":[{"name":"Fog","slug":"Fog","permalink":"https://skierhou.github.io/categories/Fog/"}],"tags":[{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/tags/Graphics/"},{"name":"Fog","slug":"Fog","permalink":"https://skierhou.github.io/tags/Fog/"}]},{"title":"3D数学基础：图形与游戏开发","slug":"Graphics/3D Math Primer for Graphics and Game 2nd","date":"2021-03-12T06:30:01.000Z","updated":"2021-12-21T12:18:14.504Z","comments":true,"path":"2021/03/12/Graphics/3D Math Primer for Graphics and Game 2nd/","link":"","permalink":"https://skierhou.github.io/2021/03/12/Graphics/3D%20Math%20Primer%20for%20Graphics%20and%20Game%202nd/","excerpt":"","text":"向量向量点乘公式：a*b = |a||b|cosθ几何意义：(1) 判断前后(2) 投影用矩阵表示： 向量叉乘公式：|a×b| = |a||b|sinθ几何意义：(1) 判断左右(2) 计算垂直a,b所形成平面的向量，该向量的朝向由左手定则(左手坐标系)，右手定则(右手坐标系)决定用矩阵表示： 矩阵 矩阵转置(M(T))：通俗解释,行变列，列变行 矩阵乘法 矩阵变换过程(1)v=(x,y,z) 拆解成v=xp+yq+zr，p,q,r为一个坐标系的+x轴，+y轴，+z轴的单位向量(2)其(p,q,r)可以拆分为一个33矩阵即(3)矩阵变换相当于 变换矩阵列向量=新的向量 旋转矩阵(1) 2D旋转矩阵 (2) 3D绕正坐标轴旋转与2D同样(3) 3D绕任意轴旋转 缩放矩阵(1) 三轴的缩放因子kx,ky,kz 乘对应的p，q，r即是缩放矩阵 (2) 沿任意轴缩放矩阵 (3) 关于沿任意轴缩放矩阵因子k的特殊解释： k=-1：镜像，n相当于平面法向量 k=0：投影，n相当于平面法向量 k&gt;0：普通缩放 切变 (扭曲变换)一个/多个轴的坐标被另外一个轴以及一个/多个系数影响，2D切变如：将y乘因子s再加到x轴上，x’ = x + y*s。可以解释为，切变y轴，因子s，x轴受y轴切变影响 行列式 (矩阵M的行列式表示为：|M|) 余子式 (M(ij)表示从M矩阵中去掉第 i 行以及第 j 列后剩余的矩阵) 代数余子式 行列式性质(1).|A*B|=|A||B|(2).|M(T)|=|M| 注：M(T)为M的转置(3).矩阵任意行或列都为零，则行列式为零(4).交换矩阵的任意两行或两列，行列式变负(5).任意行或列的非零积加到另一行或列上，行列式值不变(6).行列式的值=2D中的面积，3D中的体积 矩阵的逆 M(-1)矩阵的逆 公式： “标准伴随矩阵” / 行列式 = 矩阵的逆 正交矩阵 (通常表示为Q)M * M(T) = I，M * M(-1) = I，M(T) = M(-1)(1)M(T)，M(-1)也为正交矩阵(2)|M| = +1或-1(3)M(T)各行为单位向量且两两相交几何意义：在已知该矩阵为正交矩阵的前提下，求矩阵的逆只需要求矩阵的转置而不用复杂计算。在坐标转换中旋转矩阵都是正交矩阵 4X4齐次矩阵平移是一个特殊的变换矩阵，在3X3矩阵中无法表示，因此添加了一个唯独存放平移信息，其中W分量为1表示向量，而W分量为0表示点 欧拉角 比较常见的表达旋转的方式，用三个旋转角度表示当前的旋转值，分别对应：绕x，y，z轴旋转度数。 优点：表达简单易懂，任意3个数表示欧拉角都是有效的 缺点：插值困难，如+190°与-170°实际表现是一样的但是普通插值会造成360°以上的旋转，旋转中某种特殊情况会出现万向锁问题 四元数 Q = [w v] = [w x y z] 单位四元数：Q = [1 0] 带入角度以及旋转轴： 四元数的模 四元数的共轭：q(*) ，向量变负 四元数的逆：q(-1) * q = [1 0] （单位四元数），由共轭除以模获得 四元数的乘法（叉乘）：（满足乘法结合律，不满足交换律） 使用四元数旋转标准3D坐标（x,y,z）转成p=[0 (x,y,z)]，q为旋转矩阵：[cos(θ/2) n*sin(θ/2)]再通过以下公式由右向左旋转： 由左向右旋转： 四元数的差：计算四元数’a’旋转到’b’的角位移，用’d’表示 a*d = b ，同时左乘一个a的逆（四元数不支持除法） 四元数点乘 几何意义：a·b的绝对值越大，说明a与b角位移越相似 四元数求幂：（比较常用）一个四元数q(1/3) 表示1/3的q的角位移; q(2)：两倍q的角位移 几何图元 自由度概念：自由度是决定一个图元可用的最少参数。 如：球：半径，矩形：长，宽，高 边界球检测相交 AABB包围盒检测相交：矩形的边于世界坐标系平行，满足相交条件Xmin &lt;= X &lt;= Xmax , Ymin &lt;= Y &lt;= Ymax , Zmin &lt;= Z &lt;= Zmax关于AABB包围盒的变换，当物体变换时，并不能直接设置AABB盒子(旋转等，盒子大小会变化)，而需要重新计算 点到平面的距离计算：取平面任意一点，得向量a以及于平面的夹角θ，sinθ*|a|即最短距离 三角形面积计算：1.bh/2 ，2.海伦公式(在不知道高的情况下)： 三角形重心，内心，外心计算， 重心：三角形平衡点，内心：到三条边距离相等，外心：到三个顶点距离相等 证明点在三角形内部，只需要用三角形的三个点于点P的向量分别于其三条边的向量做叉乘，求得点P在边的左侧或右侧，但三条边都在内部则点P在三角形内部 几何检测 (重点 重复查看)三角网格 (没看懂)图形数学可见性检测","categories":[{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/categories/Graphics/"}],"tags":[{"name":"Math","slug":"Math","permalink":"https://skierhou.github.io/tags/Math/"},{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/tags/Graphics/"}]},{"title":"Addressable 深度理解与使用","slug":"Unity/Resource/Addressable","date":"2021-03-05T06:30:01.000Z","updated":"2021-03-10T04:48:10.425Z","comments":true,"path":"2021/03/05/Unity/Resource/Addressable/","link":"","permalink":"https://skierhou.github.io/2021/03/05/Unity/Resource/Addressable/","excerpt":"","text":"Addressable是什么是Unity官方出的资源管理器，Addressable即可寻址的资源系统Addressable的优点： 通过一个key，可以直接获取资源，不需要在意资源的实际位置 有完整的可视化界面，不需要写大量资源管理代码即可管理资源 方便自定义打包，自带增量更新等 Addressable的使用心得 操作界面入口 初次打开需要创建Setting之后会看到Assets目录下的文件结构，先做简单介绍后面在工具使用时会依次讲到所有资源文件使用方式 路径 注释 AddressableAssetsData 根目录，AddressableAssetSettings是整个Addressable设置 AddressableAssetsData/AssetGroups 资源管理组，管理多个Schema处理该组内资源的读取/加载/保存等逻辑 AddressableAssetsData/AssetGroups/Schemas 处理模式，处理数据的实际逻辑类，继承自AddressableAssetGroupSchema，默认提供了三个Schema，分别对应两个AssetGroups：Built In Data以及Default Local Group AddressableAssetsData/AssetGroupTemplates 这个路径下只是一个模板，在创建Group时会复制一份这个模板 AddressableAssetsData/DataBuilders 在不同构建模式下，在游戏运行中的数据提供者，可选择项有InstanceProvider以及SceneProvider AddressableAssetsData/Windows 这个路径是打包才会自动生成的本地对应文件，记录上一次打包信息，可以用于增量更新，通过保存的文件判断哪些文件需要更新 Groups界面，管理所有Groups，即资源组，默认资源组存在两个:Build In Data，Default Local Group。 Group 注释 Build In Data 点击Build In Data，对应Assets/AddressableAssetsData/AssetGroups/Build In Data.asset，只有两个设置：包含Resources路径下资源，BuildSetting设置的场景，即这部分资源会打进游戏包中，不进行资源加载，这个资源组官方已经设置好了，不需要做任何其他设置。 Build In Data.asset目前没有方式主动创建，不要误删即可（不然只能重新创建数据了）。 Default Local Group 对应Assets/AddressableAssetsData/AssetGroups/Default Local Group.asset，其中包含两个Schema：BundledAssetGroupSchema,ContentUpdateGroupSchema。 ContentUpdateSchema：只有一个设置，设置为全量更新或者增量更新，全量：更新即替换，增量：不替换原资源情况下多打一个资源包，BundledAssetGroupSchema：设置资源打包/加载路径，以及Bundle模式：crc缓存，bundle名，以什么方式分组等，通常使用默认即可 Groups界面操作资源可以通过拖拽文件夹，拖拽单个文件，或再Inspector面板直接勾选Addressable 按钮 注释 Profile 路径配置，远程/本地的加载/构建路径，不管构建再哪个路径底下，加载Key都保持不变，这也是Addressable基本思想所在 Tools 工具，可以快捷打开所有界面，关于’Check For Content Update’按钮是用于增量更新的，当group设置为增量模式，且相比较上一次存在变换，点击这个按钮增量打包，会产生一个新的资源组管理增量资源，增量打包后原资源不会删除，但对应key下的hash指向的资源会变成新包资源。 Play Mode Script 游戏中使用的资源加载模式：1.fastest：AssetsDataset加载，2.advanced：模拟ab包加载，3.requires built groups：实际ab包加载。选择每种模式后对应AddressableAssetsData/DataBuilders的构建设置也会修改，对应1.BuildScriptFastMode,2.BuildScriptPackedPlayMode,3.BuildScriptVirtualMode，其中多的一个BuildScriptPackedMode为实现构建资源时的默认构建模式 Build New Build 下的按钮对应AddressableAssetsData/DataBuilders/BuildScriptPackedMode.asset，第二个按钮即增量更新按钮与Tools中的Content Update配合使用，Clean按钮即清除已构建的资源 Profile 界面：管理Profile，设置打包，加载等路径 AddressableAssetSettings设置：通常使用默认即可，对应按钮名称标记很明显了，不进行详细介绍 EventViewer界面：查看运行时资源使用情况，启动时需设置AddressableAssetSettings中的Send Profiler Event Analyze界面：用于分析资源的依赖关系，Fixable Rule：可修复的规则，分析器自动修复，UnFixable Rule：不可修复的规则，会列出来需要手动修复 Hosting界面：创建远程或者本地的服务器，方便测试，默认使用HTTP Service，查看HttpHostingService.cs代码可自定义服务器模式 Addressable的使用说明加载资源Addressable中加载任何资源都需要异步加载，不过可以使用Task多线程方式加载，使用非常方便。 1234567891011121314151617181920212223242526272829303132333435public class Test : MonoBehaviour&#123; [SerializeField] private string _entryName &#x3D; &quot;Assets&#x2F;Prefabs&#x2F;Cube.prefab&quot;; public AssetReference ar; private void Start() &#123; &#x2F;&#x2F; 使用Task异步加载 StartAsync(); &#x2F;&#x2F; 使用AssetReference引用直接加载 ar.LoadAssetAsync&lt;GameObject&gt;().Completed +&#x3D; LoadFinish; ar.InstantiateAsync(Vector3.one, Quaternion.identity); &#125; private void LoadFinish(AsyncOperationHandle&lt;GameObject&gt; loadHandle) &#123; if (loadHandle.IsDone &amp;&amp; loadHandle.Status &#x3D;&#x3D; AsyncOperationStatus.Succeeded) &#123; &#x2F;&#x2F;这里Result是预制体 Debug.Log(loadHandle.Result); Addressables.Release(loadHandle); &#125; &#125; private async Task StartAsync() &#123; var instance &#x3D; await Addressables.InstantiateAsync(_entryName).Task; Addressables.ReleaseInstance(instance); instance &#x3D; await Addressables.InstantiateAsync(_entryName).Task; Addressables.ReleaseInstance(instance); &#125;&#125; 关于更新使用Addressables提供的接口即可完成更新检查，以及下载，详细请阅读代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344private async void UpdateAndDownLoad()&#123; &#x2F;&#x2F; 1. 检查更新 AsyncOperationHandle&lt;List&lt;string&gt;&gt; updateHandle &#x3D; Addressables.CheckForCatalogUpdates(false); await updateHandle.Task; if (updateHandle.Status &#x3D;&#x3D; AsyncOperationStatus.Succeeded) &#123; updateList &#x3D; updateHandle.Result; &#125; &#x2F;&#x2F; 2.开始更新 AsyncOperationHandle&lt;List&lt;IResourceLocator&gt;&gt; updateHandler &#x3D; Addressables.UpdateCatalogs(updateList, false); await updateHandler.Task; &#x2F;&#x2F; 3.获取更新资源的key List&lt;string&gt; updateKeys &#x3D; new List&lt;string&gt;(); foreach (IResourceLocator locator in updateHandler.Result) &#123; if (locator is ResourceLocationMap map) &#123; foreach (var item in map.Locations) &#123; if (item.Value.Count &#x3D;&#x3D; 0) continue; string key &#x3D; item.Key.ToString(); if (int.TryParse(key, out int resKey)) continue; if (!updateKeys.Contains(key)) updateKeys.Add(key); &#125; &#125; &#125; &#x2F;&#x2F; 4.判断下载资源大小 AsyncOperationHandle&lt;long&gt; downLoadSize &#x3D; Addressables.GetDownloadSizeAsync(updateKeys); await downLoadSize.Task; &#x2F;&#x2F; 5.下载 AsyncOperationHandle downLoad &#x3D; Addressables.DownloadDependenciesAsync(updateKeys, MergeMode.None); await downLoad.Task; &#x2F;&#x2F; 6.清除 Addressables.Release(updateHandler); Addressables.Release(downLoad);&#125; Addressable的扩展自动化打包 在实际项目中资源打包通常不会人工手动设置，而是通过一些模式自动化打包，Addressable虽然提供了非常完善的功能界面，但是打包自动化还是需要用户自己扩展。以下是我个人理解的打包策略，与上篇AssetBundle文章的一样的策略，一个文件夹下所有的资源都按当前文件夹名称设置AB包一个文件一个AB包，子文件递归设置。 Groups界面可以直接拖拽文件夹进去，但是打包设置中只有三个选项：1.一组打成一个包，2.文件夹打成一个包(一次拖进去的文件夹子目录也包括进去)，3.按标签打包。我这里使用的是按标签打包，相同标签一个包。 扩展代码请查看末尾的项目。 场景加载以及游戏物体实例化扩展 Addressable默认有提供InstanceProvider以及SceneProvider，但是InstanceProvider中并没有使用到对象池，且在使用Addressables.InstantiateAsync()多次后，同样的资源引用会存在多个，可以通过EventViewer中看到资源占用的堆内存空间，通过继承IInstanceProvider以及ISceneProvider自己实现加载完实际资源后的实例化对象即可。其实就是将对象池写入IInstanceProvider，查看末尾的项目代码其中有InstanceProviderHelper.cs实现。 项目路径 https://github.com/Skierhou/ResourceManager","categories":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/categories/Unity/"},{"name":"Resource","slug":"Unity/Resource","permalink":"https://skierhou.github.io/categories/Unity/Resource/"},{"name":"Addressable","slug":"Unity/Resource/Addressable","permalink":"https://skierhou.github.io/categories/Unity/Resource/Addressable/"}],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/tags/Unity/"},{"name":"Addressable","slug":"Addressable","permalink":"https://skierhou.github.io/tags/Addressable/"}]},{"title":"AssetBundle 注意事项以及使用","slug":"Unity/Resource/AssetBundle","date":"2021-03-05T06:30:01.000Z","updated":"2021-03-10T02:11:57.106Z","comments":true,"path":"2021/03/05/Unity/Resource/AssetBundle/","link":"","permalink":"https://skierhou.github.io/2021/03/05/Unity/Resource/AssetBundle/","excerpt":"","text":"AssetBundle是什么AssetBundle是Unity的资源管理包，用于资源加载卸载。AssetBundle分为数据头和数据段： 数据头：存储一些设置，如压缩类型，索引，manifest等 数据段：存储序列化后Asset数据 AssetBundle的优点： 自带压缩算法 方便管理，适合增量更新 可随意加载卸载Asset 内部包含Asset的引用关系，不需要怕引用丢失 AssetBundle的压缩压缩格式分为：LZ4，LZMA LZMA打包成字节流，包体会比LZ4小 LZMA打包运行时占用运行内存空间会比LZ4大很多,在使用是LZMA包在初始化时先解压再压缩成LZ4使用，个人理解实际情况：LZMA解压完的数据会先存在内存中，再压缩成LZ4，但是使用时又需要将LZ4解压，感觉上是极度没必要的。 通常情况下使用LZ4打包，不需要考虑太多内存空间的事，只是包体会稍微大一些 AssetBundle的读取有两种方式LoadFromMemory，LoadFromFile LoadFromMemory：需要反复读取byte数组，会有额外的内存消耗 LoadFromFile: 直接从硬盘文件中读取，注意：LoadFromFile在Editor模式下会直接读取整个AssetBundle，而运行时只会读取AssetBundle的头数据，在Editor下性能分析需要注意这一项 AssetBundle的卸载AssetBundle.UnLoad(bool unloadAllLoadedObject) 卸载时需要注意，当使用UnLoad(false)，且有实际使用资源时，该资源并不会卸载会缓存一份，再下一次加载出AssetBundle时，会复制另一份资源，导致同样的资源内存中存在两份。 卸载时使用UnLoad(true),会卸载所有加载资源，使用这类资源的将丢失，但是下一次加载出AssetBundle时，内存中只会有一份资源 AssetBundle的依赖关系编辑器下由AssetDatabase 和 AssetImporter管理，AssetDatabase管理依赖，AssetImporter为AssetBundle数据 通过AssetDatabase.GetDependencies(path) 来获取该Asset的依赖文件 通过AssetImporter可以修改Asset的AssetBundle设置 实际打包时，会将Asset的依赖关系打进manifest文件，但是加载一个AssetBundle时Unity并不会将其依赖AssetBundle一同加载出来，需要自己主动进行管理 AssetBundle在项目中使用通常在实际项目中使用并不会去手动一一设置AssetBundle名称再进行打包，而会根据项目需求自定义打包模式，下面由我介绍一下个人感觉非常实用的打包策略。 将一个文件夹路径下所有的文件统一自动打成AssetBundle包，所有Asset按文件夹名称设置ABName并递归所有子文件夹，使用这种做法只需要管理好项目资源的目录结构就可以很好管理AssetBundle了 在打包的同时将保存所有Asset的数据：crc, path, assetName, assetBundleName, dependceAssetBundles。保存成二进制一同打进config包中,游戏启动先加载config，在加载一个资源时再加载对应包以及依赖包即可12345678910111213141516171819[System.Serializable]public class AssetBundleConfig&#123; &#x2F;&#x2F; 资源路径转crc public uint crc; &#x2F;&#x2F; 资源路径 public string path; &#x2F;&#x2F; 资源包名 public string assetBundleName; &#x2F;&#x2F; 资源名：从资源包中加载的名称 public string assetName; &#x2F;&#x2F; 依赖包 public List&lt;string&gt; dependceAssetBundles;&#125;[System.Serializable]public class AssetBundleContainer&#123; public List&lt;AssetBundleConfig&gt; configList;&#125; 实现两个管理器AssetBundleManager，以及ResourceManager，使用时ResourceManager按路径加载资源，ResourceManager从AssetBundleManager拿到AssetBundle包12345678910111213141516171819202122232425262728293031public interface IAssetBundleManager&#123; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 同步加载AB包 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; AssetBundle LoadAssetBundle(string assetBundleName); &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 异步加载AB包 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; void LoadAssetBundleAsync(string assetBundleName, Action&lt;AssetBundle&gt; callback); &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 卸载AB包 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; void UnLoadAssetBundle(string assetBundleName);&#125;public interface IResourceManager&#123; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 同步加载资源 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; T LoadAsset&lt;T&gt;(string path) where T : UnityEngine.Object; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 异步加载资源 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; void LoadAssetAsync(string path, Action&lt;UnityEngine.Object, object&gt; onLoaded, int priority &#x3D; 0, object userData &#x3D; null); &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 卸载资源 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; void UnLoadAsset(string path, bool isDestroy &#x3D; false);&#125; 项目路径 https://github.com/Skierhou/ResourceManager","categories":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/categories/Unity/"},{"name":"Resource","slug":"Unity/Resource","permalink":"https://skierhou.github.io/categories/Unity/Resource/"},{"name":"AssetBundle","slug":"Unity/Resource/AssetBundle","permalink":"https://skierhou.github.io/categories/Unity/Resource/AssetBundle/"}],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/tags/Unity/"},{"name":"AssetBundle","slug":"AssetBundle","permalink":"https://skierhou.github.io/tags/AssetBundle/"}]},{"title":"Markdown基础语法","slug":"Base/markdown","date":"2021-03-02T06:30:01.000Z","updated":"2021-03-10T04:40:45.030Z","comments":true,"path":"2021/03/02/Base/markdown/","link":"","permalink":"https://skierhou.github.io/2021/03/02/Base/markdown/","excerpt":"","text":"初于方便写文章考虑，整理一下markdown语法规则 转载链接 标题123456# 这是一级标题## 这是二级标题### 这是三级标题#### 这是四级标题##### 这是五级标题###### 这是六级标题 这是一级标题这是二级标题这是三级标题这是四级标题这是五级标题这是六级标题字体1234**这是加粗的文字***这是倾斜的文字*&#96;***这是斜体加粗的文字***~~这是加删除线的文字~~ 这是加粗的文字这是倾斜的文字`这是斜体加粗的文字这是加删除线的文字 引用123&gt; 引用&gt;&gt; 引用&gt;&gt;&gt; 引用 引用 引用 引用 分割线1234-------******** 图片12格式：![图片alt](图片地址 &#39;&#39;图片title&#39;&#39;)参考：![default](https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;butterfly-extsrc@1&#x2F;img&#x2F;default.jpg &quot;标题&quot;) 超链接12格式：[超链接名](超链接地址 &quot;超链接title&quot;)参考：[简书](http:&#x2F;&#x2F;jianshu.com) 简书 列表12无序： * - +有序： 1. 2. 3. 无序 无序 无序 有序 有序 有序 表格1234567891011表头|表头|表头---|:--:|---:内容|内容|内容内容|内容|内容第二行分割表头和内容。- 有一个就行，为了对齐，多加了几个文字默认居左-两边加：表示文字居中-右边加：表示文字居右注：原生的语法两边都要用 | 包起来。此处省略 表头 表头 表头 内容 内容 内容 内容 内容 内容 代码块123(&#96;&#96;&#96;) 代码块...(&#96;&#96;&#96;) 流程图1234567891011&#96;&#96;&#96;sequenceTitle:时序图示例客户端-&gt;服务端: 我想找你拿下数据 SYN服务端--&gt;客户端: 我收到你的请求啦 ACK+SYN客户端-&gt;&gt;服务端: 我收到你的确认啦，我们开始通信吧 ACKNote right of 服务端: 我是一个服务端Note left of 客户端: 我是一个客户端Note over 服务端,客户端: TCP 三次握手participant 观察者这里也不支持流程图","categories":[{"name":"通用","slug":"通用","permalink":"https://skierhou.github.io/categories/%E9%80%9A%E7%94%A8/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://skierhou.github.io/tags/Markdown/"}]},{"title":"2021年规划","slug":"Plan/plan2021","date":"2021-03-01T06:30:01.000Z","updated":"2021-10-28T03:02:50.484Z","comments":true,"path":"2021/03/01/Plan/plan2021/","link":"","permalink":"https://skierhou.github.io/2021/03/01/Plan/plan2021/","excerpt":"","text":"每年需持续整理个人任务，个人任务可以规划为年度任务，月任务，详细再到周任务记录个人任务完成情况，如未完成，需写下原因以检讨在工作空闲时间，假期，周末等时期完成的任务 年度任务规划 任务描述 完成情况(%) 注释 客户端方向 EGameTang框架深度学习，掌握EGameTang网络架构原理并制作联机RPGDemo|10%|目前已掌握基础使用GameFramework框架深度学习，学习其代码规范，底层原理，架构思想|50%|目前以运用于项目中Ability技能系统搭建完成，并完成多个模式的Demo|50%|技能系统已搭建，准备Demo即可AI行为系统的深度学习，主要参考UE4 AI系统|10%|掌握基本使用AssetBundle,Addressable的深度学习|80%|战斗系统||UE系统学习|| TA方向||Game101 计算机图形学入门|50%|看完教程后总结OpenGL，看完书籍红皮书，蓝皮书|10%|3D数学基础，总结提炼|50%|UnityShader，光照GI，渲染管线|20%|Unity实现天气系统，下雨打雷，下雪，风|0%|Unity草地|50%|ShaderGraph使用|0%|PS，基本使用|0%|3DMax，基本使用|0%|粒子特效制作|0%|Real-Time Rendering 3rd书籍详细学习|0%|在3D数学UnityShader编程OpenGL都完成后学习GPU Gems等系列书籍|0%|放到将TA基础都看完了之后进行学习 整体技术方向||完成一款游戏Demo,未来考虑长期制作并发布的Demo|0%| 月任务规划 时间(月) 任务描述 完成情况(%) 注释 1 无 无 3月启动 2 无 无 3月启动 3 1.GF框架深度学习，代码解剖；2.PS,3DMax,粒子特效制作；3.AssetBundle,Addressable的深度学习 80% 4 1.OpenGL红皮书，蓝皮书；2.EGameTang框架深度学习，代码解剖；3.整理个人项目结构，第一个项目单机可热更 4. Game101 计算机图形学入门 5.PS,3DMax,粒子特效制作 80% 无 5 无 无 无 6 无 无 无 7 无 无 无 8 无 无 无 9 无 无 无 10 无 无 无 11 无 无 无 12 无 无 无","categories":[{"name":"年度规划","slug":"年度规划","permalink":"https://skierhou.github.io/categories/%E5%B9%B4%E5%BA%A6%E8%A7%84%E5%88%92/"}],"tags":[{"name":"Plan","slug":"Plan","permalink":"https://skierhou.github.io/tags/Plan/"}]},{"title":"GameFramework 底层解析","slug":"Unity/GameFramework/GF1","date":"2021-03-01T06:30:01.000Z","updated":"2021-03-22T02:34:23.426Z","comments":true,"path":"2021/03/01/Unity/GameFramework/GF1/","link":"","permalink":"https://skierhou.github.io/2021/03/01/Unity/GameFramework/GF1/","excerpt":"","text":"对GF的源码解析，学习设计思路，学习代码规范 GF官网 GF-API看了GF的源码，感觉自己之前写的代码都是一堆垃圾!!!源码阅读建议：与StarForce项目一同阅读 Base层数据处理器，序列化工具，Log，事件池，引用池，任务代理池，其他扩展：Action，Func，变量封装(用于自定义数据结构)，自定义链表 DataProvider 数据处理器主要细节只需要看IDataProvider，IDataProviderHelper的实现上IDataProvider，IDataProviderHelper主要实现2个接口：ReadData，ParseData IDataProvider 从ResourceManager中读取资源，为数据提供者 IDataProviderHelper负责对具体数据的解析，为数据提供者帮助接口，用户使用上只需要实现帮助类即可对于IDataProviderHelper可能会引起误区，这里的ReadData是在IDataProvider读取资源成功时调用，这时已经拿到了需要的资源，可以直接使用或者再主动调用ParseData解析数据再使用。 执行顺序如：ConfigManager.ReadData()-&gt;IDataProvider.ReadData()-&gt;读取成功后-&gt;IDataProviderHelper.ReadData()，这时主动调用ConfigManager.ParseData()-&gt;IDataProvider.ParseData()-&gt;IDataProviderHelper.ParseData() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899IDataProvider&#x2F;&#x2F;&#x2F; &lt;summary&gt;&#x2F;&#x2F;&#x2F; 数据提供者接口。&#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt;&#x2F;&#x2F;&#x2F; &lt;typeparam name&#x3D;&quot;T&quot;&gt;数据提供者的持有者的类型。&lt;&#x2F;typeparam&gt;public interface IDataProvider&lt;T&gt;&#123; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 读取数据成功事件。 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; event EventHandler&lt;ReadDataSuccessEventArgs&gt; ReadDataSuccess; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 读取数据失败事件。 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; event EventHandler&lt;ReadDataFailureEventArgs&gt; ReadDataFailure; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 读取数据更新事件。 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; event EventHandler&lt;ReadDataUpdateEventArgs&gt; ReadDataUpdate; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 读取数据时加载依赖资源事件。 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; event EventHandler&lt;ReadDataDependencyAssetEventArgs&gt; ReadDataDependencyAsset; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 读取数据。 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;dataAssetName&quot;&gt;内容资源名称。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;priority&quot;&gt;加载数据资源的优先级。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;userData&quot;&gt;用户自定义数据。&lt;&#x2F;param&gt; void ReadData(string dataAssetName, int priority, object userData); &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 解析内容。 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;dataBytes&quot;&gt;要解析的内容二进制流。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;startIndex&quot;&gt;内容二进制流的起始位置。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;length&quot;&gt;内容二进制流的长度。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;userData&quot;&gt;用户自定义数据。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;returns&gt;是否解析内容成功。&lt;&#x2F;returns&gt; bool ParseData(byte[] dataBytes, int startIndex, int length, object userData);&#125;&#x2F;&#x2F;&#x2F; &lt;summary&gt;&#x2F;&#x2F;&#x2F; 数据提供者辅助器接口。&#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt;public interface IDataProviderHelper&lt;T&gt;&#123; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 读取数据。 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;dataProviderOwner&quot;&gt;数据提供者的持有者。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;dataAssetName&quot;&gt;内容资源名称。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;dataAsset&quot;&gt;内容资源。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;userData&quot;&gt;用户自定义数据。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;returns&gt;是否读取数据成功。&lt;&#x2F;returns&gt; bool ReadData(T dataProviderOwner, string dataAssetName, object dataAsset, object userData); &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 读取数据。 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;dataProviderOwner&quot;&gt;数据提供者的持有者。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;dataAssetName&quot;&gt;内容资源名称。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;dataBytes&quot;&gt;内容二进制流。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;startIndex&quot;&gt;内容二进制流的起始位置。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;length&quot;&gt;内容二进制流的长度。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;userData&quot;&gt;用户自定义数据。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;returns&gt;是否读取数据成功。&lt;&#x2F;returns&gt; bool ReadData(T dataProviderOwner, string dataAssetName, byte[] dataBytes, int startIndex, int length, object userData); &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 解析内容。 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;dataProviderOwner&quot;&gt;数据提供者的持有者。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;dataString&quot;&gt;要解析的内容字符串。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;userData&quot;&gt;用户自定义数据。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;returns&gt;是否解析内容成功。&lt;&#x2F;returns&gt; bool ParseData(T dataProviderOwner, string dataString, object userData); &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 解析内容。 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;dataProviderOwner&quot;&gt;数据提供者的持有者。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;dataBytes&quot;&gt;要解析的内容二进制流。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;startIndex&quot;&gt;内容二进制流的起始位置。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;length&quot;&gt;内容二进制流的长度。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;userData&quot;&gt;用户自定义数据。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;returns&gt;是否解析内容成功。&lt;&#x2F;returns&gt; bool ParseData(T dataProviderOwner, byte[] dataBytes, int startIndex, int length, object userData); &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 释放内容资源。 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;dataProviderOwner&quot;&gt;数据提供者的持有者。&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;dataAsset&quot;&gt;要释放的内容资源。&lt;&#x2F;param&gt; void ReleaseDataAsset(T dataProviderOwner, object dataAsset);&#125; EventPool 事件池实现事件接口：订阅，取消订阅，抛出事件，立即抛出事件 Fire 抛出事件：线程安全，将待执行事件放入队列，下一帧执行 FireNow 立即抛出事件：线程不安全 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&#x2F;&#x2F;&#x2F;&#x2F; 摘要:&#x2F;&#x2F; 事件管理器接口。public interface IEventManager&#123; &#x2F;&#x2F; &#x2F;&#x2F; 摘要: &#x2F;&#x2F; 抛出事件，这个操作是线程安全的，即使不在主线程中抛出，也可保证在主线程中回调事件处理函数，但事件会在抛出后的下一帧分发。 &#x2F;&#x2F; &#x2F;&#x2F; 参数: &#x2F;&#x2F; sender: &#x2F;&#x2F; 事件源。 &#x2F;&#x2F; &#x2F;&#x2F; e: &#x2F;&#x2F; 事件参数。 void Fire(object sender, GameEventArgs e); &#x2F;&#x2F; &#x2F;&#x2F; 摘要: &#x2F;&#x2F; 抛出事件立即模式，这个操作不是线程安全的，事件会立刻分发。 &#x2F;&#x2F; &#x2F;&#x2F; 参数: &#x2F;&#x2F; sender: &#x2F;&#x2F; 事件源。 &#x2F;&#x2F; &#x2F;&#x2F; e: &#x2F;&#x2F; 事件参数。 void FireNow(object sender, GameEventArgs e); &#x2F;&#x2F; &#x2F;&#x2F; 摘要: &#x2F;&#x2F; 设置默认事件处理函数。 &#x2F;&#x2F; &#x2F;&#x2F; 参数: &#x2F;&#x2F; handler: &#x2F;&#x2F; 要设置的默认事件处理函数。 void SetDefaultHandler(EventHandler&lt;GameEventArgs&gt; handler); &#x2F;&#x2F; &#x2F;&#x2F; 摘要: &#x2F;&#x2F; 订阅事件处理函数。 &#x2F;&#x2F; &#x2F;&#x2F; 参数: &#x2F;&#x2F; id: &#x2F;&#x2F; 事件类型编号。 &#x2F;&#x2F; &#x2F;&#x2F; handler: &#x2F;&#x2F; 要订阅的事件处理函数。 void Subscribe(int id, EventHandler&lt;GameEventArgs&gt; handler); &#x2F;&#x2F; &#x2F;&#x2F; 摘要: &#x2F;&#x2F; 取消订阅事件处理函数。 &#x2F;&#x2F; &#x2F;&#x2F; 参数: &#x2F;&#x2F; id: &#x2F;&#x2F; 事件类型编号。 &#x2F;&#x2F; &#x2F;&#x2F; handler: &#x2F;&#x2F; 要取消订阅的事件处理函数。 void Unsubscribe(int id, EventHandler&lt;GameEventArgs&gt; handler);&#125; Log对Log进行封装，ILogHelper对Log的具体实现 ReferencePool 引用池为了降低因大量产生类对象而导致的内存分配，设计了引用池的概念，来将用完的对象清理并缓存起来，供后续使用。实现IReference接口，通过ReferencePool.Acquire()获取 TaskPool 任务池这个任务池主要做资源异步加载，下载等异步操作的任务 TaskBase：只是任务数据 ITaskAgent：任务代理，处理任务的具体行为如DownloadAgent.cs处的使用，Agent只处理该Task中数据，并在执行中通知对应Helper执行具体下载逻辑 TaskInfo：用于Debug等展示的信息 TaskPool：任务池,管理ITaskAgent并执行 Variable 变量变量封装 Version 版本号方便版本号管理，版本号在资源更新时需要使用，判断旧资源与新资源的版本号。 封装的基础类型 类 注释 GaneFrameworkAction 封装多参数委托 GameFrameworkFunc 封装多参数委托 GameFrameworkEntry 游戏入口 GameFrameworkEventArgs 事件数据封装 GameFrameworkException 异常抛出封装 GameFrameworkLinkedList 带缓存的LinkedList（链表） GameFrameworkLinkedListRange 有范围的链表，即理解为LinkedList中的一小段 GameFrameworkModule 模块的封装基类，统一管理各类模块Manager GameFrameworkMultiDictionary 多值字典,Value为链表 GameFrameworkSerializer 序列化器, Config经过了对Base层的理解，Config层就很轻松弄明白了。主要封装了数据读取，解析，获取。执行顺序：ConfigManager.ReadData()-&gt;IDataProvider.ReadData()-&gt;读取成功后-&gt;IDataProviderHelper.ReadData()，ConfigManager.ParseData()-&gt;IDataProvider.ParseData()-&gt;IDataProviderHelper.ParseData()使用上只需要：修改对应Helper即可 DataNode树状数据节点，个人使用最多就是GetOrAddNode(string) DataTable 使用DataTable，扩展一下可以很方便与excel使用 实现Helper类解析Excel产生的bytes数据即可 接口 注释 IDataTable 表(数据容器,管理多条数据) IDataRow 数据项(一条数据) IDataHelper 数据解析帮助类 IDataTableManager 管理所有表 Debugger运行时的Debugger界面，使用上很方便，具体就是打印多种不同信息 Download下载任务都是异步操作，因此需要等待，这时Base层定义好的TaskPool就有了作用下载步骤： DownloadTask携带下载数据：下载路径，保存路径，下载状态，缓冲区大小等 DownloadAgent处理任务数据，监听下载状态变化：下载数据更新，下载长度更新，下载完成，下载失败 IDownloadAgentHelper实现实际下载逻辑，如UnityWebRequestDownloadAgentHelper为例,使用UnityWebRequest发送实际下载请求，DownloadHandler抛出下载数据更新事件 DownloadCounter计算下载速度 IDownloadManager即下载管理器，管理任务池以及开放对应下载接口 EntityEntity即实体EntityManager-&gt;EntityGroup-&gt;Entity每个Entity有独一无二的id，Manager通过字典存储，方便管理Entity每个EntityManager管理EntityGroup,EntityGroup只管理组内的Entity每个Entity实际生成时通过EntityGroup中的对象池子管理ShowEntity流程：ReourcesManager加载资源-&gt;IEntityHelper实例化-&gt;注册进EntityGroup的对象池中-&gt;调用Entity生命周期函数OnInit-&gt;OnShow Event对Base层的EventPool的一层封装 FileSystem FileSystem对应一个物理文件,其中保存多个文件数据,每个文件数据可理解为一个数据类型的二进制数据，加载时解析成对应类型的数据其中有一个概念数据块，即每一个文件数据都是一个数据块，但是当同名数据更新时，文件数据会更换一个空闲块进行存储。 IFileSystem fileSystem = fileSystemComponent.CreateFileSystem(fullPath, FileSystemAccess.ReadWrite, maxFileCount, maxBlockCount);创建文件系统时，输入的maxFileCount，以及maxBlockCount对应最大文件个数以及最大数据块个数，目前FileSystem还不支持文件系统自动扩容，需一开始设定好，且maxFileCount &lt;= maxBlockCount，在更新文件数据时会更换数据块，因此更新越频繁的数据maxBlockCount需要越大，以保证数据更新有足够的碎片空间进行修改。 FSM有限状态机 Localization本地化语言,实现上与Config类似，只是在不同Language下读取不同的文件下存储的keyValue Network 接口 注释 INetworkManager 管理NetworkChannel INetworkChannel 建立链接，处理消息接收发送 INetworkChannelHelper 消息序列化反序列化帮助类 IPacketHandler 处理协议，每个协议有其ID，通过ID区分 IPacketHeader 消息头部信息主要记录长度，可自行添加头部信息携带数据，实际消息存在长度，发包是存在数据的粘包以及分包，这时需要头部信息判断消息是否接收完毕 使用上，客户端需要链接几处服务器就创建几个INetworkChannel分别链接，发消息也是同样每个链接处理各自的消息如：实际服务器一般存在：Gate服务器，Game服务器，Chat服务器，Friend服务器等等，使用NetworkManager可以很方便管理这种分布式服务器的链接 使用网络通信的数据结构最好使用protobuf，是目前最适合用于网络通信的数据结构，可以参考StarForce中Network模块心跳包实现 发送以及接收消息都是异步的，且客户端收到消息在非主线程，需要事件系统通过线程安全方式抛出 ObjectPool对象池，其中有提供CreateSingleSpawnObjectPool，CreateMultiSpawnObjectPool理解为：池子里的资源能够同时被使用一次或使用多次，缓存资源在Spawn后以及Release前都算是在使用下，MultiSpawnObjectPool能多次Spawn同一资源(目前还没使用过，感觉没什么作用，我目前理解为这个池子只管理了一个缓存资源，在任何情况下都能Spawn出来使用)，SingleSpawnObjectPool是我们通常情况下的对象池。 Procedure游戏进程管理，是FSM的实现，可以参考StarForce的游戏启动流程 Resource 资源管理模块设计整个框架，几乎每个模块都使用到资源管理器，普通的资源管理只是提供资源打包，加载，卸载等操作，这个强大的资源管理器还提供了可视化操作界面，资源使用分析，以及资源更新处理。 资源模式一共有三种：单机模式，预下载的可更新模式，使用时下载的可更新模式。 关于三种模式的使用方法参考StarForce的启动流程，非常详细。 关于资源组的思想，资源组类似于Unity中的AssetBundle包即压缩包，一个包里包含多个资源文件，方便管理，资源还可以设置文件系统，多个资源组放进一个文件中。 编辑器中的使用方式 使用前需要先设置ResourceEditor.xml文件配置，是ResourceEditor的过滤配置，再导入GF框架后可以直接复制StarForce中的配置 关于ResourceEditor有些无法过滤的文件：如bytes文件，atlas文件(将图片打成一个包并不会自动生成图集，Load出来还是Texture2D格式)等，可以手动扩展ResourceEditor的过滤配置修改脚本ResourceEditorController.cs过滤文件设置 进行第一步后就可看到设置路径下的所有合法资源文件了 Resource Builder：选择打包平台，以及路径，还可以选择打包事件处理器，如StarForce将打完的包复制了一份到StreamingAssets路径下，具体查看接口IBuildEventHandler.cs 实际运行中检查并更新资源流程12345678910111213141516171819202122&#x2F;&#x2F; 根据StarForce启动流程&#x2F;&#x2F; ---单机模式&#x2F;&#x2F; 注意：使用单机模式并初始化资源前，需要先构建 AssetBundle 并复制到 StreamingAssets 中，否则会产生 HTTP 404 错误GameEntry.Resource.InitResources(OnInitResourcesComplete);&#x2F;&#x2F; ---更新模式&#x2F;&#x2F; 1.向服务器请求版本信息GameEntry.WebRequest.AddWebRequest(Utility.Text.Format(GameEntry.BuiltinData.BuildInfo.CheckVersionUrl, GetPlatformPath()), this);&#x2F;&#x2F; 2.拿到服务器的VersionInfo，包含：最新版本信息，下载地址等等信息，设置资源更新下载地址并检查是否有更新GameEntry.Resource.UpdatePrefixUri &#x3D; Utility.Path.GetRegularPath(m_VersionInfo.UpdatePrefixUri);GameEntry.Resource.CheckVersionList(m_VersionInfo.InternalResourceVersion); &#x2F;&#x2F; 3.进行版本更新GameEntry.Resource.UpdateVersionList(m_VersionInfo.VersionListLength,m_VersionInfo.VersionListHashCode,m_VersionInfo.VersionListZipLength,m_VersionInfo.VersionListZipHashCode);&#x2F;&#x2F; 4.检查资源是否需要更新GameEntry.Resource.CheckResources(OnCheckResourcesComplete);&#x2F;&#x2F; 5.更新资源GameEntry.Resource.UpdateResources(OnUpdateResourcesComplete); dll源码解析Scene场景加载，卸载管理，对ResourceManager的LoadScene，UnLoadScene封装了一层 Setting游戏设置，与Config实现类似 Sound非常好用的音效管理器，高效，简洁，功能强大 接口 注释 ISoundAgent 一个音效有一个代理，内部逻辑代理接口，主要负责处理声音开启暂停等 ISoundAgentHelper 声音播放实际逻辑 ISoundGroup 声音组 ISoundGroupHelper 声音组帮助器，StarForce提供默认用于处理混音的组 ISoundHelper 释放资源 ISoundManager 管理音效播放，暂停，恢复以及音效组 UI设计思路与Sound以及Entity类似，UIGroup组管理UIForm，UIManager一起管理，需要注意的是同类型UIForm可以开启多个，只单个存在的界面需要自己判断是否再次开启，可以参考Demo中的写法 Utility提供了各种通用函数，方便使用 WebRequestWeb请求是异步的，通过TaskPool来代理Web请求，使用上带来的好处是可以不需要使用协程，监听成功失败事件即可。","categories":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/categories/Unity/"},{"name":"GameFramework","slug":"Unity/GameFramework","permalink":"https://skierhou.github.io/categories/Unity/GameFramework/"}],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/tags/Unity/"},{"name":"GameFramework","slug":"GameFramework","permalink":"https://skierhou.github.io/tags/GameFramework/"}]},{"title":"DOTS 详细介绍","slug":"Unity/DOTS","date":"2021-03-01T06:30:01.000Z","updated":"2021-04-12T09:53:27.568Z","comments":true,"path":"2021/03/01/Unity/DOTS/","link":"","permalink":"https://skierhou.github.io/2021/03/01/Unity/DOTS/","excerpt":"","text":"DOTS概述DATA-ORIENTED TECH STACK(多线程数据导向型技术堆栈)，是由ECS+JobSystem+Burst组成。 ECS (Entity Component System)JobSystemBurst (编译) 同时使用Unity.Mathematics以及JobSystem后使用[BurstCompile]标记，可使性能提升100倍以上。 项目中使用参考AngryBots_ECS项目Dots一些群体行为模板(鱼群等)一些文章","categories":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/categories/Unity/"},{"name":"DOTS","slug":"Unity/DOTS","permalink":"https://skierhou.github.io/categories/Unity/DOTS/"}],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/tags/Unity/"},{"name":"DOTS","slug":"DOTS","permalink":"https://skierhou.github.io/tags/DOTS/"}]},{"title":"战斗系统","slug":"Unity/战斗系统","date":"2021-03-01T06:30:01.000Z","updated":"2021-10-29T10:56:43.709Z","comments":true,"path":"2021/03/01/Unity/战斗系统/","link":"","permalink":"https://skierhou.github.io/2021/03/01/Unity/%E6%88%98%E6%96%97%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"战斗系统概述 能力系统(Ability) 3C(camera，control，character) AI系统 地图系统 能力系统(Ability)3C(camera，control，character)Camera相机 cinemachine ControlCharacterAI系统 行为树 状态机 Goap行为树 状态机Goap地图系统 大地图 地形编辑器 天气系统 大地图地形编辑器天气系统参考自制独立游戏《石头》38分钟实机演示角色动作系统概述：战斗、3C相关弹刀等问题","categories":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/categories/Unity/"},{"name":"战斗系统","slug":"Unity/战斗系统","permalink":"https://skierhou.github.io/categories/Unity/%E6%88%98%E6%96%97%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/tags/Unity/"},{"name":"战斗系统","slug":"战斗系统","permalink":"https://skierhou.github.io/tags/%E6%88%98%E6%96%97%E7%B3%BB%E7%BB%9F/"}]}],"categories":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/categories/Unity/"},{"name":"Task","slug":"Task","permalink":"https://skierhou.github.io/categories/Task/"},{"name":"Thread","slug":"Thread","permalink":"https://skierhou.github.io/categories/Thread/"},{"name":"URP","slug":"Unity/URP","permalink":"https://skierhou.github.io/categories/Unity/URP/"},{"name":"Shader","slug":"Unity/Shader","permalink":"https://skierhou.github.io/categories/Unity/Shader/"},{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/categories/Graphics/"},{"name":"Service","slug":"Service","permalink":"https://skierhou.github.io/categories/Service/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://skierhou.github.io/categories/OpenGL/"},{"name":"UnityShader","slug":"UnityShader","permalink":"https://skierhou.github.io/categories/UnityShader/"},{"name":"Fog","slug":"Fog","permalink":"https://skierhou.github.io/categories/Fog/"},{"name":"Resource","slug":"Unity/Resource","permalink":"https://skierhou.github.io/categories/Unity/Resource/"},{"name":"Addressable","slug":"Unity/Resource/Addressable","permalink":"https://skierhou.github.io/categories/Unity/Resource/Addressable/"},{"name":"AssetBundle","slug":"Unity/Resource/AssetBundle","permalink":"https://skierhou.github.io/categories/Unity/Resource/AssetBundle/"},{"name":"通用","slug":"通用","permalink":"https://skierhou.github.io/categories/%E9%80%9A%E7%94%A8/"},{"name":"年度规划","slug":"年度规划","permalink":"https://skierhou.github.io/categories/%E5%B9%B4%E5%BA%A6%E8%A7%84%E5%88%92/"},{"name":"GameFramework","slug":"Unity/GameFramework","permalink":"https://skierhou.github.io/categories/Unity/GameFramework/"},{"name":"DOTS","slug":"Unity/DOTS","permalink":"https://skierhou.github.io/categories/Unity/DOTS/"},{"name":"战斗系统","slug":"Unity/战斗系统","permalink":"https://skierhou.github.io/categories/Unity/%E6%88%98%E6%96%97%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Unity","slug":"Unity","permalink":"https://skierhou.github.io/tags/Unity/"},{"name":"C#","slug":"C","permalink":"https://skierhou.github.io/tags/C/"},{"name":"Task","slug":"Task","permalink":"https://skierhou.github.io/tags/Task/"},{"name":"Thread","slug":"Thread","permalink":"https://skierhou.github.io/tags/Thread/"},{"name":"Graphics","slug":"Graphics","permalink":"https://skierhou.github.io/tags/Graphics/"},{"name":"URP","slug":"URP","permalink":"https://skierhou.github.io/tags/URP/"},{"name":"ComputeShader","slug":"ComputeShader","permalink":"https://skierhou.github.io/tags/ComputeShader/"},{"name":"Shader","slug":"Shader","permalink":"https://skierhou.github.io/tags/Shader/"},{"name":"ZeroMQ","slug":"ZeroMQ","permalink":"https://skierhou.github.io/tags/ZeroMQ/"},{"name":"KCP","slug":"KCP","permalink":"https://skierhou.github.io/tags/KCP/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://skierhou.github.io/tags/OpenGL/"},{"name":"UnityShader","slug":"UnityShader","permalink":"https://skierhou.github.io/tags/UnityShader/"},{"name":"Fog","slug":"Fog","permalink":"https://skierhou.github.io/tags/Fog/"},{"name":"Math","slug":"Math","permalink":"https://skierhou.github.io/tags/Math/"},{"name":"Addressable","slug":"Addressable","permalink":"https://skierhou.github.io/tags/Addressable/"},{"name":"AssetBundle","slug":"AssetBundle","permalink":"https://skierhou.github.io/tags/AssetBundle/"},{"name":"Markdown","slug":"Markdown","permalink":"https://skierhou.github.io/tags/Markdown/"},{"name":"Plan","slug":"Plan","permalink":"https://skierhou.github.io/tags/Plan/"},{"name":"GameFramework","slug":"GameFramework","permalink":"https://skierhou.github.io/tags/GameFramework/"},{"name":"DOTS","slug":"DOTS","permalink":"https://skierhou.github.io/tags/DOTS/"},{"name":"战斗系统","slug":"战斗系统","permalink":"https://skierhou.github.io/tags/%E6%88%98%E6%96%97%E7%B3%BB%E7%BB%9F/"}]}